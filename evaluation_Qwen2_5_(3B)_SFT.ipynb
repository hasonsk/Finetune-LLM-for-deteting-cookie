{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hasonsk/Finetune-LLM-for-deteting-cookie/blob/main/evaluation_Qwen2_5_(3B)_SFT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SspUhKDMBZQC",
        "outputId": "8d11f077-562b-4f5a-bcb0-beecaac205b5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%capture\n",
        "# import os\n",
        "# if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "#     !pip install unsloth\n",
        "# else:\n",
        "#     # Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
        "#     !pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl==0.15.2 triton cut_cross_entropy unsloth_zoo\n",
        "#     !pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n",
        "#     !pip install --no-deps unsloth"
      ],
      "metadata": {
        "id": "uUi6Kr8nR8lo"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nJpdaREcvPG-",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -U bitsandbytes\n",
        "!pip install -U datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seBAyPabUix6"
      },
      "source": [
        "# Load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nYYiye50iAJ2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from huggingface_hub import login\n",
        "\n",
        "os.environ[\"HUGGINGFACE_API_KEY\"] = \"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\"\n",
        "\n",
        "hf_token = os.environ[\"HUGGINGFACE_API_KEY\"]\n",
        "login(hf_token)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from datasets import Dataset, load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from tqdm import tqdm\n",
        "from typing import List, Dict, Any\n",
        "from peft import PeftModel, PeftConfig"
      ],
      "metadata": {
        "id": "U3aKJ3q_keqq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "EC3GY-Z1UkXL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b847cd1a-22eb-476b-ac9a-da34a5e37a51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sử dụng device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Đang tải mô hình PEFT với base model: unsloth/qwen2.5-3b-instruct-unsloth-bnb-4bit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/peft/peft_model.py:569: UserWarning: Found missing adapter keys while loading the checkpoint: ['base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.24.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.24.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.24.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.24.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.24.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.24.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.25.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.25.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.25.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.25.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.25.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.25.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.26.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.26.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.26.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.26.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.26.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.26.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.27.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.27.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.27.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.27.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.27.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.27.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.28.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.28.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.28.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.28.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.28.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.28.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.28.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.28.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.28.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.28.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.29.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.29.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.29.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.29.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.29.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.29.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.29.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.29.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.29.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.29.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.30.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.30.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.30.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.30.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.30.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.30.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.30.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.30.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.30.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.30.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.31.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.31.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.31.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.31.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.31.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.31.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.31.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.31.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.31.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.31.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.32.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.32.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.32.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.32.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.32.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.32.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.32.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.32.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.32.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.32.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.32.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.32.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.32.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.32.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.33.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.33.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.33.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.33.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.33.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.33.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.33.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.33.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.33.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.33.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.33.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.33.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.33.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.33.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.34.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.34.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.34.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.34.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.34.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.34.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.34.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.34.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.34.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.34.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.34.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.34.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.34.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.34.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.35.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.35.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.35.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.35.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.35.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.35.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.35.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.35.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.35.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.35.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.35.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.35.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.35.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.35.mlp.down_proj.lora_B.default.weight'].\n",
            "  warnings.warn(warn_message)\n"
          ]
        }
      ],
      "source": [
        "# Đường dẫn đến thư mục chứa mô hình đã fine-tune\n",
        "# model_path = \"/content/drive/MyDrive/Project/Llama-3.2-3B-Instruct/checkpoint-584\"\n",
        "model_path = \"sonhask/Qwen2.5_3B_Instruct_SFT_Extract_cookie_from_policy\"\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Sử dụng device: {device}\")\n",
        "\n",
        "try:\n",
        "    # Nếu đây là mô hình adapter (PEFT/LoRA)\n",
        "    config = PeftConfig.from_pretrained(model_path)\n",
        "    print(f\"Đang tải mô hình PEFT với base model: {config.base_model_name_or_path}\")\n",
        "\n",
        "    # Tải mô hình cơ sở\n",
        "    base_model = AutoModelForCausalLM.from_pretrained(\n",
        "        config.base_model_name_or_path,\n",
        "        device_map=\"auto\"\n",
        "    )\n",
        "\n",
        "    # Tải mô hình adapter\n",
        "    model = PeftModel.from_pretrained(base_model, model_path)\n",
        "\n",
        "except:\n",
        "    # Nếu đây là mô hình đầy đủ (không phải adapter)\n",
        "    print(\"Không phải mô hình PEFT/adapter, đang tải mô hình đầy đủ...\")\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_path, device_map=\"auto\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NZwsSbB1htCC"
      },
      "outputs": [],
      "source": [
        "alpaca_prompt = \"\"\"\n",
        "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
        "Your task is read a cookie policy text and extract detailed information about each cookie mentioned in that policy.\n",
        "RESPONSE Format: JSON following structure:\n",
        "\n",
        "{{\n",
        "  \"is_specific\": 0,\n",
        "  \"cookies\": [\n",
        "     {{\n",
        "      \"cookie_name\": \"cookie_name\",\n",
        "      \"declared_purpose\": \"declared_purpose\",\n",
        "      \"declared_retention\": \"declared_retention\",\n",
        "      \"declared_third_parties\": [\"declared_third_parties\"],\n",
        "      \"declared_description\": \"declared_description\"\n",
        "    }}, ...\n",
        "  ]\n",
        "}}\n",
        "If no cookies are specifically described, only response {{\"is_specific\": 0, \"cookies\": []}}\n",
        "\n",
        "### Instruction:\n",
        "{}\n",
        "\n",
        "### Input:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{{\n",
        "  \"is_specific\": {},\n",
        "  \"cookies\": {}\n",
        "}}\"\"\"\n",
        "\n",
        "SYSTEM_PROMPT = \"\"\"\n",
        "Extraction guidelines:\n",
        "For \"is_specific\": Determines if the website provides detailed descriptions of individual cookies:\n",
        "- Set to 0 if cookies are only described generically (e.g., \"performance cookies,\" \"necessary cookies,\" \"Google cookies\") without specific explanations\n",
        "- Set to 1 if cookies are described with specific names, purposes, retention periods, and third parties. Example: \"The '_ga' cookie is used by Google Analytics to distinguish users and is stored for 2 years\" would result in is_specific = 1\n",
        "\n",
        "For the \"cookies\" list containing objects, each object has\n",
        "- \"cookie_name\": Extract the exact technical name as mentioned. One object just has only one cookie name, ìf more one, create multiple objects. For example: ga, _gid, _gat --> 3 object cookies\n",
        "- \"declared_purpose\": cookie's purpose. With the following options:\n",
        "  * Strictly Necessary: Essential for basic website functionality\n",
        "  * Functionality: Personalizes user experience\n",
        "  * Analytical: Collects usage data\n",
        "  * Targeting/Advertising/Marketing: For personalized ads\n",
        "  * Performance: Improves technical performance\n",
        "  * Social Sharing: Enables social media integration\n",
        "  * Null: When no specific purpose information is provided\n",
        "- \"declared_retention\": Record the exact storage duration as mentioned\n",
        "- \"declared_third_parties\": An list of third parties involved in the use of this cookie for website-owned cookies\n",
        "- \"declared_description\": exact wording from the policy without modification or embellishment\"\"\"\n",
        "\n",
        "\n",
        "EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
        "def formatting_prompts_func(example):\n",
        "    if example['english_content']:\n",
        "        content = f\"Cookie policy: {example['english_content']}\\nTable: {example['english_table']}\"\n",
        "    elif example['english_table']:\n",
        "        content = f\"Table: {example['english_table']}\"\n",
        "    else:\n",
        "        content = f\"Content: {example['english_table']}\"\n",
        "\n",
        "    instruction = SYSTEM_PROMPT\n",
        "    input       = content\n",
        "    is_specific = example['is_specific']\n",
        "    cookies     = example['extracted_cookies']\n",
        "\n",
        "    text = alpaca_prompt.format(instruction, input, is_specific, cookies) + EOS_TOKEN\n",
        "    return { \"text\" : text, }\n",
        "\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"sonhask/Extract_cookies_from_cookie_policy_specific\", split = \"test\")\n",
        "dataset = dataset.map(formatting_prompts_func)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4TlfpGqLiTV_",
        "outputId": "a9c7fc7e-445d-4028-ba9c-9d650333de9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#[]:  2137\n",
            "#Has cookies:  800\n"
          ]
        }
      ],
      "source": [
        "def thong_ke(dataset):\n",
        "    empty_label_count = 0\n",
        "    non_empty_label_count = 0\n",
        "\n",
        "    for i in dataset:\n",
        "        if i['label'] == '[]':\n",
        "            empty_label_count += 1\n",
        "        else:\n",
        "            non_empty_label_count += 1\n",
        "\n",
        "    print(\"#[]: \", empty_label_count)\n",
        "    print(\"#Has cookies: \", non_empty_label_count)\n",
        "\n",
        "thong_ke(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "v4d3q9cBikRH",
        "outputId": "78e7d532-068d-4bb8-a092-1f113b869da3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N samples:  800\n",
            "#[]:  800\n",
            "#Has cookies:  800\n"
          ]
        }
      ],
      "source": [
        "from datasets import concatenate_datasets\n",
        "\n",
        "has_no_cookie = \"[]\"\n",
        "\n",
        "empty_label_dataset = dataset.filter(lambda example: example['label'] == has_no_cookie)\n",
        "non_empty_label_dataset = dataset.filter(lambda example: example['label'] != has_no_cookie)\n",
        "\n",
        "# Downsample the non-empty dataset to the size of the empty dataset\n",
        "n_samples = len(non_empty_label_dataset)\n",
        "print(\"N samples: \", n_samples)\n",
        "downsampled_empty_dataset = empty_label_dataset.shuffle(seed=42).select(range(n_samples))\n",
        "\n",
        "# Gộp 2 dataset\n",
        "combined_dataset = concatenate_datasets([non_empty_label_dataset, downsampled_empty_dataset])\n",
        "\n",
        "# Shuffle dataset\n",
        "balanced_dataset = combined_dataset.shuffle(seed=42)\n",
        "\n",
        "# Verify the balanced dataset statistics\n",
        "thong_ke(balanced_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "dGbn9I8DiWEc"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.remove_columns(['url', 'lang', 'original_text', 'tables', 'processed_text', 'english_content', 'english_table', 'translated_tables', '__index_level_0__', 'label'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TqevtGN4fhC0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "3o9Gpmguilrd",
        "outputId": "fbead589-4355-478b-a119-68b5e34f7f44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['is_specific', 'extracted_cookies', 'text'],\n",
              "    num_rows: 2937\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD_-G4bHm8WZ"
      },
      "source": [
        "### Hàm đánh giá mô hình"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "VZVSzDY3m07u"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import jsonschema\n",
        "import numpy as np\n",
        "from typing import List, Dict, Any, Union, Tuple\n",
        "from collections import defaultdict\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import sklearn.metrics.pairwise as pairwise\n",
        "import re\n",
        "\n",
        "# Schema cho dữ liệu cookie\n",
        "COOKIE_SCHEMA = {\n",
        "    \"type\": \"array\",\n",
        "    \"items\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"cookie_name\": {\"type\": \"string\"},\n",
        "            \"declared_purpose\": {\"type\": [\"string\", \"null\"]},\n",
        "            \"declared_retention\": {\"type\": [\"string\", \"null\"]},\n",
        "            \"declared_third_parties\": {\"type\": \"array\"},\n",
        "            \"declared_description\": {\"type\": [\"string\", \"null\"]}\n",
        "        },\n",
        "        \"required\": [\"cookie_name\"]\n",
        "    }\n",
        "}\n",
        "\n",
        "# 1. JSON Validity\n",
        "def validate_json_format(predicted_json_str: str) -> bool:\n",
        "    \"\"\"\n",
        "    Kiểm tra xem chuỗi JSON có hợp lệ hay không\n",
        "\n",
        "    Args:\n",
        "        predicted_json_str: Chuỗi JSON cần kiểm tra\n",
        "\n",
        "    Returns:\n",
        "        bool: True nếu JSON hợp lệ, False nếu không\n",
        "    \"\"\"\n",
        "    try:\n",
        "        json_data = json.loads(predicted_json_str)\n",
        "        jsonschema.validate(instance=json_data, schema=COOKIE_SCHEMA)\n",
        "        return True\n",
        "    except (json.JSONDecodeError, jsonschema.exceptions.ValidationError):\n",
        "        return False\n",
        "\n",
        "def json_validity_rate(predicted_json_strings: List[str]) -> float:\n",
        "    \"\"\"\n",
        "    Tính tỷ lệ các chuỗi JSON hợp lệ theo schema đã định nghĩa\n",
        "\n",
        "    Args:\n",
        "        predicted_json_strings: Danh sách các chuỗi JSON dự đoán từ mô hình\n",
        "\n",
        "    Returns:\n",
        "        float: Tỷ lệ hợp lệ (0-1)\n",
        "    \"\"\"\n",
        "    valid_count = sum(validate_json_format(js) for js in predicted_json_strings)\n",
        "    return valid_count / len(predicted_json_strings) if predicted_json_strings else 0\n",
        "\n",
        "# 2. Precision, Recall, F1-score cho từng trường\n",
        "def normalize_text(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Chuẩn hóa văn bản để so sánh\n",
        "\n",
        "    Args:\n",
        "        text: Văn bản cần chuẩn hóa\n",
        "\n",
        "    Returns:\n",
        "        str: Văn bản đã được chuẩn hóa\n",
        "    \"\"\"\n",
        "    if text is None:\n",
        "        return \"\"\n",
        "    return re.sub(r'\\s+', ' ', text.lower().strip())\n",
        "\n",
        "def extract_valid_cookies(json_strings: List[str]) -> List[List[Dict]]:\n",
        "    \"\"\"\n",
        "    Trích xuất danh sách cookie từ các chuỗi JSON và chỉ giữ lại các JSON hợp lệ\n",
        "\n",
        "    Args:\n",
        "        json_strings: Danh sách các chuỗi JSON\n",
        "\n",
        "    Returns:\n",
        "        List[List[Dict]]: Danh sách các danh sách cookie (chỉ các JSON hợp lệ)\n",
        "    \"\"\"\n",
        "    result = []\n",
        "    for js in json_strings:\n",
        "        try:\n",
        "            data = json.loads(js)\n",
        "            jsonschema.validate(instance=data, schema=COOKIE_SCHEMA)\n",
        "            result.append(data)\n",
        "        except (json.JSONDecodeError, jsonschema.exceptions.ValidationError):\n",
        "            pass\n",
        "    return result\n",
        "\n",
        "def exact_match_metrics(ground_truth: List[Dict], predictions: List[Dict], field: str) -> Tuple[float, float, float]:\n",
        "    \"\"\"\n",
        "    Tính precision, recall, F1 cho việc so khớp chính xác một trường\n",
        "\n",
        "    Args:\n",
        "        ground_truth: Danh sách cookie chuẩn\n",
        "        predictions: Danh sách cookie dự đoán\n",
        "        field: Tên trường cần đánh giá\n",
        "\n",
        "    Returns:\n",
        "        Tuple[float, float, float]: (precision, recall, F1-score)\n",
        "    \"\"\"\n",
        "    # Tạo ánh xạ từ cookie_name sang giá trị trường cần đánh giá\n",
        "    gt_map = {item[\"cookie_name\"]: item.get(field) for item in ground_truth if \"cookie_name\" in item}\n",
        "    pred_map = {item[\"cookie_name\"]: item.get(field) for item in predictions if \"cookie_name\" in item}\n",
        "\n",
        "    # Xử lý trường hợp đặc biệt cho declared_third_parties là mảng\n",
        "    if field == \"declared_third_parties\":\n",
        "        # Chuyển thành set để so sánh không phụ thuộc thứ tự\n",
        "        gt_map = {k: set(v) if v is not None else set() for k, v in gt_map.items()}\n",
        "        pred_map = {k: set(v) if v is not None else set() for k, v in pred_map.items()}\n",
        "    else:\n",
        "        # Chuẩn hóa dữ liệu văn bản\n",
        "        gt_map = {k: normalize_text(v) for k, v in gt_map.items()}\n",
        "        pred_map = {k: normalize_text(v) for k, v in pred_map.items()}\n",
        "\n",
        "    # Đếm các trường hợp True Positive, False Positive, False Negative\n",
        "    tp = 0\n",
        "    for cookie_name in set(gt_map.keys()) & set(pred_map.keys()):\n",
        "        if field == \"declared_third_parties\":\n",
        "            if gt_map[cookie_name] == pred_map[cookie_name]:\n",
        "                tp += 1\n",
        "        else:\n",
        "            if gt_map[cookie_name] == pred_map[cookie_name]:\n",
        "                tp += 1\n",
        "\n",
        "    fp = len(set(pred_map.keys()) - set(gt_map.keys()))\n",
        "    fn = len(set(gt_map.keys()) - set(pred_map.keys()))\n",
        "\n",
        "    # Tính precision, recall, F1\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "    return precision, recall, f1\n",
        "\n",
        "def evaluate_field_metrics(ground_truth_json: List[str], predicted_json: List[str]) -> Dict[str, Dict[str, float]]:\n",
        "    \"\"\"\n",
        "    Đánh giá metrics cho tất cả các trường\n",
        "\n",
        "    Args:\n",
        "        ground_truth_json: Danh sách chuỗi JSON chuẩn\n",
        "        predicted_json: Danh sách chuỗi JSON dự đoán\n",
        "\n",
        "    Returns:\n",
        "        Dict: Kết quả metrics cho từng trường\n",
        "    \"\"\"\n",
        "    # Chỉ lấy các JSON hợp lệ\n",
        "    valid_gt = []\n",
        "    for js in ground_truth_json:\n",
        "        try:\n",
        "            data = json.loads(js)\n",
        "            jsonschema.validate(instance=data, schema=COOKIE_SCHEMA)\n",
        "            valid_gt.extend(data)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    valid_pred = []\n",
        "    for js in predicted_json:\n",
        "        try:\n",
        "            data = json.loads(js)\n",
        "            jsonschema.validate(instance=data, schema=COOKIE_SCHEMA)\n",
        "            valid_pred.extend(data)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    fields = [\"cookie_name\", \"declared_purpose\", \"declared_retention\",\n",
        "              \"declared_third_parties\", \"declared_description\"]\n",
        "\n",
        "    results = {}\n",
        "    for field in fields:\n",
        "        precision, recall, f1 = exact_match_metrics(valid_gt, valid_pred, field)\n",
        "        results[field] = {\n",
        "            \"precision\": precision,\n",
        "            \"recall\": recall,\n",
        "            \"f1\": f1\n",
        "        }\n",
        "\n",
        "    return results\n",
        "\n",
        "# 3. Semantic Similarity\n",
        "def load_sentence_transformer():\n",
        "    \"\"\"Tải mô hình sentence transformer\"\"\"\n",
        "    try:\n",
        "        return SentenceTransformer('all-MiniLM-L6-v2')\n",
        "    except:\n",
        "        print(\"Cần cài đặt sentence-transformers: pip install sentence-transformers\")\n",
        "        return None\n",
        "\n",
        "def compute_semantic_similarity(ground_truth: List[Dict], predictions: List[Dict],\n",
        "                               field: str, model) -> float:\n",
        "    \"\"\"\n",
        "    Tính toán độ tương đồng ngữ nghĩa cho một trường\n",
        "\n",
        "    Args:\n",
        "        ground_truth: Danh sách cookie chuẩn\n",
        "        predictions: Danh sách cookie dự đoán\n",
        "        field: Tên trường cần đánh giá\n",
        "        model: Mô hình sentence transformer\n",
        "\n",
        "    Returns:\n",
        "        float: Điểm tương đồng ngữ nghĩa trung bình\n",
        "    \"\"\"\n",
        "    if model is None:\n",
        "        return 0.0\n",
        "\n",
        "    # Tạo ánh xạ từ cookie_name sang giá trị trường cần đánh giá\n",
        "    gt_map = {item[\"cookie_name\"]: item.get(field, \"\") for item in ground_truth if \"cookie_name\" in item}\n",
        "    pred_map = {item[\"cookie_name\"]: item.get(field, \"\") for item in predictions if \"cookie_name\" in item}\n",
        "\n",
        "    # Chỉ so sánh các cookie cùng tên\n",
        "    common_names = set(gt_map.keys()) & set(pred_map.keys())\n",
        "\n",
        "    if not common_names or field == \"declared_third_parties\":  # Không áp dụng semantic similarity cho mảng\n",
        "        return 0.0\n",
        "\n",
        "    similarities = []\n",
        "    for name in common_names:\n",
        "        gt_text = gt_map[name]\n",
        "        pred_text = pred_map[name]\n",
        "\n",
        "        # Bỏ qua các trường rỗng hoặc None\n",
        "        if not gt_text or not pred_text or gt_text is None or pred_text is None:\n",
        "            continue\n",
        "\n",
        "        # Mã hóa văn bản thành vector\n",
        "        gt_embedding = model.encode(str(gt_text))\n",
        "        pred_embedding = model.encode(str(pred_text))\n",
        "\n",
        "        # Tính cosine similarity\n",
        "        similarity = pairwise.cosine_similarity([gt_embedding], [pred_embedding])[0][0]\n",
        "        similarities.append(similarity)\n",
        "\n",
        "    # Tính điểm trung bình\n",
        "    return float(np.mean(similarities)) if similarities else 0.0\n",
        "\n",
        "def evaluate_semantic_similarity(ground_truth_json: List[str], predicted_json: List[str]) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Đánh giá độ tương đồng ngữ nghĩa cho các trường văn bản\n",
        "\n",
        "    Args:\n",
        "        ground_truth_json: Danh sách chuỗi JSON chuẩn\n",
        "        predicted_json: Danh sách chuỗi JSON dự đoán\n",
        "\n",
        "    Returns:\n",
        "        Dict: Kết quả semantic similarity cho từng trường\n",
        "    \"\"\"\n",
        "    # Tải mô hình sentence transformer\n",
        "    model = load_sentence_transformer()\n",
        "\n",
        "    # Chỉ lấy các JSON hợp lệ\n",
        "    valid_gt = []\n",
        "    for js in ground_truth_json:\n",
        "        try:\n",
        "            data = json.loads(js)\n",
        "            jsonschema.validate(instance=data, schema=COOKIE_SCHEMA)\n",
        "            valid_gt.extend(data)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    valid_pred = []\n",
        "    for js in predicted_json:\n",
        "        try:\n",
        "            data = json.loads(js)\n",
        "            jsonschema.validate(instance=data, schema=COOKIE_SCHEMA)\n",
        "            valid_pred.extend(data)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    # Các trường văn bản cần đánh giá semantic similarity\n",
        "    text_fields = [\"declared_purpose\", \"declared_description\", \"declared_retention\"]\n",
        "\n",
        "    results = {}\n",
        "    for field in text_fields:\n",
        "        similarity = compute_semantic_similarity(valid_gt, valid_pred, field, model)\n",
        "        results[field] = similarity\n",
        "\n",
        "    # Tính điểm trung bình\n",
        "    results[\"average\"] = float(np.mean(list(results.values()))) if results else 0.0\n",
        "\n",
        "    return results\n",
        "\n",
        "# Hàm tổng hợp tất cả các metrics\n",
        "def evaluate_cookie_extraction(ground_truth_json: List[str], predicted_json: List[str]) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Đánh giá toàn diện việc trích xuất cookie\n",
        "\n",
        "    Args:\n",
        "        ground_truth_json: Danh sách chuỗi JSON chuẩn\n",
        "        predicted_json: Danh sách chuỗi JSON dự đoán\n",
        "\n",
        "    Returns:\n",
        "        Dict: Kết quả tất cả các metrics\n",
        "    \"\"\"\n",
        "    # 1. JSON Validity\n",
        "    validity_rate = json_validity_rate(predicted_json)\n",
        "\n",
        "    # 2. Field metrics (precision, recall, F1)\n",
        "    field_metrics = evaluate_field_metrics(ground_truth_json, predicted_json)\n",
        "\n",
        "    # 3. Semantic similarity\n",
        "    semantic_metrics = evaluate_semantic_similarity(ground_truth_json, predicted_json)\n",
        "\n",
        "    # Tổng hợp kết quả\n",
        "    results = {\n",
        "        \"json_validity_rate\": validity_rate,\n",
        "        \"field_metrics\": field_metrics,\n",
        "        \"semantic_similarity\": semantic_metrics\n",
        "    }\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yi7JsK5Zdcd1"
      },
      "source": [
        "### Hàm đánh giá mô hình với is_sperific"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "WTkEzRZqdcd2"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import jsonschema\n",
        "import numpy as np\n",
        "from typing import List, Dict, Any, Union, Tuple\n",
        "from collections import defaultdict\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import sklearn.metrics.pairwise as pairwise\n",
        "import re\n",
        "\n",
        "# Schema cho dữ liệu cookie đã cập nhật\n",
        "COOKIE_SCHEMA = {\n",
        "    \"type\": \"object\",\n",
        "    \"required\": [\"is_specific\", \"cookies\"],\n",
        "    \"properties\": {\n",
        "        \"is_specific\": {\n",
        "            \"type\": \"integer\",\n",
        "            \"enum\": [0, 1],\n",
        "        },\n",
        "        \"cookies\": {\n",
        "            \"type\": \"array\",\n",
        "            \"items\": {\n",
        "                \"type\": \"object\",\n",
        "                \"required\": [\n",
        "                    \"cookie_name\",\n",
        "                    \"declared_purpose\",\n",
        "                    \"declared_retention\",\n",
        "                    \"declared_third_parties\",\n",
        "                    \"declared_description\"\n",
        "                ],\n",
        "                \"properties\": {\n",
        "                    \"cookie_name\": {\n",
        "                        \"type\": \"string\",\n",
        "                    },\n",
        "                    \"declared_purpose\": {\n",
        "                        \"type\": \"string\",\n",
        "                    },\n",
        "                    \"declared_retention\": {\n",
        "                        \"type\": [\"string\", \"null\"],\n",
        "                    },\n",
        "                    \"declared_third_parties\": {\n",
        "                        \"type\": \"array\",\n",
        "                        \"items\": {\n",
        "                            \"type\": \"string\"\n",
        "                        },\n",
        "                    },\n",
        "                    \"declared_description\": {\n",
        "                        \"type\": [\"string\", \"null\"],\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# 1. JSON Validity\n",
        "def validate_json_format(predicted_json_str: str) -> bool:\n",
        "    \"\"\"\n",
        "    Kiểm tra xem chuỗi JSON có hợp lệ theo schema mới hay không\n",
        "\n",
        "    Args:\n",
        "        predicted_json_str: Chuỗi JSON cần kiểm tra\n",
        "\n",
        "    Returns:\n",
        "        bool: True nếu JSON hợp lệ, False nếu không\n",
        "    \"\"\"\n",
        "    try:\n",
        "        json_data = ast.literal_eval(predicted_json_str)\n",
        "        jsonschema.validate(instance=json_data, schema=COOKIE_SCHEMA)\n",
        "        return True\n",
        "    except (json.JSONDecodeError, jsonschema.exceptions.ValidationError):\n",
        "        return False\n",
        "\n",
        "def json_validity_rate(predicted_json_strings: List[str]) -> float:\n",
        "    \"\"\"\n",
        "    Tính tỷ lệ các chuỗi JSON hợp lệ theo schema đã định nghĩa\n",
        "\n",
        "    Args:\n",
        "        predicted_json_strings: Danh sách các chuỗi JSON dự đoán từ mô hình\n",
        "\n",
        "    Returns:\n",
        "        float: Tỷ lệ hợp lệ (0-1)\n",
        "    \"\"\"\n",
        "    valid_count = sum(validate_json_format(js) for js in predicted_json_strings)\n",
        "    return valid_count / len(predicted_json_strings) if predicted_json_strings else 0\n",
        "\n",
        "# 2. Precision, Recall, F1-score cho từng trường\n",
        "def normalize_text(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Chuẩn hóa văn bản để so sánh\n",
        "\n",
        "    Args:\n",
        "        text: Văn bản cần chuẩn hóa\n",
        "\n",
        "    Returns:\n",
        "        str: Văn bản đã được chuẩn hóa\n",
        "    \"\"\"\n",
        "    if text is None:\n",
        "        return \"\"\n",
        "    return re.sub(r'\\s+', ' ', text.lower().strip())\n",
        "\n",
        "def extract_valid_cookies(json_strings: List[str]) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Trích xuất dữ liệu từ các chuỗi JSON và chỉ giữ lại các JSON hợp lệ\n",
        "\n",
        "    Args:\n",
        "        json_strings: Danh sách các chuỗi JSON\n",
        "\n",
        "    Returns:\n",
        "        List[Dict]: Danh sách các đối tượng JSON hợp lệ\n",
        "    \"\"\"\n",
        "    result = []\n",
        "    for js in json_strings:\n",
        "        try:\n",
        "            data = ast.literal_eval(js)\n",
        "            jsonschema.validate(instance=data, schema=COOKIE_SCHEMA)\n",
        "            result.append(data)\n",
        "        except (json.JSONDecodeError, jsonschema.exceptions.ValidationError):\n",
        "            pass\n",
        "    return result\n",
        "\n",
        "def exact_match_metrics(ground_truth: List[Dict], predictions: List[Dict], field: str) -> Tuple[float, float, float]:\n",
        "    \"\"\"\n",
        "    Tính precision, recall, F1 cho việc so khớp chính xác một trường trong cookies\n",
        "\n",
        "    Args:\n",
        "        ground_truth: Danh sách đối tượng JSON chuẩn\n",
        "        predictions: Danh sách đối tượng JSON dự đoán\n",
        "        field: Tên trường cần đánh giá\n",
        "\n",
        "    Returns:\n",
        "        Tuple[float, float, float]: (precision, recall, F1-score)\n",
        "    \"\"\"\n",
        "    # Tạo ánh xạ từ cookie_name sang giá trị trường cần đánh giá\n",
        "    gt_cookies = []\n",
        "    for doc in ground_truth:\n",
        "        gt_cookies.extend(doc.get(\"cookies\", []))\n",
        "\n",
        "    pred_cookies = []\n",
        "    for doc in predictions:\n",
        "        pred_cookies.extend(doc.get(\"cookies\", []))\n",
        "\n",
        "    gt_map = {item[\"cookie_name\"]: item.get(field) for item in gt_cookies if \"cookie_name\" in item}\n",
        "    pred_map = {item[\"cookie_name\"]: item.get(field) for item in pred_cookies if \"cookie_name\" in item}\n",
        "\n",
        "    # Xử lý trường hợp đặc biệt cho declared_third_parties là mảng\n",
        "    if field == \"declared_third_parties\":\n",
        "        # Chuyển thành set để so sánh không phụ thuộc thứ tự\n",
        "        gt_map = {k: set(v) if v is not None else set() for k, v in gt_map.items()}\n",
        "        pred_map = {k: set(v) if v is not None else set() for k, v in pred_map.items()}\n",
        "    else:\n",
        "        # Chuẩn hóa dữ liệu văn bản\n",
        "        gt_map = {k: normalize_text(v) for k, v in gt_map.items()}\n",
        "        pred_map = {k: normalize_text(v) for k, v in pred_map.items()}\n",
        "\n",
        "    # Đếm số lượng predicted cookies và ground truth cookies\n",
        "    total_gt = len(gt_map)\n",
        "    total_pred = len(pred_map)\n",
        "\n",
        "    # Đếm các trường hợp True Positive\n",
        "    tp = 0\n",
        "    for cookie_name in set(gt_map.keys()) & set(pred_map.keys()):\n",
        "        if field == \"declared_third_parties\":\n",
        "            if gt_map[cookie_name] == pred_map[cookie_name]:\n",
        "                tp += 1\n",
        "        else:\n",
        "            if gt_map[cookie_name] == pred_map[cookie_name]:\n",
        "                tp += 1\n",
        "\n",
        "    # Tính precision, recall, F1\n",
        "    precision = tp / total_pred if total_pred > 0 else 0\n",
        "    recall = tp / total_gt if total_gt > 0 else 0\n",
        "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "    return precision, recall, f1\n",
        "\n",
        "def evaluate_is_specific_classification(ground_truth_json: List[str], predicted_json: List[str]) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Đánh giá accuracy cho việc phân loại is_specific\n",
        "\n",
        "    Args:\n",
        "        ground_truth_json: Danh sách chuỗi JSON chuẩn\n",
        "        predicted_json: Danh sách chuỗi JSON dự đoán\n",
        "\n",
        "    Returns:\n",
        "        Dict: Kết quả accuracy cho is_specific\n",
        "    \"\"\"\n",
        "    valid_gt = extract_valid_cookies(ground_truth_json)\n",
        "    valid_pred = extract_valid_cookies(predicted_json)\n",
        "\n",
        "    if not valid_gt or not valid_pred:\n",
        "        return {\"accuracy\": 0.0}\n",
        "\n",
        "    correct = 0\n",
        "    total = len(valid_gt)\n",
        "\n",
        "    for i in range(total):\n",
        "        if valid_gt[i].get(\"is_specific\") == valid_pred[i].get(\"is_specific\"):\n",
        "            correct += 1\n",
        "\n",
        "    accuracy = correct / total if total > 0 else 0\n",
        "\n",
        "    return {\"accuracy\": accuracy}\n",
        "\n",
        "def evaluate_field_metrics(ground_truth_json: List[str], predicted_json: List[str]) -> Dict[str, Dict[str, float]]:\n",
        "    \"\"\"\n",
        "    Đánh giá metrics cho tất cả các trường trong cookies\n",
        "\n",
        "    Args:\n",
        "        ground_truth_json: Danh sách chuỗi JSON chuẩn\n",
        "        predicted_json: Danh sách chuỗi JSON dự đoán\n",
        "\n",
        "    Returns:\n",
        "        Dict: Kết quả metrics cho từng trường\n",
        "    \"\"\"\n",
        "    # Lấy các JSON hợp lệ\n",
        "    valid_gt = extract_valid_cookies(ground_truth_json)\n",
        "    valid_pred = extract_valid_cookies(predicted_json)\n",
        "\n",
        "    if not valid_gt or not valid_pred:\n",
        "        empty_metrics = {\"precision\": 0.0, \"recall\": 0.0, \"f1\": 0.0}\n",
        "        return {\n",
        "            \"cookie_name\": empty_metrics,\n",
        "            \"declared_purpose\": empty_metrics,\n",
        "            \"declared_retention\": empty_metrics,\n",
        "            \"declared_third_parties\": empty_metrics,\n",
        "            \"declared_description\": empty_metrics\n",
        "        }\n",
        "\n",
        "    fields = [\"cookie_name\", \"declared_purpose\", \"declared_retention\",\n",
        "              \"declared_third_parties\", \"declared_description\"]\n",
        "\n",
        "    results = {}\n",
        "    for field in fields:\n",
        "        precision, recall, f1 = exact_match_metrics(valid_gt, valid_pred, field)\n",
        "        results[field] = {\n",
        "            \"precision\": precision,\n",
        "            \"recall\": recall,\n",
        "            \"f1\": f1\n",
        "        }\n",
        "\n",
        "    return results\n",
        "\n",
        "# 3. Semantic Similarity\n",
        "def load_sentence_transformer():\n",
        "    \"\"\"Tải mô hình sentence transformer\"\"\"\n",
        "    try:\n",
        "        return SentenceTransformer('all-MiniLM-L6-v2')\n",
        "    except:\n",
        "        print(\"Cần cài đặt sentence-transformers: pip install sentence-transformers\")\n",
        "        return None\n",
        "\n",
        "def compute_semantic_similarity(ground_truth: List[Dict], predictions: List[Dict],\n",
        "                               field: str, model) -> float:\n",
        "    \"\"\"\n",
        "    Tính toán độ tương đồng ngữ nghĩa cho một trường trong cookies\n",
        "\n",
        "    Args:\n",
        "        ground_truth: Danh sách đối tượng JSON chuẩn\n",
        "        predictions: Danh sách đối tượng JSON dự đoán\n",
        "        field: Tên trường cần đánh giá\n",
        "        model: Mô hình sentence transformer\n",
        "\n",
        "    Returns:\n",
        "        float: Điểm tương đồng ngữ nghĩa trung bình\n",
        "    \"\"\"\n",
        "    if model is None:\n",
        "        return 0.0\n",
        "\n",
        "    # Lấy danh sách cookies từ mỗi đối tượng JSON\n",
        "    gt_cookies = []\n",
        "    for doc in ground_truth:\n",
        "        gt_cookies.extend(doc.get(\"cookies\", []))\n",
        "\n",
        "    pred_cookies = []\n",
        "    for doc in predictions:\n",
        "        pred_cookies.extend(doc.get(\"cookies\", []))\n",
        "\n",
        "    # Tạo ánh xạ từ cookie_name sang giá trị trường cần đánh giá\n",
        "    gt_map = {item[\"cookie_name\"]: item.get(field, \"\") for item in gt_cookies if \"cookie_name\" in item}\n",
        "    pred_map = {item[\"cookie_name\"]: item.get(field, \"\") for item in pred_cookies if \"cookie_name\" in item}\n",
        "\n",
        "    # Chỉ so sánh các cookie cùng tên\n",
        "    common_names = set(gt_map.keys()) & set(pred_map.keys())\n",
        "\n",
        "    if not common_names or field == \"declared_third_parties\":  # Không áp dụng semantic similarity cho mảng\n",
        "        return 0.0\n",
        "\n",
        "    similarities = []\n",
        "    for name in common_names:\n",
        "        gt_text = gt_map[name]\n",
        "        pred_text = pred_map[name]\n",
        "\n",
        "        # Bỏ qua các trường rỗng hoặc None\n",
        "        if not gt_text or not pred_text or gt_text is None or pred_text is None:\n",
        "            continue\n",
        "\n",
        "        # Mã hóa văn bản thành vector\n",
        "        gt_embedding = model.encode(str(gt_text))\n",
        "        pred_embedding = model.encode(str(pred_text))\n",
        "\n",
        "        # Tính cosine similarity\n",
        "        similarity = pairwise.cosine_similarity([gt_embedding], [pred_embedding])[0][0]\n",
        "        similarities.append(similarity)\n",
        "\n",
        "    # Tính điểm trung bình\n",
        "    return float(np.mean(similarities)) if similarities else 0.0\n",
        "\n",
        "def evaluate_semantic_similarity(ground_truth_json: List[str], predicted_json: List[str]) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Đánh giá độ tương đồng ngữ nghĩa cho các trường văn bản\n",
        "\n",
        "    Args:\n",
        "        ground_truth_json: Danh sách chuỗi JSON chuẩn\n",
        "        predicted_json: Danh sách chuỗi JSON dự đoán\n",
        "\n",
        "    Returns:\n",
        "        Dict: Kết quả semantic similarity cho từng trường\n",
        "    \"\"\"\n",
        "    # Tải mô hình sentence transformer\n",
        "    model = load_sentence_transformer()\n",
        "\n",
        "    # Lấy các JSON hợp lệ\n",
        "    valid_gt = extract_valid_cookies(ground_truth_json)\n",
        "    valid_pred = extract_valid_cookies(predicted_json)\n",
        "\n",
        "    if not valid_gt or not valid_pred or model is None:\n",
        "        return {\n",
        "            \"declared_purpose\": 0.0,\n",
        "            \"declared_description\": 0.0,\n",
        "            \"declared_retention\": 0.0,\n",
        "            \"average\": 0.0\n",
        "        }\n",
        "\n",
        "    # Các trường văn bản cần đánh giá semantic similarity\n",
        "    text_fields = [\"declared_purpose\", \"declared_description\", \"declared_retention\"]\n",
        "\n",
        "    results = {}\n",
        "    for field in text_fields:\n",
        "        similarity = compute_semantic_similarity(valid_gt, valid_pred, field, model)\n",
        "        results[field] = similarity\n",
        "\n",
        "    # Tính điểm trung bình\n",
        "    results[\"average\"] = float(np.mean(list(results.values()))) if results else 0.0\n",
        "\n",
        "    return results\n",
        "\n",
        "# 4. Cookie Count Accuracy\n",
        "def evaluate_cookie_count_accuracy(ground_truth_json: List[str], predicted_json: List[str]) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Đánh giá độ chính xác về số lượng cookie được trích xuất\n",
        "\n",
        "    Args:\n",
        "        ground_truth_json: Danh sách chuỗi JSON chuẩn\n",
        "        predicted_json: Danh sách chuỗi JSON dự đoán\n",
        "\n",
        "    Returns:\n",
        "        Dict: Kết quả đánh giá số lượng cookie\n",
        "    \"\"\"\n",
        "    valid_gt = extract_valid_cookies(ground_truth_json)\n",
        "    valid_pred = extract_valid_cookies(predicted_json)\n",
        "\n",
        "    if not valid_gt:\n",
        "        return {\"cookie_count_accuracy\": 0.0}\n",
        "\n",
        "    # Đếm số lượng cookie trong mỗi JSON\n",
        "    gt_counts = [len(doc.get(\"cookies\", [])) for doc in valid_gt]\n",
        "    pred_counts = [len(doc.get(\"cookies\", [])) for doc in valid_pred]\n",
        "\n",
        "    # Tính mức độ chênh lệch tuyệt đối trung bình\n",
        "    total_docs = min(len(gt_counts), len(pred_counts))\n",
        "    if total_docs == 0:\n",
        "        return {\"cookie_count_accuracy\": 0.0}\n",
        "\n",
        "    abs_diff_sum = sum(abs(gt_counts[i] - pred_counts[i]) for i in range(total_docs))\n",
        "    mean_abs_diff = abs_diff_sum / total_docs\n",
        "\n",
        "    # Tính độ chính xác của số lượng cookie (0-1, càng cao càng tốt)\n",
        "    max_gt_count = max(gt_counts) if gt_counts else 1\n",
        "    cookie_count_accuracy = max(0, 1 - (mean_abs_diff / max_gt_count))\n",
        "\n",
        "    return {\"cookie_count_accuracy\": cookie_count_accuracy}\n",
        "\n",
        "# Hàm tổng hợp tất cả các metrics\n",
        "def evaluate_cookie_extraction(ground_truth_json: List[str], predicted_json: List[str]) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Đánh giá toàn diện việc trích xuất cookie và phân loại is_specific\n",
        "\n",
        "    Args:\n",
        "        ground_truth_json: Danh sách chuỗi JSON chuẩn\n",
        "        predicted_json: Danh sách chuỗi JSON dự đoán\n",
        "\n",
        "    Returns:\n",
        "        Dict: Kết quả tất cả các metrics\n",
        "    \"\"\"\n",
        "    # 1. JSON Validity\n",
        "    validity_rate = json_validity_rate(predicted_json)\n",
        "\n",
        "    # 2. Field metrics (precision, recall, F1)\n",
        "    field_metrics = evaluate_field_metrics(ground_truth_json, predicted_json)\n",
        "\n",
        "    # 3. is_specific classification accuracy\n",
        "    is_specific_metrics = evaluate_is_specific_classification(ground_truth_json, predicted_json)\n",
        "\n",
        "    # 4. Cookie count accuracy\n",
        "    cookie_count_metrics = evaluate_cookie_count_accuracy(ground_truth_json, predicted_json)\n",
        "\n",
        "    # 5. Semantic similarity\n",
        "    semantic_metrics = evaluate_semantic_similarity(ground_truth_json, predicted_json)\n",
        "\n",
        "    # Tính overall accuracy dựa trên trung bình của các metrics chính\n",
        "    # Kết hợp F1 của các trường + accuracy của is_specific\n",
        "    f1_scores = [metrics[\"f1\"] for field, metrics in field_metrics.items()]\n",
        "    overall_accuracy = (sum(f1_scores) + is_specific_metrics[\"accuracy\"] + cookie_count_metrics[\"cookie_count_accuracy\"]) / (len(f1_scores) + 2)\n",
        "\n",
        "    # Tổng hợp kết quả\n",
        "    results = {\n",
        "        \"json_validity_rate\": validity_rate,\n",
        "        \"field_metrics\": field_metrics,\n",
        "        \"is_specific_classification\": is_specific_metrics,\n",
        "        \"cookie_count_metrics\": cookie_count_metrics,\n",
        "        \"semantic_similarity\": semantic_metrics,\n",
        "        \"overall_accuracy\": overall_accuracy\n",
        "    }\n",
        "\n",
        "    return results\n",
        "\n",
        "# Hàm hỗ trợ đánh giá với đầu vào từ file\n",
        "def evaluate_from_files(ground_truth_file: str, prediction_file: str) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Đánh giá từ các file chứa JSON\n",
        "\n",
        "    Args:\n",
        "        ground_truth_file: Đường dẫn đến file chứa JSON chuẩn\n",
        "        prediction_file: Đường dẫn đến file chứa JSON dự đoán\n",
        "\n",
        "    Returns:\n",
        "        Dict: Kết quả tất cả các metrics\n",
        "    \"\"\"\n",
        "    with open(ground_truth_file, 'r', encoding='utf-8') as f:\n",
        "        ground_truth_json = [line.strip() for line in f if line.strip()]\n",
        "\n",
        "    with open(prediction_file, 'r', encoding='utf-8') as f:\n",
        "        predicted_json = [line.strip() for line in f if line.strip()]\n",
        "\n",
        "    return evaluate_cookie_extraction(ground_truth_json, predicted_json)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-7-qCEgnBmm"
      },
      "source": [
        "### Đánh giá mô hình"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "5SqbAmE5mlIA"
      },
      "outputs": [],
      "source": [
        "def generate_response(messages, max_new_tokens=4096, temperature=0):\n",
        "\n",
        "    inputs = tokenizer(messages, return_tensors=\"pt\", truncation=True,\n",
        "                       max_length=max_new_tokens\n",
        "                       ).to(device)\n",
        "\n",
        "    # Tạo đầu ra\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            do_sample=temperature > 0,\n",
        "            temperature=temperature,\n",
        "            top_p=1,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    # # Decode the prediction\n",
        "    decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    result_text = decoded_output.split(\"### Response:\")[-1].strip()\n",
        "\n",
        "\n",
        "    # # Trích xuất phần JSON\n",
        "    json_start = result_text.find(\"{\")\n",
        "    json_end = result_text.rfind(\"}\")\n",
        "    if json_start != -1 and json_end != -1 and json_end > json_start:\n",
        "        json_text = result_text[json_start:json_end+1]\n",
        "        return json_text\n",
        "\n",
        "    return result_text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_response(\"how are you today\")"
      ],
      "metadata": {
        "id": "Kev3j1dVzngZ",
        "outputId": "f03c75b5-2ea1-42a4-a7d4-9070df66f532",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:653: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"how are you today? I'm doing well, thank you. How can I assist you today? If you have any questions or need help with anything, feel free to ask! Alternatively, if you'd like to chat or just talk, I'm here to listen. What would you like to do?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "\n",
        "def evaluate_model(eval_data: Dataset, batch_size: int = 4, checkpoint_interval: int = 10,\n",
        "                checkpoint_path: str = \"/content/drive/MyDrive/Project/Models-v3/Qwen2.5-3B-Instruct_SFT/eval_checkpoint.json\") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Đánh giá mô hình trên tập dữ liệu với khả năng lưu checkpoint\n",
        "\n",
        "    Args:\n",
        "      eval_data: Tập dữ liệu đánh giá (Dataset object)\n",
        "      batch_size: Số lượng mẫu xử lý cùng lúc\n",
        "      checkpoint_interval: Số lượng mẫu xử lý trước khi lưu checkpoint\n",
        "      checkpoint_path: Đường dẫn để lưu tệp checkpoint\n",
        "\n",
        "    Returns:\n",
        "      Dict: Kết quả đánh giá\n",
        "    \"\"\"\n",
        "    if not model or not tokenizer:\n",
        "      raise ValueError(\"Cần tải mô hình trước khi đánh giá\")\n",
        "\n",
        "    all_ground_truth = []\n",
        "    all_predictions = []\n",
        "\n",
        "    # Kiểm tra xem có checkpoint trước đó hay không\n",
        "    start_idx = 0\n",
        "    if os.path.exists(checkpoint_path):\n",
        "        try:\n",
        "            with open(checkpoint_path, 'r', encoding='utf-8') as f:\n",
        "                checkpoint_data = json.load(f)\n",
        "                all_ground_truth = checkpoint_data.get('ground_truth', [])\n",
        "                all_predictions = checkpoint_data.get('predictions', [])\n",
        "                start_idx = checkpoint_data.get('next_idx', 0)\n",
        "                print(f\"Đã tải checkpoint, tiếp tục từ mẫu {start_idx}/{len(eval_data)}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Không thể tải checkpoint: {str(e)}, bắt đầu từ đầu\")\n",
        "    else:\n",
        "      print(\"Start from zero! \")\n",
        "    # Tính số mẫu đã xử lý\n",
        "#     processed_samples = len(all_ground_truth)\n",
        "\n",
        "#     for i in tqdm(range(start_idx, len(eval_data), batch_size), desc=\"Đánh giá\"):\n",
        "#       batch = [eval_data[j] for j in range(i, min(i + batch_size, len(eval_data)))]\n",
        "\n",
        "#       for sample in batch:\n",
        "#         try:\n",
        "#           # Lấy ground truth\n",
        "#           ground_truth = f\"\"\"\n",
        "# {{\n",
        "#   'is_specific': {sample['is_specific']},\n",
        "#   'extracted_cookies': {sample['extracted_cookies']}\n",
        "# }}\"\"\"\n",
        "#           all_ground_truth.append(ground_truth)\n",
        "#           print(\"------> Ground_truth: \", ground_truth)\n",
        "\n",
        "#           # Sinh dự đoán\n",
        "#           prediction = generate_response(sample['text'])\n",
        "#           print(\"-----> Predict: \", prediction)\n",
        "#           all_predictions.append(prediction)\n",
        "\n",
        "#           # Tăng số mẫu đã xử lý\n",
        "#           processed_samples += 1\n",
        "\n",
        "#           # Lưu checkpoint sau mỗi checkpoint_interval mẫu\n",
        "#           if processed_samples % checkpoint_interval == 0:\n",
        "#               save_checkpoint(all_ground_truth, all_predictions, i + 1, checkpoint_path)\n",
        "#               print(f\"Đã lưu checkpoint sau khi xử lý {processed_samples} mẫu\")\n",
        "\n",
        "#         except Exception as e:\n",
        "#           print(f\"Lỗi khi xử lý mẫu {i}: {str(e)}\")\n",
        "\n",
        "    print(\"----------Start to evaluate----------\")\n",
        "    # Đánh giá kết quả sau khi hoàn thành\n",
        "    overall_result = evaluate_cookie_extraction(all_ground_truth, all_predictions)\n",
        "\n",
        "    return {\n",
        "      'overall': overall_result,\n",
        "    }\n",
        "\n",
        "def save_checkpoint(ground_truth: list, predictions: list, next_idx: int, checkpoint_path: str):\n",
        "    \"\"\"\n",
        "    Lưu trạng thái hiện tại của quá trình đánh giá\n",
        "\n",
        "    Args:\n",
        "        ground_truth: Danh sách ground truth đã xử lý\n",
        "        predictions: Danh sách dự đoán đã xử lý\n",
        "        next_idx: Chỉ số mẫu tiếp theo sẽ xử lý\n",
        "        checkpoint_path: Đường dẫn lưu tệp checkpoint\n",
        "    \"\"\"\n",
        "    checkpoint_data = {\n",
        "        'ground_truth': ground_truth,\n",
        "        'predictions': predictions,\n",
        "        'next_idx': next_idx,\n",
        "        'timestamp': datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    }\n",
        "\n",
        "    # Tạo thư mục chứa nếu chưa tồn tại\n",
        "    os.makedirs(os.path.dirname(checkpoint_path) if os.path.dirname(checkpoint_path) else '.', exist_ok=True)\n",
        "\n",
        "    with open(checkpoint_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(checkpoint_data, f, ensure_ascii=False)\n",
        "\n",
        "def save_evaluation_report(eval_results: Dict[str, Any], output_path: str = \"evaluation_report.json\"):\n",
        "    \"\"\"\n",
        "    Lưu báo cáo đánh giá\n",
        "\n",
        "    Args:\n",
        "        eval_results: Kết quả đánh giá\n",
        "        output_path: Đường dẫn lưu báo cáo\n",
        "    \"\"\"\n",
        "    with open(output_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(eval_results, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    print(f\"Đã lưu báo cáo đánh giá tại: {output_path}\")\n",
        "\n",
        "    summary = {\n",
        "        \"json_validity_rate\": eval_results['overall']['json_validity_rate'],\n",
        "        \"average_f1_scores\": {\n",
        "            field: metrics['f1']\n",
        "            for field, metrics in eval_results['overall']['field_metrics'].items()\n",
        "        },\n",
        "        \"average_semantic_similarity\": eval_results['overall']['semantic_similarity']['average']\n",
        "    }\n",
        "\n",
        "    print(\"\\n=== BÁO CÁO TÓM TẮT ===\")\n",
        "    print(f\"Tỷ lệ JSON hợp lệ: {summary['json_validity_rate']:.2%}\")\n",
        "    print(\"\\nF1-score trung bình theo trường:\")\n",
        "    for field, score in summary['average_f1_scores'].items():\n",
        "        print(f\"  - {field}: {score:.4f}\")\n",
        "    print(f\"\\nĐộ tương đồng ngữ nghĩa trung bình: {summary['average_semantic_similarity']:.4f}\")"
      ],
      "metadata": {
        "id": "hknhOpDpeXcA"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nLONIRAnM0J"
      },
      "source": [
        "### Bắt đầu đánh giá"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Ps_A4ueinK6s",
        "outputId": "7de038e8-06fc-4446-e32b-adc57e3cf04e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 703
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start from zero! \n",
            "----------Start to evaluate----------\n",
            "Đã tải checkpoint, tiếp tục từ mẫu 491/2937\n",
            "----------Start to evaluate----------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<unknown>, line 5)",
          "traceback": [
            "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
            "  File \u001b[1;32m\"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3553\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \u001b[1;32m\"<ipython-input-20-a33c7f6c33a0>\"\u001b[0m, line \u001b[1;32m3\u001b[0m, in \u001b[1;35m<cell line: 0>\u001b[0m\n    results = evaluate_model(\n",
            "  File \u001b[1;32m\"<ipython-input-14-6c94b7f63876>\"\u001b[0m, line \u001b[1;32m72\u001b[0m, in \u001b[1;35mevaluate_model\u001b[0m\n    overall_result = evaluate_cookie_extraction(all_ground_truth, all_predictions)\n",
            "  File \u001b[1;32m\"<ipython-input-11-9786be185190>\"\u001b[0m, line \u001b[1;32m396\u001b[0m, in \u001b[1;35mevaluate_cookie_extraction\u001b[0m\n    validity_rate = json_validity_rate(predicted_json)\n",
            "  File \u001b[1;32m\"<ipython-input-11-9786be185190>\"\u001b[0m, line \u001b[1;32m83\u001b[0m, in \u001b[1;35mjson_validity_rate\u001b[0m\n    valid_count = sum(validate_json_format(js) for js in predicted_json_strings)\n",
            "  File \u001b[1;32m\"<ipython-input-11-9786be185190>\"\u001b[0m, line \u001b[1;32m83\u001b[0m, in \u001b[1;35m<genexpr>\u001b[0m\n    valid_count = sum(validate_json_format(js) for js in predicted_json_strings)\n",
            "  File \u001b[1;32m\"<ipython-input-11-9786be185190>\"\u001b[0m, line \u001b[1;32m67\u001b[0m, in \u001b[1;35mvalidate_json_format\u001b[0m\n    json_data = ast.literal_eval(predicted_json_str)\n",
            "  File \u001b[1;32m\"/usr/lib/python3.11/ast.py\"\u001b[0m, line \u001b[1;32m64\u001b[0m, in \u001b[1;35mliteral_eval\u001b[0m\n    node_or_string = parse(node_or_string.lstrip(\" \\t\"), mode='eval')\n",
            "\u001b[0;36m  File \u001b[0;32m\"/usr/lib/python3.11/ast.py\"\u001b[0;36m, line \u001b[0;32m50\u001b[0;36m, in \u001b[0;35mparse\u001b[0;36m\u001b[0m\n\u001b[0;31m    return compile(source, filename, mode, flags,\u001b[0m\n",
            "\u001b[0;36m  File \u001b[0;32m\"<unknown>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    ```\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "evaluate_result = evaluate_model(dataset, batch_size=4)\n",
        "\n",
        "results = evaluate_model(\n",
        "    dataset,\n",
        "    batch_size=16,\n",
        "    checkpoint_interval=32,  # Lưu sau mỗi 30 mẫu\n",
        "    checkpoint_path=\"/content/drive/MyDrive/Project/Models-v3/Qwen2.5-3B-Instruct_SFT/evaluation_checkpoint.json\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_result"
      ],
      "metadata": {
        "id": "fx3si8TZ5_Ct",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dba1aa06-a850-49d9-e1d4-c51a75ddb86f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'overall': {'json_validity_rate': 0,\n",
              "  'field_metrics': {'cookie_name': {'precision': 0.0,\n",
              "    'recall': 0.0,\n",
              "    'f1': 0.0},\n",
              "   'declared_purpose': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0},\n",
              "   'declared_retention': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0},\n",
              "   'declared_third_parties': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0},\n",
              "   'declared_description': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0}},\n",
              "  'is_specific_classification': {'accuracy': 0.0},\n",
              "  'cookie_count_metrics': {'cookie_count_accuracy': 0.0},\n",
              "  'semantic_similarity': {'declared_purpose': 0.0,\n",
              "   'declared_description': 0.0,\n",
              "   'declared_retention': 0.0,\n",
              "   'average': 0.0},\n",
              "  'overall_accuracy': 0.0}}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_evaluation_report(evaluate_result, \"/content/drive/MyDrive/Qwen2.5_(3B)-SFT/evaluation_report.json\")"
      ],
      "metadata": {
        "id": "0HqzIxok5_l-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ab5eafa-d54e-4b80-905b-3646bc11432c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Đã lưu báo cáo đánh giá tại: /content/drive/MyDrive/Qwen2.5_(3B)-SFT/evaluation_report.json\n",
            "\n",
            "=== BÁO CÁO TÓM TẮT ===\n",
            "Tỷ lệ JSON hợp lệ: 0.00%\n",
            "\n",
            "F1-score trung bình theo trường:\n",
            "  - cookie_name: 0.0000\n",
            "  - declared_purpose: 0.0000\n",
            "  - declared_retention: 0.0000\n",
            "  - declared_third_parties: 0.0000\n",
            "  - declared_description: 0.0000\n",
            "\n",
            "Độ tương đồng ngữ nghĩa trung bình: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# new_model_online = \"sonhask/Qwen2.5_3B_SFT_detect_cookies\"\n",
        "\n",
        "# model.push_to_hub(new_model_online) # Online saving\n",
        "# tokenizer.push_to_hub(new_model_online) # Online saving"
      ],
      "metadata": {
        "id": "-viRVvdel2rA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165,
          "referenced_widgets": [
            "d31aaa30c92c47f8b2f04244f80a32f3",
            "4316092229ab491f9e82e592d916776f",
            "e110982f52cd4d5dafbb22a41f49e4f8",
            "86e9934a7ce14d9a8439de6e074f51dd",
            "1fad8ece12ba434c803d9bc599c5401f",
            "d225564528014f598018ca65662ff76a",
            "ae786023db0443758a607a41bf4877e8",
            "7302d8b03f6b4f87a72b6238fa807c8d",
            "f8ebaa80a71c4af9ae2c1ac0e2a31490",
            "bfa71feb72ba428598ac49e937da647a",
            "3fa6d9115b1d45549f2451cca91ea388",
            "e120a5e74b6046cc81792e1ecbb15e19",
            "87d695ed591247b297fc7b97784ee0f5",
            "92d918fa5a104fffbb3a907b40eae6fa",
            "2498a17d724f4cf0bb50e2a14e64834c",
            "27690f6e89394d18be2dfce24cfc327c",
            "8229490dd386417ba36a49725f819943",
            "0521bb48fb5e4046bd82cbca4b43e800",
            "c592c9c636be4e8da789df15a33cab45",
            "95d3010105a74fbe985d2ac52177afad",
            "fd815345a68f4931931a5bff7477f24e",
            "f0605ae3a91d4527bc1b1cfda6b93ecd",
            "66bafc0f39b5415cb311dd9e654ae36f",
            "50e3118ed86544f9b5d5f1769dc0953a",
            "b89d9bff936a459cb55e517df6ce56fb",
            "eaf78ae368fc43d88c271413c70fc9ba",
            "8678a67177694b95b961bd5ba583932e",
            "b607baca88fe43ea8b3983c4df2396f3",
            "e1dc9311aec34f459447de118c6a9b8b",
            "bc6e61c56dc34084b2115203def966f9",
            "45cad39124834d7e8fa135e9cd526120",
            "e05fdf166dd545e6acadbeb2d13b1219",
            "33ba7a097ec24abf8afff195377fc996"
          ]
        },
        "outputId": "b5e6a8f2-6c97-4eb7-c997-3f74331dfed6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d31aaa30c92c47f8b2f04244f80a32f3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "adapter_model.safetensors:   0%|          | 0.00/120M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e120a5e74b6046cc81792e1ecbb15e19"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "66bafc0f39b5415cb311dd9e654ae36f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/sonhask/Qwen2.5_3B_SFT_detect_cookies/commit/19b025bab011c67617335afaafe8cefb89a6c0f3', commit_message='Upload tokenizer', commit_description='', oid='19b025bab011c67617335afaafe8cefb89a6c0f3', pr_url=None, repo_url=RepoUrl('https://huggingface.co/sonhask/Qwen2.5_3B_SFT_detect_cookies', endpoint='https://huggingface.co', repo_type='model', repo_id='sonhask/Qwen2.5_3B_SFT_detect_cookies'), pr_revision=None, pr_num=None)"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = \"meta-llama/meta-Llama-3.1-8B-Instruct\"\n",
        "peft_model = \"Llama_3_1_8B_GRPO_detect_cookies\"\n",
        "hub_id = \"sonhask/Llama_3_1_8B_GRPO_detect_cookies\"\n",
        "\n",
        "print(f\"[1/5] Loading base model: {base_model}\")\n",
        "base_model = FastLanguageModel.from_pretrained(\n",
        "    base_model,\n",
        "    return_dict=True,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
        "\n",
        "print(f\"[2/5] Loading adapter: {peft_model}\")\n",
        "model = PeftModel.from_pretrained(base_model, peft_model, device_map=\"auto\")\n",
        "\n",
        "print(\"[3/5] Merge base model and adapter\")\n",
        "model = model.merge_and_unload()\n",
        "\n",
        "print(f\"[4/5] Saving model and tokenizer in {hub_id}\")\n",
        "model.save_pretrained(f\"{hub_id}\")\n",
        "tokenizer.save_pretrained(f\"{hub_id}\")\n",
        "\n",
        "print(f\"[5/5] Uploading to Hugging Face Hub: {hub_id}\")\n",
        "model.push_to_hub(f\"{hub_id}\", use_temp_dir=False)\n",
        "tokenizer.push_to_hub(f\"{hub_id}\", use_temp_dir=False)\n",
        "\n",
        "print(\"Merged model uploaded to Hugging Face Hub!\")"
      ],
      "metadata": {
        "id": "6snCuRc5pwWA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "fa4b552b-aae8-4c9a-e896-91bc75b30b83"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1/5] Loading base model: meta-llama/meta-Llama-3.1-8B-Instruct\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'FastLanguageModel' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-c5d686b35182>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[1/5] Loading base model: {base_model}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m base_model = FastLanguageModel.from_pretrained(\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mbase_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'FastLanguageModel' is not defined"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "rD_-G4bHm8WZ"
      ],
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d31aaa30c92c47f8b2f04244f80a32f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4316092229ab491f9e82e592d916776f",
              "IPY_MODEL_e110982f52cd4d5dafbb22a41f49e4f8",
              "IPY_MODEL_86e9934a7ce14d9a8439de6e074f51dd"
            ],
            "layout": "IPY_MODEL_1fad8ece12ba434c803d9bc599c5401f"
          }
        },
        "4316092229ab491f9e82e592d916776f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d225564528014f598018ca65662ff76a",
            "placeholder": "​",
            "style": "IPY_MODEL_ae786023db0443758a607a41bf4877e8",
            "value": "README.md: 100%"
          }
        },
        "e110982f52cd4d5dafbb22a41f49e4f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7302d8b03f6b4f87a72b6238fa807c8d",
            "max": 5174,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f8ebaa80a71c4af9ae2c1ac0e2a31490",
            "value": 5174
          }
        },
        "86e9934a7ce14d9a8439de6e074f51dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfa71feb72ba428598ac49e937da647a",
            "placeholder": "​",
            "style": "IPY_MODEL_3fa6d9115b1d45549f2451cca91ea388",
            "value": " 5.17k/5.17k [00:00&lt;00:00, 215kB/s]"
          }
        },
        "1fad8ece12ba434c803d9bc599c5401f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d225564528014f598018ca65662ff76a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae786023db0443758a607a41bf4877e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7302d8b03f6b4f87a72b6238fa807c8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8ebaa80a71c4af9ae2c1ac0e2a31490": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bfa71feb72ba428598ac49e937da647a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fa6d9115b1d45549f2451cca91ea388": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e120a5e74b6046cc81792e1ecbb15e19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_87d695ed591247b297fc7b97784ee0f5",
              "IPY_MODEL_92d918fa5a104fffbb3a907b40eae6fa",
              "IPY_MODEL_2498a17d724f4cf0bb50e2a14e64834c"
            ],
            "layout": "IPY_MODEL_27690f6e89394d18be2dfce24cfc327c"
          }
        },
        "87d695ed591247b297fc7b97784ee0f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8229490dd386417ba36a49725f819943",
            "placeholder": "​",
            "style": "IPY_MODEL_0521bb48fb5e4046bd82cbca4b43e800",
            "value": "adapter_model.safetensors: 100%"
          }
        },
        "92d918fa5a104fffbb3a907b40eae6fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c592c9c636be4e8da789df15a33cab45",
            "max": 119801528,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_95d3010105a74fbe985d2ac52177afad",
            "value": 119801528
          }
        },
        "2498a17d724f4cf0bb50e2a14e64834c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd815345a68f4931931a5bff7477f24e",
            "placeholder": "​",
            "style": "IPY_MODEL_f0605ae3a91d4527bc1b1cfda6b93ecd",
            "value": " 120M/120M [00:09&lt;00:00, 8.73MB/s]"
          }
        },
        "27690f6e89394d18be2dfce24cfc327c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8229490dd386417ba36a49725f819943": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0521bb48fb5e4046bd82cbca4b43e800": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c592c9c636be4e8da789df15a33cab45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95d3010105a74fbe985d2ac52177afad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fd815345a68f4931931a5bff7477f24e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0605ae3a91d4527bc1b1cfda6b93ecd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66bafc0f39b5415cb311dd9e654ae36f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_50e3118ed86544f9b5d5f1769dc0953a",
              "IPY_MODEL_b89d9bff936a459cb55e517df6ce56fb",
              "IPY_MODEL_eaf78ae368fc43d88c271413c70fc9ba"
            ],
            "layout": "IPY_MODEL_8678a67177694b95b961bd5ba583932e"
          }
        },
        "50e3118ed86544f9b5d5f1769dc0953a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b607baca88fe43ea8b3983c4df2396f3",
            "placeholder": "​",
            "style": "IPY_MODEL_e1dc9311aec34f459447de118c6a9b8b",
            "value": "tokenizer.json: 100%"
          }
        },
        "b89d9bff936a459cb55e517df6ce56fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc6e61c56dc34084b2115203def966f9",
            "max": 11421995,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_45cad39124834d7e8fa135e9cd526120",
            "value": 11421995
          }
        },
        "eaf78ae368fc43d88c271413c70fc9ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e05fdf166dd545e6acadbeb2d13b1219",
            "placeholder": "​",
            "style": "IPY_MODEL_33ba7a097ec24abf8afff195377fc996",
            "value": " 11.4M/11.4M [00:00&lt;00:00, 12.7MB/s]"
          }
        },
        "8678a67177694b95b961bd5ba583932e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b607baca88fe43ea8b3983c4df2396f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1dc9311aec34f459447de118c6a9b8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc6e61c56dc34084b2115203def966f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45cad39124834d7e8fa135e9cd526120": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e05fdf166dd545e6acadbeb2d13b1219": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33ba7a097ec24abf8afff195377fc996": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
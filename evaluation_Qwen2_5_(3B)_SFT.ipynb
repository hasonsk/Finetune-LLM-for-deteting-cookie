{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SspUhKDMBZQC",
        "outputId": "2ecf3e8c-7b27-42d1-ec56-b71cd8753e3c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "import os\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth\n",
        "else:\n",
        "    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
        "    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl==0.15.2 triton cut_cross_entropy unsloth_zoo\n",
        "    !pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n",
        "    !pip install --no-deps unsloth\n",
        "    !pip install datasets"
      ],
      "metadata": {
        "id": "uUi6Kr8nR8lo"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nJpdaREcvPG-",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -U bitsandbytes\n",
        "!pip install datasets\n",
        "!pip install transformers==4.41.2 accelerate==0.32.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seBAyPabUix6"
      },
      "source": [
        "# Load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nYYiye50iAJ2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from huggingface_hub import login\n",
        "\n",
        "os.environ[\"HUGGINGFACE_API_KEY\"] = \"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\"\n",
        "\n",
        "hf_token = os.environ[\"HUGGINGFACE_API_KEY\"]\n",
        "login(hf_token)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from datasets import Dataset, load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from tqdm import tqdm\n",
        "from typing import List, Dict, Any\n",
        "from peft import PeftModel, PeftConfig"
      ],
      "metadata": {
        "id": "U3aKJ3q_keqq",
        "outputId": "069e8942-02ad-4c61-d6b7-1417c40c987b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-0ffa3a9e4227>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m     ) from _err\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m from pandas._config import (\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mget_option\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mset_option\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/_config/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;34m\"warn_copy_on_write\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m ]\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdates\u001b[0m  \u001b[0;31m# pyright: ignore[reportUnusedImport]  # noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m from pandas._config.config import (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/_config/config.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m from pandas._typing import (\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/_typing.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBitGenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mpublic_symbols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'testing'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         public_symbols -= {\n\u001b[1;32m    339\u001b[0m             \u001b[0;34m\"core\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"matrixlib\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/random/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;31m# add these for module-freeze analysis (like PyInstaller)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_common\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_bounded_integers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/random/_pickle.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmtrand\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomState\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_philox\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPhilox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_pcg64\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPCG64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPCG64DXSM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_sfc64\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSFC64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mnumpy/random/mtrand.pyx\u001b[0m in \u001b[0;36minit numpy.random.mtrand\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "EC3GY-Z1UkXL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599,
          "referenced_widgets": [
            "cd089b930f4a4315a539cc91df2827a7",
            "024802e6739e45cabcb36b986c91077a",
            "2f9a2eb93d5a4e059b42330099306384",
            "5dad066cc122478781a8143b66a1d268",
            "b14775ab311045b99a4ec447353720a7",
            "5d785a133f0f4718aab6ee8d9f4f0de1",
            "af1b671e9eda45f7b0b0b7aa9fa7b672",
            "340adc350ce646639ce8fcaf8888c50a",
            "3cffcc45b8344fef820e705b740f5dc1",
            "bf97b761a9674466a7119545502e57c6",
            "bb59a6c6cebe44489a565d379cd0dbb0"
          ]
        },
        "outputId": "8a5088d2-6a26-41c5-a586-756d619f1d8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd089b930f4a4315a539cc91df2827a7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'EncoderDecoderCache' from 'transformers' (/usr/local/lib/python3.11/dist-packages/transformers/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-8f4ce64489b0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpeft\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPeftConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Đường dẫn đến thư mục chứa mô hình đã fine-tune\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/peft/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"0.15.2\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m from .auto import (\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mMODEL_TYPE_TO_PEFT_MODEL_MAPPING\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mAutoPeftModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/peft/auto.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPeftConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m from .peft_model import (\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mPeftModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mPeftModelForCausalLM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msafetensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave_file\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msafe_save_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBCEWithLogitsLoss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMSELoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDynamicCache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEncoderDecoderCache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPreTrainedModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodeling_outputs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mQuestionAnsweringModelOutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequenceClassifierOutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTokenClassifierOutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPushToHubMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'EncoderDecoderCache' from 'transformers' (/usr/local/lib/python3.11/dist-packages/transformers/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "# Đường dẫn đến thư mục chứa mô hình đã fine-tune\n",
        "model_path = \"/content/drive/MyDrive/Project/Qwen2.5-3B-Instruct/checkpoint-584\"\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Sử dụng device: {device}\")\n",
        "\n",
        "try:\n",
        "    # Nếu đây là mô hình adapter (PEFT/LoRA)\n",
        "    config = PeftConfig.from_pretrained(model_path)\n",
        "    print(f\"Đang tải mô hình PEFT với base model: {config.base_model_name_or_path}\")\n",
        "\n",
        "    # Tải mô hình cơ sở\n",
        "    base_model = AutoModelForCausalLM.from_pretrained(\n",
        "        config.base_model_name_or_path,\n",
        "        device_map=\"auto\"\n",
        "    )\n",
        "\n",
        "    # Tải mô hình adapter\n",
        "    model = PeftModel.from_pretrained(base_model, model_path)\n",
        "\n",
        "except:\n",
        "    # Nếu đây là mô hình đầy đủ (không phải adapter)\n",
        "    print(\"Không phải mô hình PEFT/adapter, đang tải mô hình đầy đủ...\")\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_path, device_map=\"auto\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZwsSbB1htCC"
      },
      "outputs": [],
      "source": [
        "alpaca_prompt = \"\"\"\n",
        "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
        "Your task is read a cookie policy text and extract detailed information about each cookie mentioned in that policy.\n",
        "RESPONSE Format: JSON following structure:\n",
        "\n",
        "{{\n",
        "  \"is_specific\": 0,\n",
        "  \"cookies\": [\n",
        "     {{\n",
        "      \"cookie_name\": \"cookie_name\",\n",
        "      \"declared_purpose\": \"declared_purpose\",\n",
        "      \"declared_retention\": \"declared_retention\",\n",
        "      \"declared_third_parties\": [\"declared_third_parties\"],\n",
        "      \"declared_description\": \"declared_description\"\n",
        "    }}, ...\n",
        "  ]\n",
        "}}\n",
        "If no cookies are specifically described, only response {{\"is_specific\": 0, \"cookies\": []}}\n",
        "\n",
        "### Instruction:\n",
        "{}\n",
        "\n",
        "### Input:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{{\n",
        "  \"is_specific\": {},\n",
        "  \"cookies\": {}\n",
        "}}\"\"\"\n",
        "\n",
        "SYSTEM_PROMPT = \"\"\"\n",
        "Extraction guidelines:\n",
        "For \"is_specific\": Determines if the website provides detailed descriptions of individual cookies:\n",
        "- Set to 0 if cookies are only described generically (e.g., \"performance cookies,\" \"necessary cookies,\" \"Google cookies\") without specific explanations\n",
        "- Set to 1 if cookies are described with specific names, purposes, retention periods, and third parties. Example: \"The '_ga' cookie is used by Google Analytics to distinguish users and is stored for 2 years\" would result in is_specific = 1\n",
        "\n",
        "For the \"cookies\" list containing objects, each object has\n",
        "- \"cookie_name\": Extract the exact technical name as mentioned. One object just has only one cookie name, ìf more one, create multiple objects. For example: ga, _gid, _gat --> 3 object cookies\n",
        "- \"declared_purpose\": cookie's purpose. With the following options:\n",
        "  * Strictly Necessary: Essential for basic website functionality\n",
        "  * Functionality: Personalizes user experience\n",
        "  * Analytical: Collects usage data\n",
        "  * Targeting/Advertising/Marketing: For personalized ads\n",
        "  * Performance: Improves technical performance\n",
        "  * Social Sharing: Enables social media integration\n",
        "  * Null: When no specific purpose information is provided\n",
        "- \"declared_retention\": Record the exact storage duration as mentioned\n",
        "- \"declared_third_parties\": An list of third parties involved in the use of this cookie for website-owned cookies\n",
        "- \"declared_description\": exact wording from the policy without modification or embellishment\"\"\"\n",
        "\n",
        "\n",
        "EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
        "def formatting_prompts_func(example):\n",
        "    if example['english_content']:\n",
        "        content = f\"Cookie policy: {example['english_content']}\\nTable: {example['english_table']}\"\n",
        "    elif example['english_table']:\n",
        "        content = f\"Table: {example['english_table']}\"\n",
        "    else:\n",
        "        content = f\"Content: {example['english_table']}\"\n",
        "\n",
        "    instruction = SYSTEM_PROMPT\n",
        "    input       = content\n",
        "    is_specific = example['is_specific']\n",
        "    cookies     = example['extracted_cookies']\n",
        "\n",
        "    text = alpaca_prompt.format(instruction, input, is_specific, cookies) + EOS_TOKEN\n",
        "    return { \"text\" : text, }\n",
        "\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"sonhask/Extract_cookies_from_cookie_policy_specific\", split = \"test\")\n",
        "dataset = dataset.map(formatting_prompts_func)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4TlfpGqLiTV_"
      },
      "outputs": [],
      "source": [
        "def thong_ke(dataset):\n",
        "    empty_label_count = 0\n",
        "    non_empty_label_count = 0\n",
        "\n",
        "    for i in dataset:\n",
        "        if i['label'] == '[]':\n",
        "            empty_label_count += 1\n",
        "        else:\n",
        "            non_empty_label_count += 1\n",
        "\n",
        "    print(\"#[]: \", empty_label_count)\n",
        "    print(\"#Has cookies: \", non_empty_label_count)\n",
        "\n",
        "thong_ke(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4d3q9cBikRH"
      },
      "outputs": [],
      "source": [
        "from datasets import concatenate_datasets\n",
        "\n",
        "has_no_cookie = \"[]\"\n",
        "\n",
        "empty_label_dataset = dataset.filter(lambda example: example['label'] == has_no_cookie)\n",
        "non_empty_label_dataset = dataset.filter(lambda example: example['label'] != has_no_cookie)\n",
        "\n",
        "# Downsample the non-empty dataset to the size of the empty dataset\n",
        "n_samples = len(non_empty_label_dataset)\n",
        "print(\"N samples: \", n_samples)\n",
        "downsampled_empty_dataset = empty_label_dataset.shuffle(seed=42).select(range(n_samples))\n",
        "\n",
        "# Gộp 2 dataset\n",
        "combined_dataset = concatenate_datasets([non_empty_label_dataset, downsampled_empty_dataset])\n",
        "\n",
        "# Shuffle dataset\n",
        "balanced_dataset = combined_dataset.shuffle(seed=42)\n",
        "\n",
        "# Verify the balanced dataset statistics\n",
        "thong_ke(balanced_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGbn9I8DiWEc"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.remove_columns(['url', 'lang', 'original_text', 'tables', 'processed_text', 'english_content', 'english_table', 'translated_tables', '__index_level_0__', 'label'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TqevtGN4fhC0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3o9Gpmguilrd"
      },
      "outputs": [],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD_-G4bHm8WZ"
      },
      "source": [
        "### Hàm đánh giá mô hình"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZVSzDY3m07u"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import jsonschema\n",
        "import numpy as np\n",
        "from typing import List, Dict, Any, Union, Tuple\n",
        "from collections import defaultdict\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import sklearn.metrics.pairwise as pairwise\n",
        "import re\n",
        "\n",
        "# Schema cho dữ liệu cookie\n",
        "COOKIE_SCHEMA = {\n",
        "    \"type\": \"array\",\n",
        "    \"items\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"cookie_name\": {\"type\": \"string\"},\n",
        "            \"declared_purpose\": {\"type\": [\"string\", \"null\"]},\n",
        "            \"declared_retention\": {\"type\": [\"string\", \"null\"]},\n",
        "            \"declared_third_parties\": {\"type\": \"array\"},\n",
        "            \"declared_description\": {\"type\": [\"string\", \"null\"]}\n",
        "        },\n",
        "        \"required\": [\"cookie_name\"]\n",
        "    }\n",
        "}\n",
        "\n",
        "# 1. JSON Validity\n",
        "def validate_json_format(predicted_json_str: str) -> bool:\n",
        "    \"\"\"\n",
        "    Kiểm tra xem chuỗi JSON có hợp lệ hay không\n",
        "\n",
        "    Args:\n",
        "        predicted_json_str: Chuỗi JSON cần kiểm tra\n",
        "\n",
        "    Returns:\n",
        "        bool: True nếu JSON hợp lệ, False nếu không\n",
        "    \"\"\"\n",
        "    try:\n",
        "        json_data = json.loads(predicted_json_str)\n",
        "        jsonschema.validate(instance=json_data, schema=COOKIE_SCHEMA)\n",
        "        return True\n",
        "    except (json.JSONDecodeError, jsonschema.exceptions.ValidationError):\n",
        "        return False\n",
        "\n",
        "def json_validity_rate(predicted_json_strings: List[str]) -> float:\n",
        "    \"\"\"\n",
        "    Tính tỷ lệ các chuỗi JSON hợp lệ theo schema đã định nghĩa\n",
        "\n",
        "    Args:\n",
        "        predicted_json_strings: Danh sách các chuỗi JSON dự đoán từ mô hình\n",
        "\n",
        "    Returns:\n",
        "        float: Tỷ lệ hợp lệ (0-1)\n",
        "    \"\"\"\n",
        "    valid_count = sum(validate_json_format(js) for js in predicted_json_strings)\n",
        "    return valid_count / len(predicted_json_strings) if predicted_json_strings else 0\n",
        "\n",
        "# 2. Precision, Recall, F1-score cho từng trường\n",
        "def normalize_text(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Chuẩn hóa văn bản để so sánh\n",
        "\n",
        "    Args:\n",
        "        text: Văn bản cần chuẩn hóa\n",
        "\n",
        "    Returns:\n",
        "        str: Văn bản đã được chuẩn hóa\n",
        "    \"\"\"\n",
        "    if text is None:\n",
        "        return \"\"\n",
        "    return re.sub(r'\\s+', ' ', text.lower().strip())\n",
        "\n",
        "def extract_valid_cookies(json_strings: List[str]) -> List[List[Dict]]:\n",
        "    \"\"\"\n",
        "    Trích xuất danh sách cookie từ các chuỗi JSON và chỉ giữ lại các JSON hợp lệ\n",
        "\n",
        "    Args:\n",
        "        json_strings: Danh sách các chuỗi JSON\n",
        "\n",
        "    Returns:\n",
        "        List[List[Dict]]: Danh sách các danh sách cookie (chỉ các JSON hợp lệ)\n",
        "    \"\"\"\n",
        "    result = []\n",
        "    for js in json_strings:\n",
        "        try:\n",
        "            data = json.loads(js)\n",
        "            jsonschema.validate(instance=data, schema=COOKIE_SCHEMA)\n",
        "            result.append(data)\n",
        "        except (json.JSONDecodeError, jsonschema.exceptions.ValidationError):\n",
        "            pass\n",
        "    return result\n",
        "\n",
        "def exact_match_metrics(ground_truth: List[Dict], predictions: List[Dict], field: str) -> Tuple[float, float, float]:\n",
        "    \"\"\"\n",
        "    Tính precision, recall, F1 cho việc so khớp chính xác một trường\n",
        "\n",
        "    Args:\n",
        "        ground_truth: Danh sách cookie chuẩn\n",
        "        predictions: Danh sách cookie dự đoán\n",
        "        field: Tên trường cần đánh giá\n",
        "\n",
        "    Returns:\n",
        "        Tuple[float, float, float]: (precision, recall, F1-score)\n",
        "    \"\"\"\n",
        "    # Tạo ánh xạ từ cookie_name sang giá trị trường cần đánh giá\n",
        "    gt_map = {item[\"cookie_name\"]: item.get(field) for item in ground_truth if \"cookie_name\" in item}\n",
        "    pred_map = {item[\"cookie_name\"]: item.get(field) for item in predictions if \"cookie_name\" in item}\n",
        "\n",
        "    # Xử lý trường hợp đặc biệt cho declared_third_parties là mảng\n",
        "    if field == \"declared_third_parties\":\n",
        "        # Chuyển thành set để so sánh không phụ thuộc thứ tự\n",
        "        gt_map = {k: set(v) if v is not None else set() for k, v in gt_map.items()}\n",
        "        pred_map = {k: set(v) if v is not None else set() for k, v in pred_map.items()}\n",
        "    else:\n",
        "        # Chuẩn hóa dữ liệu văn bản\n",
        "        gt_map = {k: normalize_text(v) for k, v in gt_map.items()}\n",
        "        pred_map = {k: normalize_text(v) for k, v in pred_map.items()}\n",
        "\n",
        "    # Đếm các trường hợp True Positive, False Positive, False Negative\n",
        "    tp = 0\n",
        "    for cookie_name in set(gt_map.keys()) & set(pred_map.keys()):\n",
        "        if field == \"declared_third_parties\":\n",
        "            if gt_map[cookie_name] == pred_map[cookie_name]:\n",
        "                tp += 1\n",
        "        else:\n",
        "            if gt_map[cookie_name] == pred_map[cookie_name]:\n",
        "                tp += 1\n",
        "\n",
        "    fp = len(set(pred_map.keys()) - set(gt_map.keys()))\n",
        "    fn = len(set(gt_map.keys()) - set(pred_map.keys()))\n",
        "\n",
        "    # Tính precision, recall, F1\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "    return precision, recall, f1\n",
        "\n",
        "def evaluate_field_metrics(ground_truth_json: List[str], predicted_json: List[str]) -> Dict[str, Dict[str, float]]:\n",
        "    \"\"\"\n",
        "    Đánh giá metrics cho tất cả các trường\n",
        "\n",
        "    Args:\n",
        "        ground_truth_json: Danh sách chuỗi JSON chuẩn\n",
        "        predicted_json: Danh sách chuỗi JSON dự đoán\n",
        "\n",
        "    Returns:\n",
        "        Dict: Kết quả metrics cho từng trường\n",
        "    \"\"\"\n",
        "    # Chỉ lấy các JSON hợp lệ\n",
        "    valid_gt = []\n",
        "    for js in ground_truth_json:\n",
        "        try:\n",
        "            data = json.loads(js)\n",
        "            jsonschema.validate(instance=data, schema=COOKIE_SCHEMA)\n",
        "            valid_gt.extend(data)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    valid_pred = []\n",
        "    for js in predicted_json:\n",
        "        try:\n",
        "            data = json.loads(js)\n",
        "            jsonschema.validate(instance=data, schema=COOKIE_SCHEMA)\n",
        "            valid_pred.extend(data)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    fields = [\"cookie_name\", \"declared_purpose\", \"declared_retention\",\n",
        "              \"declared_third_parties\", \"declared_description\"]\n",
        "\n",
        "    results = {}\n",
        "    for field in fields:\n",
        "        precision, recall, f1 = exact_match_metrics(valid_gt, valid_pred, field)\n",
        "        results[field] = {\n",
        "            \"precision\": precision,\n",
        "            \"recall\": recall,\n",
        "            \"f1\": f1\n",
        "        }\n",
        "\n",
        "    return results\n",
        "\n",
        "# 3. Semantic Similarity\n",
        "def load_sentence_transformer():\n",
        "    \"\"\"Tải mô hình sentence transformer\"\"\"\n",
        "    try:\n",
        "        return SentenceTransformer('all-MiniLM-L6-v2')\n",
        "    except:\n",
        "        print(\"Cần cài đặt sentence-transformers: pip install sentence-transformers\")\n",
        "        return None\n",
        "\n",
        "def compute_semantic_similarity(ground_truth: List[Dict], predictions: List[Dict],\n",
        "                               field: str, model) -> float:\n",
        "    \"\"\"\n",
        "    Tính toán độ tương đồng ngữ nghĩa cho một trường\n",
        "\n",
        "    Args:\n",
        "        ground_truth: Danh sách cookie chuẩn\n",
        "        predictions: Danh sách cookie dự đoán\n",
        "        field: Tên trường cần đánh giá\n",
        "        model: Mô hình sentence transformer\n",
        "\n",
        "    Returns:\n",
        "        float: Điểm tương đồng ngữ nghĩa trung bình\n",
        "    \"\"\"\n",
        "    if model is None:\n",
        "        return 0.0\n",
        "\n",
        "    # Tạo ánh xạ từ cookie_name sang giá trị trường cần đánh giá\n",
        "    gt_map = {item[\"cookie_name\"]: item.get(field, \"\") for item in ground_truth if \"cookie_name\" in item}\n",
        "    pred_map = {item[\"cookie_name\"]: item.get(field, \"\") for item in predictions if \"cookie_name\" in item}\n",
        "\n",
        "    # Chỉ so sánh các cookie cùng tên\n",
        "    common_names = set(gt_map.keys()) & set(pred_map.keys())\n",
        "\n",
        "    if not common_names or field == \"declared_third_parties\":  # Không áp dụng semantic similarity cho mảng\n",
        "        return 0.0\n",
        "\n",
        "    similarities = []\n",
        "    for name in common_names:\n",
        "        gt_text = gt_map[name]\n",
        "        pred_text = pred_map[name]\n",
        "\n",
        "        # Bỏ qua các trường rỗng hoặc None\n",
        "        if not gt_text or not pred_text or gt_text is None or pred_text is None:\n",
        "            continue\n",
        "\n",
        "        # Mã hóa văn bản thành vector\n",
        "        gt_embedding = model.encode(str(gt_text))\n",
        "        pred_embedding = model.encode(str(pred_text))\n",
        "\n",
        "        # Tính cosine similarity\n",
        "        similarity = pairwise.cosine_similarity([gt_embedding], [pred_embedding])[0][0]\n",
        "        similarities.append(similarity)\n",
        "\n",
        "    # Tính điểm trung bình\n",
        "    return float(np.mean(similarities)) if similarities else 0.0\n",
        "\n",
        "def evaluate_semantic_similarity(ground_truth_json: List[str], predicted_json: List[str]) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Đánh giá độ tương đồng ngữ nghĩa cho các trường văn bản\n",
        "\n",
        "    Args:\n",
        "        ground_truth_json: Danh sách chuỗi JSON chuẩn\n",
        "        predicted_json: Danh sách chuỗi JSON dự đoán\n",
        "\n",
        "    Returns:\n",
        "        Dict: Kết quả semantic similarity cho từng trường\n",
        "    \"\"\"\n",
        "    # Tải mô hình sentence transformer\n",
        "    model = load_sentence_transformer()\n",
        "\n",
        "    # Chỉ lấy các JSON hợp lệ\n",
        "    valid_gt = []\n",
        "    for js in ground_truth_json:\n",
        "        try:\n",
        "            data = json.loads(js)\n",
        "            jsonschema.validate(instance=data, schema=COOKIE_SCHEMA)\n",
        "            valid_gt.extend(data)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    valid_pred = []\n",
        "    for js in predicted_json:\n",
        "        try:\n",
        "            data = json.loads(js)\n",
        "            jsonschema.validate(instance=data, schema=COOKIE_SCHEMA)\n",
        "            valid_pred.extend(data)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    # Các trường văn bản cần đánh giá semantic similarity\n",
        "    text_fields = [\"declared_purpose\", \"declared_description\", \"declared_retention\"]\n",
        "\n",
        "    results = {}\n",
        "    for field in text_fields:\n",
        "        similarity = compute_semantic_similarity(valid_gt, valid_pred, field, model)\n",
        "        results[field] = similarity\n",
        "\n",
        "    # Tính điểm trung bình\n",
        "    results[\"average\"] = float(np.mean(list(results.values()))) if results else 0.0\n",
        "\n",
        "    return results\n",
        "\n",
        "# Hàm tổng hợp tất cả các metrics\n",
        "def evaluate_cookie_extraction(ground_truth_json: List[str], predicted_json: List[str]) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Đánh giá toàn diện việc trích xuất cookie\n",
        "\n",
        "    Args:\n",
        "        ground_truth_json: Danh sách chuỗi JSON chuẩn\n",
        "        predicted_json: Danh sách chuỗi JSON dự đoán\n",
        "\n",
        "    Returns:\n",
        "        Dict: Kết quả tất cả các metrics\n",
        "    \"\"\"\n",
        "    # 1. JSON Validity\n",
        "    validity_rate = json_validity_rate(predicted_json)\n",
        "\n",
        "    # 2. Field metrics (precision, recall, F1)\n",
        "    field_metrics = evaluate_field_metrics(ground_truth_json, predicted_json)\n",
        "\n",
        "    # 3. Semantic similarity\n",
        "    semantic_metrics = evaluate_semantic_similarity(ground_truth_json, predicted_json)\n",
        "\n",
        "    # Tổng hợp kết quả\n",
        "    results = {\n",
        "        \"json_validity_rate\": validity_rate,\n",
        "        \"field_metrics\": field_metrics,\n",
        "        \"semantic_similarity\": semantic_metrics\n",
        "    }\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yi7JsK5Zdcd1"
      },
      "source": [
        "### Hàm đánh giá mô hình với is_sperific"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTkEzRZqdcd2"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import jsonschema\n",
        "import numpy as np\n",
        "from typing import List, Dict, Any, Union, Tuple\n",
        "from collections import defaultdict\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import sklearn.metrics.pairwise as pairwise\n",
        "import re\n",
        "\n",
        "# Schema cho dữ liệu cookie đã cập nhật\n",
        "COOKIE_SCHEMA = {\n",
        "    \"type\": \"object\",\n",
        "    \"required\": [\"is_specific\", \"cookies\"],\n",
        "    \"properties\": {\n",
        "        \"is_specific\": {\n",
        "            \"type\": \"integer\",\n",
        "            \"enum\": [0, 1],\n",
        "        },\n",
        "        \"cookies\": {\n",
        "            \"type\": \"array\",\n",
        "            \"items\": {\n",
        "                \"type\": \"object\",\n",
        "                \"required\": [\n",
        "                    \"cookie_name\",\n",
        "                    \"declared_purpose\",\n",
        "                    \"declared_retention\",\n",
        "                    \"declared_third_parties\",\n",
        "                    \"declared_description\"\n",
        "                ],\n",
        "                \"properties\": {\n",
        "                    \"cookie_name\": {\n",
        "                        \"type\": \"string\",\n",
        "                    },\n",
        "                    \"declared_purpose\": {\n",
        "                        \"type\": \"string\",\n",
        "                    },\n",
        "                    \"declared_retention\": {\n",
        "                        \"type\": [\"string\", \"null\"],\n",
        "                    },\n",
        "                    \"declared_third_parties\": {\n",
        "                        \"type\": \"array\",\n",
        "                        \"items\": {\n",
        "                            \"type\": \"string\"\n",
        "                        },\n",
        "                    },\n",
        "                    \"declared_description\": {\n",
        "                        \"type\": [\"string\", \"null\"],\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# 1. JSON Validity\n",
        "def validate_json_format(predicted_json_str: str) -> bool:\n",
        "    \"\"\"\n",
        "    Kiểm tra xem chuỗi JSON có hợp lệ theo schema mới hay không\n",
        "\n",
        "    Args:\n",
        "        predicted_json_str: Chuỗi JSON cần kiểm tra\n",
        "\n",
        "    Returns:\n",
        "        bool: True nếu JSON hợp lệ, False nếu không\n",
        "    \"\"\"\n",
        "    try:\n",
        "        json_data = json.loads(predicted_json_str)\n",
        "        jsonschema.validate(instance=json_data, schema=COOKIE_SCHEMA)\n",
        "        return True\n",
        "    except (json.JSONDecodeError, jsonschema.exceptions.ValidationError):\n",
        "        return False\n",
        "\n",
        "def json_validity_rate(predicted_json_strings: List[str]) -> float:\n",
        "    \"\"\"\n",
        "    Tính tỷ lệ các chuỗi JSON hợp lệ theo schema đã định nghĩa\n",
        "\n",
        "    Args:\n",
        "        predicted_json_strings: Danh sách các chuỗi JSON dự đoán từ mô hình\n",
        "\n",
        "    Returns:\n",
        "        float: Tỷ lệ hợp lệ (0-1)\n",
        "    \"\"\"\n",
        "    valid_count = sum(validate_json_format(js) for js in predicted_json_strings)\n",
        "    return valid_count / len(predicted_json_strings) if predicted_json_strings else 0\n",
        "\n",
        "# 2. Precision, Recall, F1-score cho từng trường\n",
        "def normalize_text(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Chuẩn hóa văn bản để so sánh\n",
        "\n",
        "    Args:\n",
        "        text: Văn bản cần chuẩn hóa\n",
        "\n",
        "    Returns:\n",
        "        str: Văn bản đã được chuẩn hóa\n",
        "    \"\"\"\n",
        "    if text is None:\n",
        "        return \"\"\n",
        "    return re.sub(r'\\s+', ' ', text.lower().strip())\n",
        "\n",
        "def extract_valid_cookies(json_strings: List[str]) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Trích xuất dữ liệu từ các chuỗi JSON và chỉ giữ lại các JSON hợp lệ\n",
        "\n",
        "    Args:\n",
        "        json_strings: Danh sách các chuỗi JSON\n",
        "\n",
        "    Returns:\n",
        "        List[Dict]: Danh sách các đối tượng JSON hợp lệ\n",
        "    \"\"\"\n",
        "    result = []\n",
        "    for js in json_strings:\n",
        "        try:\n",
        "            data = json.loads(js)\n",
        "            jsonschema.validate(instance=data, schema=COOKIE_SCHEMA)\n",
        "            result.append(data)\n",
        "        except (json.JSONDecodeError, jsonschema.exceptions.ValidationError):\n",
        "            pass\n",
        "    return result\n",
        "\n",
        "def exact_match_metrics(ground_truth: List[Dict], predictions: List[Dict], field: str) -> Tuple[float, float, float]:\n",
        "    \"\"\"\n",
        "    Tính precision, recall, F1 cho việc so khớp chính xác một trường trong cookies\n",
        "\n",
        "    Args:\n",
        "        ground_truth: Danh sách đối tượng JSON chuẩn\n",
        "        predictions: Danh sách đối tượng JSON dự đoán\n",
        "        field: Tên trường cần đánh giá\n",
        "\n",
        "    Returns:\n",
        "        Tuple[float, float, float]: (precision, recall, F1-score)\n",
        "    \"\"\"\n",
        "    # Tạo ánh xạ từ cookie_name sang giá trị trường cần đánh giá\n",
        "    gt_cookies = []\n",
        "    for doc in ground_truth:\n",
        "        gt_cookies.extend(doc.get(\"cookies\", []))\n",
        "\n",
        "    pred_cookies = []\n",
        "    for doc in predictions:\n",
        "        pred_cookies.extend(doc.get(\"cookies\", []))\n",
        "\n",
        "    gt_map = {item[\"cookie_name\"]: item.get(field) for item in gt_cookies if \"cookie_name\" in item}\n",
        "    pred_map = {item[\"cookie_name\"]: item.get(field) for item in pred_cookies if \"cookie_name\" in item}\n",
        "\n",
        "    # Xử lý trường hợp đặc biệt cho declared_third_parties là mảng\n",
        "    if field == \"declared_third_parties\":\n",
        "        # Chuyển thành set để so sánh không phụ thuộc thứ tự\n",
        "        gt_map = {k: set(v) if v is not None else set() for k, v in gt_map.items()}\n",
        "        pred_map = {k: set(v) if v is not None else set() for k, v in pred_map.items()}\n",
        "    else:\n",
        "        # Chuẩn hóa dữ liệu văn bản\n",
        "        gt_map = {k: normalize_text(v) for k, v in gt_map.items()}\n",
        "        pred_map = {k: normalize_text(v) for k, v in pred_map.items()}\n",
        "\n",
        "    # Đếm số lượng predicted cookies và ground truth cookies\n",
        "    total_gt = len(gt_map)\n",
        "    total_pred = len(pred_map)\n",
        "\n",
        "    # Đếm các trường hợp True Positive\n",
        "    tp = 0\n",
        "    for cookie_name in set(gt_map.keys()) & set(pred_map.keys()):\n",
        "        if field == \"declared_third_parties\":\n",
        "            if gt_map[cookie_name] == pred_map[cookie_name]:\n",
        "                tp += 1\n",
        "        else:\n",
        "            if gt_map[cookie_name] == pred_map[cookie_name]:\n",
        "                tp += 1\n",
        "\n",
        "    # Tính precision, recall, F1\n",
        "    precision = tp / total_pred if total_pred > 0 else 0\n",
        "    recall = tp / total_gt if total_gt > 0 else 0\n",
        "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "    return precision, recall, f1\n",
        "\n",
        "def evaluate_is_specific_classification(ground_truth_json: List[str], predicted_json: List[str]) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Đánh giá accuracy cho việc phân loại is_specific\n",
        "\n",
        "    Args:\n",
        "        ground_truth_json: Danh sách chuỗi JSON chuẩn\n",
        "        predicted_json: Danh sách chuỗi JSON dự đoán\n",
        "\n",
        "    Returns:\n",
        "        Dict: Kết quả accuracy cho is_specific\n",
        "    \"\"\"\n",
        "    valid_gt = extract_valid_cookies(ground_truth_json)\n",
        "    valid_pred = extract_valid_cookies(predicted_json)\n",
        "\n",
        "    if not valid_gt or not valid_pred:\n",
        "        return {\"accuracy\": 0.0}\n",
        "\n",
        "    correct = 0\n",
        "    total = min(len(valid_gt), len(valid_pred))\n",
        "\n",
        "    for i in range(total):\n",
        "        if valid_gt[i].get(\"is_specific\") == valid_pred[i].get(\"is_specific\"):\n",
        "            correct += 1\n",
        "\n",
        "    accuracy = correct / total if total > 0 else 0\n",
        "\n",
        "    return {\"accuracy\": accuracy}\n",
        "\n",
        "def evaluate_field_metrics(ground_truth_json: List[str], predicted_json: List[str]) -> Dict[str, Dict[str, float]]:\n",
        "    \"\"\"\n",
        "    Đánh giá metrics cho tất cả các trường trong cookies\n",
        "\n",
        "    Args:\n",
        "        ground_truth_json: Danh sách chuỗi JSON chuẩn\n",
        "        predicted_json: Danh sách chuỗi JSON dự đoán\n",
        "\n",
        "    Returns:\n",
        "        Dict: Kết quả metrics cho từng trường\n",
        "    \"\"\"\n",
        "    # Lấy các JSON hợp lệ\n",
        "    valid_gt = extract_valid_cookies(ground_truth_json)\n",
        "    valid_pred = extract_valid_cookies(predicted_json)\n",
        "\n",
        "    if not valid_gt or not valid_pred:\n",
        "        empty_metrics = {\"precision\": 0.0, \"recall\": 0.0, \"f1\": 0.0}\n",
        "        return {\n",
        "            \"cookie_name\": empty_metrics,\n",
        "            \"declared_purpose\": empty_metrics,\n",
        "            \"declared_retention\": empty_metrics,\n",
        "            \"declared_third_parties\": empty_metrics,\n",
        "            \"declared_description\": empty_metrics\n",
        "        }\n",
        "\n",
        "    fields = [\"cookie_name\", \"declared_purpose\", \"declared_retention\",\n",
        "              \"declared_third_parties\", \"declared_description\"]\n",
        "\n",
        "    results = {}\n",
        "    for field in fields:\n",
        "        precision, recall, f1 = exact_match_metrics(valid_gt, valid_pred, field)\n",
        "        results[field] = {\n",
        "            \"precision\": precision,\n",
        "            \"recall\": recall,\n",
        "            \"f1\": f1\n",
        "        }\n",
        "\n",
        "    return results\n",
        "\n",
        "# 3. Semantic Similarity\n",
        "def load_sentence_transformer():\n",
        "    \"\"\"Tải mô hình sentence transformer\"\"\"\n",
        "    try:\n",
        "        return SentenceTransformer('all-MiniLM-L6-v2')\n",
        "    except:\n",
        "        print(\"Cần cài đặt sentence-transformers: pip install sentence-transformers\")\n",
        "        return None\n",
        "\n",
        "def compute_semantic_similarity(ground_truth: List[Dict], predictions: List[Dict],\n",
        "                               field: str, model) -> float:\n",
        "    \"\"\"\n",
        "    Tính toán độ tương đồng ngữ nghĩa cho một trường trong cookies\n",
        "\n",
        "    Args:\n",
        "        ground_truth: Danh sách đối tượng JSON chuẩn\n",
        "        predictions: Danh sách đối tượng JSON dự đoán\n",
        "        field: Tên trường cần đánh giá\n",
        "        model: Mô hình sentence transformer\n",
        "\n",
        "    Returns:\n",
        "        float: Điểm tương đồng ngữ nghĩa trung bình\n",
        "    \"\"\"\n",
        "    if model is None:\n",
        "        return 0.0\n",
        "\n",
        "    # Lấy danh sách cookies từ mỗi đối tượng JSON\n",
        "    gt_cookies = []\n",
        "    for doc in ground_truth:\n",
        "        gt_cookies.extend(doc.get(\"cookies\", []))\n",
        "\n",
        "    pred_cookies = []\n",
        "    for doc in predictions:\n",
        "        pred_cookies.extend(doc.get(\"cookies\", []))\n",
        "\n",
        "    # Tạo ánh xạ từ cookie_name sang giá trị trường cần đánh giá\n",
        "    gt_map = {item[\"cookie_name\"]: item.get(field, \"\") for item in gt_cookies if \"cookie_name\" in item}\n",
        "    pred_map = {item[\"cookie_name\"]: item.get(field, \"\") for item in pred_cookies if \"cookie_name\" in item}\n",
        "\n",
        "    # Chỉ so sánh các cookie cùng tên\n",
        "    common_names = set(gt_map.keys()) & set(pred_map.keys())\n",
        "\n",
        "    if not common_names or field == \"declared_third_parties\":  # Không áp dụng semantic similarity cho mảng\n",
        "        return 0.0\n",
        "\n",
        "    similarities = []\n",
        "    for name in common_names:\n",
        "        gt_text = gt_map[name]\n",
        "        pred_text = pred_map[name]\n",
        "\n",
        "        # Bỏ qua các trường rỗng hoặc None\n",
        "        if not gt_text or not pred_text or gt_text is None or pred_text is None:\n",
        "            continue\n",
        "\n",
        "        # Mã hóa văn bản thành vector\n",
        "        gt_embedding = model.encode(str(gt_text))\n",
        "        pred_embedding = model.encode(str(pred_text))\n",
        "\n",
        "        # Tính cosine similarity\n",
        "        similarity = pairwise.cosine_similarity([gt_embedding], [pred_embedding])[0][0]\n",
        "        similarities.append(similarity)\n",
        "\n",
        "    # Tính điểm trung bình\n",
        "    return float(np.mean(similarities)) if similarities else 0.0\n",
        "\n",
        "def evaluate_semantic_similarity(ground_truth_json: List[str], predicted_json: List[str]) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Đánh giá độ tương đồng ngữ nghĩa cho các trường văn bản\n",
        "\n",
        "    Args:\n",
        "        ground_truth_json: Danh sách chuỗi JSON chuẩn\n",
        "        predicted_json: Danh sách chuỗi JSON dự đoán\n",
        "\n",
        "    Returns:\n",
        "        Dict: Kết quả semantic similarity cho từng trường\n",
        "    \"\"\"\n",
        "    # Tải mô hình sentence transformer\n",
        "    model = load_sentence_transformer()\n",
        "\n",
        "    # Lấy các JSON hợp lệ\n",
        "    valid_gt = extract_valid_cookies(ground_truth_json)\n",
        "    valid_pred = extract_valid_cookies(predicted_json)\n",
        "\n",
        "    if not valid_gt or not valid_pred or model is None:\n",
        "        return {\n",
        "            \"declared_purpose\": 0.0,\n",
        "            \"declared_description\": 0.0,\n",
        "            \"declared_retention\": 0.0,\n",
        "            \"average\": 0.0\n",
        "        }\n",
        "\n",
        "    # Các trường văn bản cần đánh giá semantic similarity\n",
        "    text_fields = [\"declared_purpose\", \"declared_description\", \"declared_retention\"]\n",
        "\n",
        "    results = {}\n",
        "    for field in text_fields:\n",
        "        similarity = compute_semantic_similarity(valid_gt, valid_pred, field, model)\n",
        "        results[field] = similarity\n",
        "\n",
        "    # Tính điểm trung bình\n",
        "    results[\"average\"] = float(np.mean(list(results.values()))) if results else 0.0\n",
        "\n",
        "    return results\n",
        "\n",
        "# 4. Cookie Count Accuracy\n",
        "def evaluate_cookie_count_accuracy(ground_truth_json: List[str], predicted_json: List[str]) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Đánh giá độ chính xác về số lượng cookie được trích xuất\n",
        "\n",
        "    Args:\n",
        "        ground_truth_json: Danh sách chuỗi JSON chuẩn\n",
        "        predicted_json: Danh sách chuỗi JSON dự đoán\n",
        "\n",
        "    Returns:\n",
        "        Dict: Kết quả đánh giá số lượng cookie\n",
        "    \"\"\"\n",
        "    valid_gt = extract_valid_cookies(ground_truth_json)\n",
        "    valid_pred = extract_valid_cookies(predicted_json)\n",
        "\n",
        "    if not valid_gt:\n",
        "        return {\"cookie_count_accuracy\": 0.0}\n",
        "\n",
        "    # Đếm số lượng cookie trong mỗi JSON\n",
        "    gt_counts = [len(doc.get(\"cookies\", [])) for doc in valid_gt]\n",
        "    pred_counts = [len(doc.get(\"cookies\", [])) for doc in valid_pred]\n",
        "\n",
        "    # Tính mức độ chênh lệch tuyệt đối trung bình\n",
        "    total_docs = min(len(gt_counts), len(pred_counts))\n",
        "    if total_docs == 0:\n",
        "        return {\"cookie_count_accuracy\": 0.0}\n",
        "\n",
        "    abs_diff_sum = sum(abs(gt_counts[i] - pred_counts[i]) for i in range(total_docs))\n",
        "    mean_abs_diff = abs_diff_sum / total_docs\n",
        "\n",
        "    # Tính độ chính xác của số lượng cookie (0-1, càng cao càng tốt)\n",
        "    max_gt_count = max(gt_counts) if gt_counts else 1\n",
        "    cookie_count_accuracy = max(0, 1 - (mean_abs_diff / max_gt_count))\n",
        "\n",
        "    return {\"cookie_count_accuracy\": cookie_count_accuracy}\n",
        "\n",
        "# Hàm tổng hợp tất cả các metrics\n",
        "def evaluate_cookie_extraction(ground_truth_json: List[str], predicted_json: List[str]) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Đánh giá toàn diện việc trích xuất cookie và phân loại is_specific\n",
        "\n",
        "    Args:\n",
        "        ground_truth_json: Danh sách chuỗi JSON chuẩn\n",
        "        predicted_json: Danh sách chuỗi JSON dự đoán\n",
        "\n",
        "    Returns:\n",
        "        Dict: Kết quả tất cả các metrics\n",
        "    \"\"\"\n",
        "    # 1. JSON Validity\n",
        "    validity_rate = json_validity_rate(predicted_json)\n",
        "\n",
        "    # 2. Field metrics (precision, recall, F1)\n",
        "    field_metrics = evaluate_field_metrics(ground_truth_json, predicted_json)\n",
        "\n",
        "    # 3. is_specific classification accuracy\n",
        "    is_specific_metrics = evaluate_is_specific_classification(ground_truth_json, predicted_json)\n",
        "\n",
        "    # 4. Cookie count accuracy\n",
        "    cookie_count_metrics = evaluate_cookie_count_accuracy(ground_truth_json, predicted_json)\n",
        "\n",
        "    # 5. Semantic similarity\n",
        "    semantic_metrics = evaluate_semantic_similarity(ground_truth_json, predicted_json)\n",
        "\n",
        "    # Tính overall accuracy dựa trên trung bình của các metrics chính\n",
        "    # Kết hợp F1 của các trường + accuracy của is_specific\n",
        "    f1_scores = [metrics[\"f1\"] for field, metrics in field_metrics.items()]\n",
        "    overall_accuracy = (sum(f1_scores) + is_specific_metrics[\"accuracy\"] + cookie_count_metrics[\"cookie_count_accuracy\"]) / (len(f1_scores) + 2)\n",
        "\n",
        "    # Tổng hợp kết quả\n",
        "    results = {\n",
        "        \"json_validity_rate\": validity_rate,\n",
        "        \"field_metrics\": field_metrics,\n",
        "        \"is_specific_classification\": is_specific_metrics,\n",
        "        \"cookie_count_metrics\": cookie_count_metrics,\n",
        "        \"semantic_similarity\": semantic_metrics,\n",
        "        \"overall_accuracy\": overall_accuracy\n",
        "    }\n",
        "\n",
        "    return results\n",
        "\n",
        "# Hàm hỗ trợ đánh giá với đầu vào từ file\n",
        "def evaluate_from_files(ground_truth_file: str, prediction_file: str) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Đánh giá từ các file chứa JSON\n",
        "\n",
        "    Args:\n",
        "        ground_truth_file: Đường dẫn đến file chứa JSON chuẩn\n",
        "        prediction_file: Đường dẫn đến file chứa JSON dự đoán\n",
        "\n",
        "    Returns:\n",
        "        Dict: Kết quả tất cả các metrics\n",
        "    \"\"\"\n",
        "    with open(ground_truth_file, 'r', encoding='utf-8') as f:\n",
        "        ground_truth_json = [line.strip() for line in f if line.strip()]\n",
        "\n",
        "    with open(prediction_file, 'r', encoding='utf-8') as f:\n",
        "        predicted_json = [line.strip() for line in f if line.strip()]\n",
        "\n",
        "    return evaluate_cookie_extraction(ground_truth_json, predicted_json)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-7-qCEgnBmm"
      },
      "source": [
        "### Đánh giá mô hình"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5SqbAmE5mlIA"
      },
      "outputs": [],
      "source": [
        "def generate_response(messages, max_new_tokens=4096, temperature=0):\n",
        "\n",
        "    inputs = tokenizer(messages, return_tensors=\"pt\", truncation=True,\n",
        "                       max_length=max_new_tokens\n",
        "                       ).to(device)\n",
        "\n",
        "    # Tạo đầu ra\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            # max_new_tokens=max_new_tokens,\n",
        "            do_sample=temperature > 0,\n",
        "            temperature=temperature,\n",
        "            top_p=0.9,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    # # Decode the prediction\n",
        "    decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    result_text = decoded_output.split(\"### Response:\")[-1].strip()\n",
        "\n",
        "\n",
        "    # # Trích xuất phần JSON\n",
        "    json_start = result_text.find(\"[\")\n",
        "    json_end = result_text.rfind(\"]\")\n",
        "    if json_start != -1 and json_end != -1 and json_end > json_start:\n",
        "        json_text = result_text[json_start:json_end+1]\n",
        "        return json_text\n",
        "\n",
        "    return result_text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(eval_data: Dataset, batch_size: int = 1) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Đánh giá mô hình trên tập dữ liệu\n",
        "\n",
        "    Args:\n",
        "      eval_data: Tập dữ liệu đánh giá (Dataset object)\n",
        "      batch_size: Số lượng mẫu xử lý cùng lúc\n",
        "\n",
        "    Returns:\n",
        "      Dict: Kết quả đánh giá\n",
        "    \"\"\"\n",
        "    if not model or not tokenizer:\n",
        "      raise ValueError(\"Cần tải mô hình trước khi đánh giá\")\n",
        "\n",
        "    all_ground_truth = []\n",
        "    all_predictions = []\n",
        "\n",
        "    for i in tqdm(range(0, len(eval_data), batch_size), desc=\"Đánh giá\"):\n",
        "      batch = [eval_data[j] for j in range(i, min(i + batch_size, len(eval_data)))]\n",
        "\n",
        "      for sample in batch:\n",
        "        try:\n",
        "          # Lấy ground truth\n",
        "          ground_truth = sample['label']\n",
        "          all_ground_truth.append(ground_truth)\n",
        "\n",
        "          # Sinh dự đoán\n",
        "          prediction = generate_response(sample['text'])\n",
        "          print(\"-----> Predict: \", prediction)\n",
        "          all_predictions.append(prediction)\n",
        "\n",
        "        except Exception as e:\n",
        "          print(f\"Lỗi khi xử lý mẫu {i}: {str(e)}\")\n",
        "\n",
        "    overall_result = evaluate_cookie_extraction(all_ground_truth, all_predictions)\n",
        "\n",
        "    return {\n",
        "      'overall': overall_result,\n",
        "    }\n",
        "\n",
        "def save_evaluation_report(eval_results: Dict[str, Any], output_path: str = \"evaluation_report.json\"):\n",
        "    \"\"\"\n",
        "    Lưu báo cáo đánh giá\n",
        "\n",
        "    Args:\n",
        "        eval_results: Kết quả đánh giá\n",
        "        output_path: Đường dẫn lưu báo cáo\n",
        "    \"\"\"\n",
        "    with open(output_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(eval_results, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    print(f\"Đã lưu báo cáo đánh giá tại: {output_path}\")\n",
        "\n",
        "    summary = {\n",
        "        \"json_validity_rate\": eval_results['overall']['json_validity_rate'],\n",
        "        \"average_f1_scores\": {\n",
        "            field: metrics['f1']\n",
        "            for field, metrics in eval_results['overall']['field_metrics'].items()\n",
        "        },\n",
        "        \"average_semantic_similarity\": eval_results['overall']['semantic_similarity']['average']\n",
        "    }\n",
        "\n",
        "    print(\"\\n=== BÁO CÁO TÓM TẮT ===\")\n",
        "    print(f\"Tỷ lệ JSON hợp lệ: {summary['json_validity_rate']:.2%}\")\n",
        "    print(\"\\nF1-score trung bình theo trường:\")\n",
        "    for field, score in summary['average_f1_scores'].items():\n",
        "        print(f\"  - {field}: {score:.4f}\")\n",
        "    print(f\"\\nĐộ tương đồng ngữ nghĩa trung bình: {summary['average_semantic_similarity']:.4f}\")"
      ],
      "metadata": {
        "id": "XgiryPAtg_Ae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "\n",
        "def evaluate_model(eval_data: Dataset, batch_size: int = 1, checkpoint_interval: int = 30,\n",
        "                checkpoint_path: str = \"/content/drive/MyDrive/Project/Qwen2.5-3B-Instructevaluation_checkpoint.json\") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Đánh giá mô hình trên tập dữ liệu với khả năng lưu checkpoint\n",
        "\n",
        "    Args:\n",
        "      eval_data: Tập dữ liệu đánh giá (Dataset object)\n",
        "      batch_size: Số lượng mẫu xử lý cùng lúc\n",
        "      checkpoint_interval: Số lượng mẫu xử lý trước khi lưu checkpoint\n",
        "      checkpoint_path: Đường dẫn để lưu tệp checkpoint\n",
        "\n",
        "    Returns:\n",
        "      Dict: Kết quả đánh giá\n",
        "    \"\"\"\n",
        "    if not model or not tokenizer:\n",
        "      raise ValueError(\"Cần tải mô hình trước khi đánh giá\")\n",
        "\n",
        "    all_ground_truth = []\n",
        "    all_predictions = []\n",
        "\n",
        "    # Kiểm tra xem có checkpoint trước đó hay không\n",
        "    start_idx = 0\n",
        "    if os.path.exists(checkpoint_path):\n",
        "        try:\n",
        "            with open(checkpoint_path, 'r', encoding='utf-8') as f:\n",
        "                checkpoint_data = json.load(f)\n",
        "                all_ground_truth = checkpoint_data.get('ground_truth', [])\n",
        "                all_predictions = checkpoint_data.get('predictions', [])\n",
        "                start_idx = checkpoint_data.get('next_idx', 0)\n",
        "                print(f\"Đã tải checkpoint, tiếp tục từ mẫu {start_idx}/{len(eval_data)}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Không thể tải checkpoint: {str(e)}, bắt đầu từ đầu\")\n",
        "\n",
        "    # Tính số mẫu đã xử lý\n",
        "    processed_samples = len(all_ground_truth)\n",
        "\n",
        "    for i in tqdm(range(start_idx, len(eval_data), batch_size), desc=\"Đánh giá\"):\n",
        "      batch = [eval_data[j] for j in range(i, min(i + batch_size, len(eval_data)))]\n",
        "\n",
        "      for sample in batch:\n",
        "        try:\n",
        "          # Lấy ground truth\n",
        "          ground_truth = f\"\"\"\n",
        "                {{\n",
        "                  'is_specific': {sample['is_specific']},\n",
        "                  'extracted_cookies': {sample['extracted_cookies']}\n",
        "                }}\"\"\"\n",
        "          all_ground_truth.append(ground_truth)\n",
        "\n",
        "          # Sinh dự đoán\n",
        "          prediction = generate_response(sample['text'])\n",
        "          print(\"-----> Predict: \", prediction)\n",
        "          all_predictions.append(prediction)\n",
        "\n",
        "          # Tăng số mẫu đã xử lý\n",
        "          processed_samples += 1\n",
        "\n",
        "          # Lưu checkpoint sau mỗi checkpoint_interval mẫu\n",
        "          if processed_samples % checkpoint_interval == 0:\n",
        "              save_checkpoint(all_ground_truth, all_predictions, i + 1, checkpoint_path)\n",
        "              print(f\"Đã lưu checkpoint sau khi xử lý {processed_samples} mẫu\")\n",
        "\n",
        "        except Exception as e:\n",
        "          print(f\"Lỗi khi xử lý mẫu {i}: {str(e)}\")\n",
        "\n",
        "    # Đánh giá kết quả sau khi hoàn thành\n",
        "    overall_result = evaluate_cookie_extraction(all_ground_truth, all_predictions)\n",
        "\n",
        "    return {\n",
        "      'overall': overall_result,\n",
        "    }\n",
        "\n",
        "def save_checkpoint(ground_truth: list, predictions: list, next_idx: int, checkpoint_path: str):\n",
        "    \"\"\"\n",
        "    Lưu trạng thái hiện tại của quá trình đánh giá\n",
        "\n",
        "    Args:\n",
        "        ground_truth: Danh sách ground truth đã xử lý\n",
        "        predictions: Danh sách dự đoán đã xử lý\n",
        "        next_idx: Chỉ số mẫu tiếp theo sẽ xử lý\n",
        "        checkpoint_path: Đường dẫn lưu tệp checkpoint\n",
        "    \"\"\"\n",
        "    checkpoint_data = {\n",
        "        'ground_truth': ground_truth,\n",
        "        'predictions': predictions,\n",
        "        'next_idx': next_idx,\n",
        "        'timestamp': datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    }\n",
        "\n",
        "    # Tạo thư mục chứa nếu chưa tồn tại\n",
        "    os.makedirs(os.path.dirname(checkpoint_path) if os.path.dirname(checkpoint_path) else '.', exist_ok=True)\n",
        "\n",
        "    with open(checkpoint_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(checkpoint_data, f, ensure_ascii=False)\n",
        "\n",
        "def save_evaluation_report(eval_results: Dict[str, Any], output_path: str = \"evaluation_report.json\"):\n",
        "    \"\"\"\n",
        "    Lưu báo cáo đánh giá\n",
        "\n",
        "    Args:\n",
        "        eval_results: Kết quả đánh giá\n",
        "        output_path: Đường dẫn lưu báo cáo\n",
        "    \"\"\"\n",
        "    with open(output_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(eval_results, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    print(f\"Đã lưu báo cáo đánh giá tại: {output_path}\")\n",
        "\n",
        "    summary = {\n",
        "        \"json_validity_rate\": eval_results['overall']['json_validity_rate'],\n",
        "        \"average_f1_scores\": {\n",
        "            field: metrics['f1']\n",
        "            for field, metrics in eval_results['overall']['field_metrics'].items()\n",
        "        },\n",
        "        \"average_semantic_similarity\": eval_results['overall']['semantic_similarity']['average']\n",
        "    }\n",
        "\n",
        "    print(\"\\n=== BÁO CÁO TÓM TẮT ===\")\n",
        "    print(f\"Tỷ lệ JSON hợp lệ: {summary['json_validity_rate']:.2%}\")\n",
        "    print(\"\\nF1-score trung bình theo trường:\")\n",
        "    for field, score in summary['average_f1_scores'].items():\n",
        "        print(f\"  - {field}: {score:.4f}\")\n",
        "    print(f\"\\nĐộ tương đồng ngữ nghĩa trung bình: {summary['average_semantic_similarity']:.4f}\")"
      ],
      "metadata": {
        "id": "hknhOpDpeXcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nLONIRAnM0J"
      },
      "source": [
        "### Bắt đầu đánh giá"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ps_A4ueinK6s"
      },
      "outputs": [],
      "source": [
        "evaluate_result = evaluate_model(dataset, batch_size=4)\n",
        "\n",
        "results = evaluate_model(\n",
        "    dataset,\n",
        "    batch_size=4,\n",
        "    checkpoint_interval=30,  # Lưu sau mỗi 30 mẫu\n",
        "    checkpoint_path=\"eval_checkpoint.json\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_result"
      ],
      "metadata": {
        "id": "fx3si8TZ5_Ct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_evaluation_report(evaluate_result, \"/content/drive/MyDrive/Qwen2.5_(3B)-SFT/evaluation_report.json\")"
      ],
      "metadata": {
        "id": "0HqzIxok5_l-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_model_online = \"sonhask/Qwen2.5_3B_SFT_detect_cookies\"\n",
        "\n",
        "model.push_to_hub(new_model_online) # Online saving\n",
        "tokenizer.push_to_hub(new_model_online) # Online saving"
      ],
      "metadata": {
        "id": "-viRVvdel2rA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = \"meta-llama/meta-Llama-3.1-8B-Instruct\"\n",
        "peft_model = \"Llama_3_1_8B_GRPO_detect_cookies\"\n",
        "hub_id = \"sonhask/Llama_3_1_8B_GRPO_detect_cookies\"\n",
        "\n",
        "print(f\"[1/5] Loading base model: {base_model}\")\n",
        "base_model = FastLanguageModel.from_pretrained(\n",
        "    base_model,\n",
        "    return_dict=True,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
        "\n",
        "print(f\"[2/5] Loading adapter: {peft_model}\")\n",
        "model = PeftModel.from_pretrained(base_model, peft_model, device_map=\"auto\")\n",
        "\n",
        "print(\"[3/5] Merge base model and adapter\")\n",
        "model = model.merge_and_unload()\n",
        "\n",
        "print(f\"[4/5] Saving model and tokenizer in {hub_id}\")\n",
        "model.save_pretrained(f\"{hub_id}\")\n",
        "tokenizer.save_pretrained(f\"{hub_id}\")\n",
        "\n",
        "print(f\"[5/5] Uploading to Hugging Face Hub: {hub_id}\")\n",
        "model.push_to_hub(f\"{hub_id}\", use_temp_dir=False)\n",
        "tokenizer.push_to_hub(f\"{hub_id}\", use_temp_dir=False)\n",
        "\n",
        "print(\"Merged model uploaded to Hugging Face Hub!\")"
      ],
      "metadata": {
        "id": "6snCuRc5pwWA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "rD_-G4bHm8WZ"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cd089b930f4a4315a539cc91df2827a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_024802e6739e45cabcb36b986c91077a",
              "IPY_MODEL_2f9a2eb93d5a4e059b42330099306384",
              "IPY_MODEL_5dad066cc122478781a8143b66a1d268"
            ],
            "layout": "IPY_MODEL_b14775ab311045b99a4ec447353720a7"
          }
        },
        "024802e6739e45cabcb36b986c91077a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d785a133f0f4718aab6ee8d9f4f0de1",
            "placeholder": "​",
            "style": "IPY_MODEL_af1b671e9eda45f7b0b0b7aa9fa7b672",
            "value": ""
          }
        },
        "2f9a2eb93d5a4e059b42330099306384": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_340adc350ce646639ce8fcaf8888c50a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3cffcc45b8344fef820e705b740f5dc1",
            "value": 0
          }
        },
        "5dad066cc122478781a8143b66a1d268": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf97b761a9674466a7119545502e57c6",
            "placeholder": "​",
            "style": "IPY_MODEL_bb59a6c6cebe44489a565d379cd0dbb0",
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        },
        "b14775ab311045b99a4ec447353720a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d785a133f0f4718aab6ee8d9f4f0de1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af1b671e9eda45f7b0b0b7aa9fa7b672": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "340adc350ce646639ce8fcaf8888c50a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "3cffcc45b8344fef820e705b740f5dc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bf97b761a9674466a7119545502e57c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb59a6c6cebe44489a565d379cd0dbb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
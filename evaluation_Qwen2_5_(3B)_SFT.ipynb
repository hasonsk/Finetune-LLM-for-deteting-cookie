{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hasonsk/Finetune-LLM-for-deteting-cookie/blob/main/evaluation_Qwen2_5_(3B)_SFT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SspUhKDMBZQC",
        "outputId": "8d11f077-562b-4f5a-bcb0-beecaac205b5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "import os\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth\n",
        "else:\n",
        "    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
        "    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl==0.15.2 triton cut_cross_entropy unsloth_zoo\n",
        "    !pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n",
        "    !pip install --no-deps unsloth"
      ],
      "metadata": {
        "id": "uUi6Kr8nR8lo"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nJpdaREcvPG-",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -U bitsandbytes\n",
        "!pip install -U datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seBAyPabUix6"
      },
      "source": [
        "# Load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nYYiye50iAJ2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from huggingface_hub import login\n",
        "\n",
        "os.environ[\"HUGGINGFACE_API_KEY\"] = \"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\"\n",
        "\n",
        "hf_token = os.environ[\"HUGGINGFACE_API_KEY\"]\n",
        "login(hf_token)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from datasets import Dataset, load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from tqdm import tqdm\n",
        "from typing import List, Dict, Any\n",
        "from peft import PeftModel, PeftConfig"
      ],
      "metadata": {
        "id": "U3aKJ3q_keqq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "max_seq_length = 4096 # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"Qwen/Qwen2.5-3B-Instruct\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        ")"
      ],
      "metadata": {
        "id": "byMfzzWIjwsF",
        "outputId": "a5bdf595-2fba-49a6-8d57-0a56698e0d23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-b8fb98152428>:1: UserWarning: WARNING: Unsloth should be imported before transformers, peft to ensure all optimizations are applied. Your code may run slower or encounter memory issues without these optimizations.\n",
            "\n",
            "Please restructure your imports with 'import unsloth' at the top of your file.\n",
            "  from unsloth import FastLanguageModel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
            "==((====))==  Unsloth 2025.5.1: Fast Qwen2 patching. Transformers: 4.51.3.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "EC3GY-Z1UkXL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d005feb-6b2e-4011-f5d4-9908fcb3ce85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S·ª≠ d·ª•ng device: cuda\n",
            "ƒêang t·∫£i m√¥ h√¨nh PEFT v·ªõi base model: unsloth/qwen2.5-3b-instruct-unsloth-bnb-4bit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/peft/peft_model.py:569: UserWarning: Found missing adapter keys while loading the checkpoint: ['base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.24.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.24.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.24.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.24.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.24.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.24.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.25.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.25.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.25.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.25.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.25.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.25.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.26.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.26.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.26.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.26.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.26.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.26.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.27.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.27.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.27.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.27.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.27.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.27.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.28.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.28.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.28.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.28.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.28.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.28.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.28.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.28.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.28.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.28.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.29.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.29.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.29.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.29.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.29.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.29.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.29.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.29.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.29.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.29.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.30.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.30.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.30.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.30.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.30.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.30.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.30.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.30.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.30.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.30.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.31.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.31.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.31.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.31.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.31.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.31.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.31.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.31.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.31.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.31.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.32.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.32.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.32.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.32.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.32.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.32.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.32.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.32.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.32.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.32.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.32.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.32.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.32.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.32.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.33.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.33.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.33.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.33.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.33.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.33.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.33.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.33.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.33.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.33.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.33.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.33.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.33.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.33.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.34.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.34.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.34.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.34.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.34.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.34.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.34.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.34.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.34.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.34.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.34.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.34.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.34.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.34.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.35.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.35.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.35.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.35.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.35.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.35.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.35.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.35.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.35.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.35.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.35.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.35.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.35.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.35.mlp.down_proj.lora_B.default.weight'].\n",
            "  warnings.warn(warn_message)\n"
          ]
        }
      ],
      "source": [
        "# ƒê∆∞·ªùng d·∫´n ƒë·∫øn th∆∞ m·ª•c ch·ª©a m√¥ h√¨nh ƒë√£ fine-tune\n",
        "# model_path = \"/content/drive/MyDrive/Project/Llama-3.2-3B-Instruct/checkpoint-584\"\n",
        "model_path = \"sonhask/Qwen2.5_3B_Instruct_SFT_Extract_cookie_from_policy\"\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"S·ª≠ d·ª•ng device: {device}\")\n",
        "\n",
        "try:\n",
        "    # N·∫øu ƒë√¢y l√† m√¥ h√¨nh adapter (PEFT/LoRA)\n",
        "    config = PeftConfig.from_pretrained(model_path)\n",
        "    print(f\"ƒêang t·∫£i m√¥ h√¨nh PEFT v·ªõi base model: {config.base_model_name_or_path}\")\n",
        "\n",
        "    # T·∫£i m√¥ h√¨nh c∆° s·ªü\n",
        "    base_model = AutoModelForCausalLM.from_pretrained(\n",
        "        config.base_model_name_or_path,\n",
        "        device_map=\"auto\"\n",
        "    )\n",
        "\n",
        "    # T·∫£i m√¥ h√¨nh adapter\n",
        "    model = PeftModel.from_pretrained(base_model, model_path)\n",
        "\n",
        "except:\n",
        "    # N·∫øu ƒë√¢y l√† m√¥ h√¨nh ƒë·∫ßy ƒë·ªß (kh√¥ng ph·∫£i adapter)\n",
        "    print(\"Kh√¥ng ph·∫£i m√¥ h√¨nh PEFT/adapter, ƒëang t·∫£i m√¥ h√¨nh ƒë·∫ßy ƒë·ªß...\")\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_path, device_map=\"auto\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NZwsSbB1htCC",
        "outputId": "f5c89681-4f11-49de-d8fd-941b697e8591",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "ff11f0bb506b47f7be210d111ba31bd5",
            "9becec72152640e08f06f5d84fc9b26e",
            "c163660edb1a42dea70cbb0610a6206e",
            "3f511e3d4fb64fe19738c4958d4a42f5",
            "a87243b4a4064d958e72e95c37fc8d9f",
            "fa5fc6aa5fc74587b3750bad4c269ef3",
            "0b55b2ce2dd84b82a1866b20395ed2d1",
            "090127ddf76945fd93e9c0672a9afc71",
            "98b5dd0ecb974ebbb8b09ba3a04beab3",
            "a74f64e3e45a4badbaff14311df70d30",
            "5f2da80a8b8749dd8d9e9dea956fba9b",
            "87f57da48df0446f85c4facd9a157ef9",
            "90a88e92429a4d44a099101e0da00bdb",
            "623a355710fe4bc29162af72b806a7dd",
            "6f926127b92a42238afabe502b3aa85d",
            "9a700962c00a47c8b931a2203872d3d9",
            "b5ed84bc864941f594dfc381142a67f3",
            "dce934a812ec4c66b7437913ab28f318",
            "981c02c4fb404427bb05590bb3024682",
            "615c944248b848d9a4e51d357c977c1f",
            "a8d733d813d4494fbddf69b15a7d518c",
            "9d13bc2759e8448d8576026df1488187",
            "5fc2f90b5c524f28856c8218642e4677",
            "fc3d1ad515b34a1f88dc6a33b23b44e2",
            "59dd042efca44c17ac4e513dec73ecc2",
            "8a66fce0fe124ffaacf5a8b92a40f124",
            "d343c88f02094c289a308ad9025bb3f3",
            "78670141e058497f96071742a7f98c70",
            "bbe5963eba594e7cbeeefb4272c105d0",
            "fb712b4471cb4e999c577e00a1de389e",
            "dbb03abd80a74aa2a1b3320df5316d4e",
            "ac6848355fb443069f02e5c0e191a9b0",
            "490f427b9b2a47c280b8b4e114fd253b"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/8808 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ff11f0bb506b47f7be210d111ba31bd5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/2937 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "87f57da48df0446f85c4facd9a157ef9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2937 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5fc2f90b5c524f28856c8218642e4677"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "alpaca_prompt = \"\"\"\n",
        "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
        "Your task is read a cookie policy text and extract detailed information about each cookie mentioned in that policy.\n",
        "RESPONSE Format: JSON following structure:\n",
        "\n",
        "{{\n",
        "  \"is_specific\": 0,\n",
        "  \"cookies\": [\n",
        "     {{\n",
        "      \"cookie_name\": \"cookie_name\",\n",
        "      \"declared_purpose\": \"declared_purpose\",\n",
        "      \"declared_retention\": \"declared_retention\",\n",
        "      \"declared_third_parties\": [\"declared_third_parties\"],\n",
        "      \"declared_description\": \"declared_description\"\n",
        "    }}, ...\n",
        "  ]\n",
        "}}\n",
        "If no cookies are specifically described, only response {{\"is_specific\": 0, \"cookies\": []}}\n",
        "\n",
        "### Instruction:\n",
        "{}\n",
        "\n",
        "### Input:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{{\n",
        "  \"is_specific\": {},\n",
        "  \"cookies\": {}\n",
        "}}\"\"\"\n",
        "\n",
        "SYSTEM_PROMPT = \"\"\"\n",
        "Extraction guidelines:\n",
        "For \"is_specific\": Determines if the website provides detailed descriptions of individual cookies:\n",
        "- Set to 0 if cookies are only described generically (e.g., \"performance cookies,\" \"necessary cookies,\" \"Google cookies\") without specific explanations\n",
        "- Set to 1 if cookies are described with specific names, purposes, retention periods, and third parties. Example: \"The '_ga' cookie is used by Google Analytics to distinguish users and is stored for 2 years\" would result in is_specific = 1\n",
        "\n",
        "For the \"cookies\" list containing objects, each object has\n",
        "- \"cookie_name\": Extract the exact technical name as mentioned. One object just has only one cookie name, √¨f more one, create multiple objects. For example: ga, _gid, _gat --> 3 object cookies\n",
        "- \"declared_purpose\": cookie's purpose. With the following options:\n",
        "  * Strictly Necessary: Essential for basic website functionality\n",
        "  * Functionality: Personalizes user experience\n",
        "  * Analytical: Collects usage data\n",
        "  * Targeting/Advertising/Marketing: For personalized ads\n",
        "  * Performance: Improves technical performance\n",
        "  * Social Sharing: Enables social media integration\n",
        "  * Null: When no specific purpose information is provided\n",
        "- \"declared_retention\": Record the exact storage duration as mentioned\n",
        "- \"declared_third_parties\": An list of third parties involved in the use of this cookie for website-owned cookies\n",
        "- \"declared_description\": exact wording from the policy without modification or embellishment\"\"\"\n",
        "\n",
        "\n",
        "EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
        "def formatting_prompts_func(example):\n",
        "    if example['english_content']:\n",
        "        content = f\"Cookie policy: {example['english_content']}\\nTable: {example['english_table']}\"\n",
        "    elif example['english_table']:\n",
        "        content = f\"Table: {example['english_table']}\"\n",
        "    else:\n",
        "        content = f\"Content: {example['english_table']}\"\n",
        "\n",
        "    instruction = SYSTEM_PROMPT\n",
        "    input       = content\n",
        "    is_specific = example['is_specific']\n",
        "    cookies     = example['extracted_cookies']\n",
        "\n",
        "    text = alpaca_prompt.format(instruction, input, is_specific, cookies) + EOS_TOKEN\n",
        "    return { \"text\" : text, }\n",
        "\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"sonhask/Extract_cookies_from_cookie_policy_specific\", split = \"test\")\n",
        "dataset = dataset.map(formatting_prompts_func)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4TlfpGqLiTV_",
        "outputId": "c792da60-dbde-40f4-f8f7-c707bf5445ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#[]:  2137\n",
            "#Has cookies:  800\n"
          ]
        }
      ],
      "source": [
        "def thong_ke(dataset):\n",
        "    empty_label_count = 0\n",
        "    non_empty_label_count = 0\n",
        "\n",
        "    for i in dataset:\n",
        "        if i['label'] == '[]':\n",
        "            empty_label_count += 1\n",
        "        else:\n",
        "            non_empty_label_count += 1\n",
        "\n",
        "    print(\"#[]: \", empty_label_count)\n",
        "    print(\"#Has cookies: \", non_empty_label_count)\n",
        "\n",
        "thong_ke(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "v4d3q9cBikRH",
        "outputId": "0bb3b22f-d56f-44c9-f0db-a810cf03ba64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133,
          "referenced_widgets": [
            "c26ceb2c247043e9b56ed870749e8671",
            "17d2d0e875354c5cadc9a98b477c13db",
            "9d21702366ac43039b8a81f4ef542546",
            "cece01037c274911bf33f6435bbaffef",
            "3ba493e9888f49d783e1b718f48d35b6",
            "9adf06b614714af3859266ca0c7799ed",
            "e8b33e3dc5744d27bd06868f79f43b17",
            "0d0bb2f56dac4545b8cbd32d79ae6372",
            "58c0967e900745f0932334f3f956aaa1",
            "be45d299f9a1416cbd1c30feaba40428",
            "ed4ee927579d48039e592b548337b0d0",
            "a13f5a9401dc4f15a3ec2e3b916e06bf",
            "28d664a5e7b94a9ba90d116ca69a206a",
            "ad04ca82619e4a4a81ed2fa9a4982e18",
            "a8a8bd718ffa427683bc9aa4d66aa8bc",
            "64ddb8e9b9b34ef493f716c7eca5057e",
            "8bbaf97fd15c43bb993339fb4a0ef5e3",
            "2e011084c31b41c2b74818b497ff4877",
            "5be77eef223a4452a2ba928b727564eb",
            "4bb8ef10815a47619cff50b29f74ca3e",
            "5709222ad005478f8776d11c56a33f4b",
            "283296ca2c534534be29e4722ee7b2a4"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/2937 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c26ceb2c247043e9b56ed870749e8671"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/2937 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a13f5a9401dc4f15a3ec2e3b916e06bf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N samples:  800\n",
            "#[]:  800\n",
            "#Has cookies:  800\n"
          ]
        }
      ],
      "source": [
        "from datasets import concatenate_datasets\n",
        "\n",
        "has_no_cookie = \"[]\"\n",
        "\n",
        "empty_label_dataset = dataset.filter(lambda example: example['label'] == has_no_cookie)\n",
        "non_empty_label_dataset = dataset.filter(lambda example: example['label'] != has_no_cookie)\n",
        "\n",
        "# Downsample the non-empty dataset to the size of the empty dataset\n",
        "n_samples = len(non_empty_label_dataset)\n",
        "print(\"N samples: \", n_samples)\n",
        "downsampled_empty_dataset = empty_label_dataset.shuffle(seed=42).select(range(n_samples))\n",
        "\n",
        "# G·ªôp 2 dataset\n",
        "combined_dataset = concatenate_datasets([non_empty_label_dataset, downsampled_empty_dataset])\n",
        "\n",
        "# Shuffle dataset\n",
        "balanced_dataset = combined_dataset.shuffle(seed=42)\n",
        "\n",
        "# Verify the balanced dataset statistics\n",
        "thong_ke(balanced_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "dGbn9I8DiWEc"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.remove_columns(['url', 'lang', 'original_text', 'tables', 'processed_text', 'english_content', 'english_table', 'translated_tables', '__index_level_0__', 'label'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TqevtGN4fhC0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "3o9Gpmguilrd",
        "outputId": "fb7f6862-fd5e-4e40-d6d7-ba43717bcdeb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['is_specific', 'extracted_cookies', 'text'],\n",
              "    num_rows: 2937\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD_-G4bHm8WZ"
      },
      "source": [
        "### H√†m ƒë√°nh gi√° m√¥ h√¨nh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "VZVSzDY3m07u"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import jsonschema\n",
        "import numpy as np\n",
        "from typing import List, Dict, Any, Union, Tuple\n",
        "from collections import defaultdict\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import sklearn.metrics.pairwise as pairwise\n",
        "import re\n",
        "\n",
        "# Schema cho d·ªØ li·ªáu cookie\n",
        "COOKIE_SCHEMA = {\n",
        "    \"type\": \"array\",\n",
        "    \"items\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"cookie_name\": {\"type\": \"string\"},\n",
        "            \"declared_purpose\": {\"type\": [\"string\", \"null\"]},\n",
        "            \"declared_retention\": {\"type\": [\"string\", \"null\"]},\n",
        "            \"declared_third_parties\": {\"type\": \"array\"},\n",
        "            \"declared_description\": {\"type\": [\"string\", \"null\"]}\n",
        "        },\n",
        "        \"required\": [\"cookie_name\"]\n",
        "    }\n",
        "}\n",
        "\n",
        "# 1. JSON Validity\n",
        "def validate_json_format(predicted_json_str: str) -> bool:\n",
        "    \"\"\"\n",
        "    Ki·ªÉm tra xem chu·ªói JSON c√≥ h·ª£p l·ªá hay kh√¥ng\n",
        "\n",
        "    Args:\n",
        "        predicted_json_str: Chu·ªói JSON c·∫ßn ki·ªÉm tra\n",
        "\n",
        "    Returns:\n",
        "        bool: True n·∫øu JSON h·ª£p l·ªá, False n·∫øu kh√¥ng\n",
        "    \"\"\"\n",
        "    try:\n",
        "        json_data = json.loads(predicted_json_str)\n",
        "        jsonschema.validate(instance=json_data, schema=COOKIE_SCHEMA)\n",
        "        return True\n",
        "    except (json.JSONDecodeError, jsonschema.exceptions.ValidationError):\n",
        "        return False\n",
        "\n",
        "def json_validity_rate(predicted_json_strings: List[str]) -> float:\n",
        "    \"\"\"\n",
        "    T√≠nh t·ª∑ l·ªá c√°c chu·ªói JSON h·ª£p l·ªá theo schema ƒë√£ ƒë·ªãnh nghƒ©a\n",
        "\n",
        "    Args:\n",
        "        predicted_json_strings: Danh s√°ch c√°c chu·ªói JSON d·ª± ƒëo√°n t·ª´ m√¥ h√¨nh\n",
        "\n",
        "    Returns:\n",
        "        float: T·ª∑ l·ªá h·ª£p l·ªá (0-1)\n",
        "    \"\"\"\n",
        "    valid_count = sum(validate_json_format(js) for js in predicted_json_strings)\n",
        "    return valid_count / len(predicted_json_strings) if predicted_json_strings else 0\n",
        "\n",
        "# 2. Precision, Recall, F1-score cho t·ª´ng tr∆∞·ªùng\n",
        "def normalize_text(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Chu·∫©n h√≥a vƒÉn b·∫£n ƒë·ªÉ so s√°nh\n",
        "\n",
        "    Args:\n",
        "        text: VƒÉn b·∫£n c·∫ßn chu·∫©n h√≥a\n",
        "\n",
        "    Returns:\n",
        "        str: VƒÉn b·∫£n ƒë√£ ƒë∆∞·ª£c chu·∫©n h√≥a\n",
        "    \"\"\"\n",
        "    if text is None:\n",
        "        return \"\"\n",
        "    return re.sub(r'\\s+', ' ', text.lower().strip())\n",
        "\n",
        "def extract_valid_cookies(json_strings: List[str]) -> List[List[Dict]]:\n",
        "    \"\"\"\n",
        "    Tr√≠ch xu·∫•t danh s√°ch cookie t·ª´ c√°c chu·ªói JSON v√† ch·ªâ gi·ªØ l·∫°i c√°c JSON h·ª£p l·ªá\n",
        "\n",
        "    Args:\n",
        "        json_strings: Danh s√°ch c√°c chu·ªói JSON\n",
        "\n",
        "    Returns:\n",
        "        List[List[Dict]]: Danh s√°ch c√°c danh s√°ch cookie (ch·ªâ c√°c JSON h·ª£p l·ªá)\n",
        "    \"\"\"\n",
        "    result = []\n",
        "    for js in json_strings:\n",
        "        try:\n",
        "            data = json.loads(js)\n",
        "            jsonschema.validate(instance=data, schema=COOKIE_SCHEMA)\n",
        "            result.append(data)\n",
        "        except (json.JSONDecodeError, jsonschema.exceptions.ValidationError):\n",
        "            pass\n",
        "    return result\n",
        "\n",
        "def exact_match_metrics(ground_truth: List[Dict], predictions: List[Dict], field: str) -> Tuple[float, float, float]:\n",
        "    \"\"\"\n",
        "    T√≠nh precision, recall, F1 cho vi·ªác so kh·ªõp ch√≠nh x√°c m·ªôt tr∆∞·ªùng\n",
        "\n",
        "    Args:\n",
        "        ground_truth: Danh s√°ch cookie chu·∫©n\n",
        "        predictions: Danh s√°ch cookie d·ª± ƒëo√°n\n",
        "        field: T√™n tr∆∞·ªùng c·∫ßn ƒë√°nh gi√°\n",
        "\n",
        "    Returns:\n",
        "        Tuple[float, float, float]: (precision, recall, F1-score)\n",
        "    \"\"\"\n",
        "    # T·∫°o √°nh x·∫° t·ª´ cookie_name sang gi√° tr·ªã tr∆∞·ªùng c·∫ßn ƒë√°nh gi√°\n",
        "    gt_map = {item[\"cookie_name\"]: item.get(field) for item in ground_truth if \"cookie_name\" in item}\n",
        "    pred_map = {item[\"cookie_name\"]: item.get(field) for item in predictions if \"cookie_name\" in item}\n",
        "\n",
        "    # X·ª≠ l√Ω tr∆∞·ªùng h·ª£p ƒë·∫∑c bi·ªát cho declared_third_parties l√† m·∫£ng\n",
        "    if field == \"declared_third_parties\":\n",
        "        # Chuy·ªÉn th√†nh set ƒë·ªÉ so s√°nh kh√¥ng ph·ª• thu·ªôc th·ª© t·ª±\n",
        "        gt_map = {k: set(v) if v is not None else set() for k, v in gt_map.items()}\n",
        "        pred_map = {k: set(v) if v is not None else set() for k, v in pred_map.items()}\n",
        "    else:\n",
        "        # Chu·∫©n h√≥a d·ªØ li·ªáu vƒÉn b·∫£n\n",
        "        gt_map = {k: normalize_text(v) for k, v in gt_map.items()}\n",
        "        pred_map = {k: normalize_text(v) for k, v in pred_map.items()}\n",
        "\n",
        "    # ƒê·∫øm c√°c tr∆∞·ªùng h·ª£p True Positive, False Positive, False Negative\n",
        "    tp = 0\n",
        "    for cookie_name in set(gt_map.keys()) & set(pred_map.keys()):\n",
        "        if field == \"declared_third_parties\":\n",
        "            if gt_map[cookie_name] == pred_map[cookie_name]:\n",
        "                tp += 1\n",
        "        else:\n",
        "            if gt_map[cookie_name] == pred_map[cookie_name]:\n",
        "                tp += 1\n",
        "\n",
        "    fp = len(set(pred_map.keys()) - set(gt_map.keys()))\n",
        "    fn = len(set(gt_map.keys()) - set(pred_map.keys()))\n",
        "\n",
        "    # T√≠nh precision, recall, F1\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "    return precision, recall, f1\n",
        "\n",
        "def evaluate_field_metrics(ground_truth_json: List[str], predicted_json: List[str]) -> Dict[str, Dict[str, float]]:\n",
        "    \"\"\"\n",
        "    ƒê√°nh gi√° metrics cho t·∫•t c·∫£ c√°c tr∆∞·ªùng\n",
        "\n",
        "    Args:\n",
        "        ground_truth_json: Danh s√°ch chu·ªói JSON chu·∫©n\n",
        "        predicted_json: Danh s√°ch chu·ªói JSON d·ª± ƒëo√°n\n",
        "\n",
        "    Returns:\n",
        "        Dict: K·∫øt qu·∫£ metrics cho t·ª´ng tr∆∞·ªùng\n",
        "    \"\"\"\n",
        "    # Ch·ªâ l·∫•y c√°c JSON h·ª£p l·ªá\n",
        "    valid_gt = []\n",
        "    for js in ground_truth_json:\n",
        "        try:\n",
        "            data = json.loads(js)\n",
        "            jsonschema.validate(instance=data, schema=COOKIE_SCHEMA)\n",
        "            valid_gt.extend(data)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    valid_pred = []\n",
        "    for js in predicted_json:\n",
        "        try:\n",
        "            data = json.loads(js)\n",
        "            jsonschema.validate(instance=data, schema=COOKIE_SCHEMA)\n",
        "            valid_pred.extend(data)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    fields = [\"cookie_name\", \"declared_purpose\", \"declared_retention\",\n",
        "              \"declared_third_parties\", \"declared_description\"]\n",
        "\n",
        "    results = {}\n",
        "    for field in fields:\n",
        "        precision, recall, f1 = exact_match_metrics(valid_gt, valid_pred, field)\n",
        "        results[field] = {\n",
        "            \"precision\": precision,\n",
        "            \"recall\": recall,\n",
        "            \"f1\": f1\n",
        "        }\n",
        "\n",
        "    return results\n",
        "\n",
        "# 3. Semantic Similarity\n",
        "def load_sentence_transformer():\n",
        "    \"\"\"T·∫£i m√¥ h√¨nh sentence transformer\"\"\"\n",
        "    try:\n",
        "        return SentenceTransformer('all-MiniLM-L6-v2')\n",
        "    except:\n",
        "        print(\"C·∫ßn c√†i ƒë·∫∑t sentence-transformers: pip install sentence-transformers\")\n",
        "        return None\n",
        "\n",
        "def compute_semantic_similarity(ground_truth: List[Dict], predictions: List[Dict],\n",
        "                               field: str, model) -> float:\n",
        "    \"\"\"\n",
        "    T√≠nh to√°n ƒë·ªô t∆∞∆°ng ƒë·ªìng ng·ªØ nghƒ©a cho m·ªôt tr∆∞·ªùng\n",
        "\n",
        "    Args:\n",
        "        ground_truth: Danh s√°ch cookie chu·∫©n\n",
        "        predictions: Danh s√°ch cookie d·ª± ƒëo√°n\n",
        "        field: T√™n tr∆∞·ªùng c·∫ßn ƒë√°nh gi√°\n",
        "        model: M√¥ h√¨nh sentence transformer\n",
        "\n",
        "    Returns:\n",
        "        float: ƒêi·ªÉm t∆∞∆°ng ƒë·ªìng ng·ªØ nghƒ©a trung b√¨nh\n",
        "    \"\"\"\n",
        "    if model is None:\n",
        "        return 0.0\n",
        "\n",
        "    # T·∫°o √°nh x·∫° t·ª´ cookie_name sang gi√° tr·ªã tr∆∞·ªùng c·∫ßn ƒë√°nh gi√°\n",
        "    gt_map = {item[\"cookie_name\"]: item.get(field, \"\") for item in ground_truth if \"cookie_name\" in item}\n",
        "    pred_map = {item[\"cookie_name\"]: item.get(field, \"\") for item in predictions if \"cookie_name\" in item}\n",
        "\n",
        "    # Ch·ªâ so s√°nh c√°c cookie c√πng t√™n\n",
        "    common_names = set(gt_map.keys()) & set(pred_map.keys())\n",
        "\n",
        "    if not common_names or field == \"declared_third_parties\":  # Kh√¥ng √°p d·ª•ng semantic similarity cho m·∫£ng\n",
        "        return 0.0\n",
        "\n",
        "    similarities = []\n",
        "    for name in common_names:\n",
        "        gt_text = gt_map[name]\n",
        "        pred_text = pred_map[name]\n",
        "\n",
        "        # B·ªè qua c√°c tr∆∞·ªùng r·ªóng ho·∫∑c None\n",
        "        if not gt_text or not pred_text or gt_text is None or pred_text is None:\n",
        "            continue\n",
        "\n",
        "        # M√£ h√≥a vƒÉn b·∫£n th√†nh vector\n",
        "        gt_embedding = model.encode(str(gt_text))\n",
        "        pred_embedding = model.encode(str(pred_text))\n",
        "\n",
        "        # T√≠nh cosine similarity\n",
        "        similarity = pairwise.cosine_similarity([gt_embedding], [pred_embedding])[0][0]\n",
        "        similarities.append(similarity)\n",
        "\n",
        "    # T√≠nh ƒëi·ªÉm trung b√¨nh\n",
        "    return float(np.mean(similarities)) if similarities else 0.0\n",
        "\n",
        "def evaluate_semantic_similarity(ground_truth_json: List[str], predicted_json: List[str]) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    ƒê√°nh gi√° ƒë·ªô t∆∞∆°ng ƒë·ªìng ng·ªØ nghƒ©a cho c√°c tr∆∞·ªùng vƒÉn b·∫£n\n",
        "\n",
        "    Args:\n",
        "        ground_truth_json: Danh s√°ch chu·ªói JSON chu·∫©n\n",
        "        predicted_json: Danh s√°ch chu·ªói JSON d·ª± ƒëo√°n\n",
        "\n",
        "    Returns:\n",
        "        Dict: K·∫øt qu·∫£ semantic similarity cho t·ª´ng tr∆∞·ªùng\n",
        "    \"\"\"\n",
        "    # T·∫£i m√¥ h√¨nh sentence transformer\n",
        "    model = load_sentence_transformer()\n",
        "\n",
        "    # Ch·ªâ l·∫•y c√°c JSON h·ª£p l·ªá\n",
        "    valid_gt = []\n",
        "    for js in ground_truth_json:\n",
        "        try:\n",
        "            data = json.loads(js)\n",
        "            jsonschema.validate(instance=data, schema=COOKIE_SCHEMA)\n",
        "            valid_gt.extend(data)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    valid_pred = []\n",
        "    for js in predicted_json:\n",
        "        try:\n",
        "            data = json.loads(js)\n",
        "            jsonschema.validate(instance=data, schema=COOKIE_SCHEMA)\n",
        "            valid_pred.extend(data)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    # C√°c tr∆∞·ªùng vƒÉn b·∫£n c·∫ßn ƒë√°nh gi√° semantic similarity\n",
        "    text_fields = [\"declared_purpose\", \"declared_description\", \"declared_retention\"]\n",
        "\n",
        "    results = {}\n",
        "    for field in text_fields:\n",
        "        similarity = compute_semantic_similarity(valid_gt, valid_pred, field, model)\n",
        "        results[field] = similarity\n",
        "\n",
        "    # T√≠nh ƒëi·ªÉm trung b√¨nh\n",
        "    results[\"average\"] = float(np.mean(list(results.values()))) if results else 0.0\n",
        "\n",
        "    return results\n",
        "\n",
        "# H√†m t·ªïng h·ª£p t·∫•t c·∫£ c√°c metrics\n",
        "def evaluate_cookie_extraction(ground_truth_json: List[str], predicted_json: List[str]) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    ƒê√°nh gi√° to√†n di·ªán vi·ªác tr√≠ch xu·∫•t cookie\n",
        "\n",
        "    Args:\n",
        "        ground_truth_json: Danh s√°ch chu·ªói JSON chu·∫©n\n",
        "        predicted_json: Danh s√°ch chu·ªói JSON d·ª± ƒëo√°n\n",
        "\n",
        "    Returns:\n",
        "        Dict: K·∫øt qu·∫£ t·∫•t c·∫£ c√°c metrics\n",
        "    \"\"\"\n",
        "    # 1. JSON Validity\n",
        "    validity_rate = json_validity_rate(predicted_json)\n",
        "\n",
        "    # 2. Field metrics (precision, recall, F1)\n",
        "    field_metrics = evaluate_field_metrics(ground_truth_json, predicted_json)\n",
        "\n",
        "    # 3. Semantic similarity\n",
        "    semantic_metrics = evaluate_semantic_similarity(ground_truth_json, predicted_json)\n",
        "\n",
        "    # T·ªïng h·ª£p k·∫øt qu·∫£\n",
        "    results = {\n",
        "        \"json_validity_rate\": validity_rate,\n",
        "        \"field_metrics\": field_metrics,\n",
        "        \"semantic_similarity\": semantic_metrics\n",
        "    }\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yi7JsK5Zdcd1"
      },
      "source": [
        "### H√†m ƒë√°nh gi√° m√¥ h√¨nh v·ªõi is_sperific"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "WTkEzRZqdcd2"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import jsonschema\n",
        "import numpy as np\n",
        "from typing import List, Dict, Any, Union, Tuple\n",
        "from collections import defaultdict\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import sklearn.metrics.pairwise as pairwise\n",
        "import re\n",
        "\n",
        "# Schema cho d·ªØ li·ªáu cookie ƒë√£ c·∫≠p nh·∫≠t\n",
        "COOKIE_SCHEMA = {\n",
        "    \"type\": \"object\",\n",
        "    \"required\": [\"is_specific\", \"cookies\"],\n",
        "    \"properties\": {\n",
        "        \"is_specific\": {\n",
        "            \"type\": \"integer\",\n",
        "            \"enum\": [0, 1],\n",
        "        },\n",
        "        \"cookies\": {\n",
        "            \"type\": \"array\",\n",
        "            \"items\": {\n",
        "                \"type\": \"object\",\n",
        "                \"required\": [\n",
        "                    \"cookie_name\",\n",
        "                    \"declared_purpose\",\n",
        "                    \"declared_retention\",\n",
        "                    \"declared_third_parties\",\n",
        "                    \"declared_description\"\n",
        "                ],\n",
        "                \"properties\": {\n",
        "                    \"cookie_name\": {\n",
        "                        \"type\": \"string\",\n",
        "                    },\n",
        "                    \"declared_purpose\": {\n",
        "                        \"type\": \"string\",\n",
        "                    },\n",
        "                    \"declared_retention\": {\n",
        "                        \"type\": [\"string\", \"null\"],\n",
        "                    },\n",
        "                    \"declared_third_parties\": {\n",
        "                        \"type\": \"array\",\n",
        "                        \"items\": {\n",
        "                            \"type\": \"string\"\n",
        "                        },\n",
        "                    },\n",
        "                    \"declared_description\": {\n",
        "                        \"type\": [\"string\", \"null\"],\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# 1. JSON Validity\n",
        "def validate_json_format(predicted_json_str: str) -> bool:\n",
        "    \"\"\"\n",
        "    Ki·ªÉm tra xem chu·ªói JSON c√≥ h·ª£p l·ªá theo schema m·ªõi hay kh√¥ng\n",
        "\n",
        "    Args:\n",
        "        predicted_json_str: Chu·ªói JSON c·∫ßn ki·ªÉm tra\n",
        "\n",
        "    Returns:\n",
        "        bool: True n·∫øu JSON h·ª£p l·ªá, False n·∫øu kh√¥ng\n",
        "    \"\"\"\n",
        "    try:\n",
        "        json_data = ast.literal_eval(predicted_json_str)\n",
        "        jsonschema.validate(instance=json_data, schema=COOKIE_SCHEMA)\n",
        "        return True\n",
        "    except (json.JSONDecodeError, jsonschema.exceptions.ValidationError):\n",
        "        return False\n",
        "\n",
        "def json_validity_rate(predicted_json_strings: List[str]) -> float:\n",
        "    \"\"\"\n",
        "    T√≠nh t·ª∑ l·ªá c√°c chu·ªói JSON h·ª£p l·ªá theo schema ƒë√£ ƒë·ªãnh nghƒ©a\n",
        "\n",
        "    Args:\n",
        "        predicted_json_strings: Danh s√°ch c√°c chu·ªói JSON d·ª± ƒëo√°n t·ª´ m√¥ h√¨nh\n",
        "\n",
        "    Returns:\n",
        "        float: T·ª∑ l·ªá h·ª£p l·ªá (0-1)\n",
        "    \"\"\"\n",
        "    valid_count = sum(validate_json_format(js) for js in predicted_json_strings)\n",
        "    return valid_count / len(predicted_json_strings) if predicted_json_strings else 0\n",
        "\n",
        "# 2. Precision, Recall, F1-score cho t·ª´ng tr∆∞·ªùng\n",
        "def normalize_text(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Chu·∫©n h√≥a vƒÉn b·∫£n ƒë·ªÉ so s√°nh\n",
        "\n",
        "    Args:\n",
        "        text: VƒÉn b·∫£n c·∫ßn chu·∫©n h√≥a\n",
        "\n",
        "    Returns:\n",
        "        str: VƒÉn b·∫£n ƒë√£ ƒë∆∞·ª£c chu·∫©n h√≥a\n",
        "    \"\"\"\n",
        "    if text is None:\n",
        "        return \"\"\n",
        "    return re.sub(r'\\s+', ' ', text.lower().strip())\n",
        "\n",
        "def extract_valid_cookies(json_strings: List[str]) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Tr√≠ch xu·∫•t d·ªØ li·ªáu t·ª´ c√°c chu·ªói JSON v√† ch·ªâ gi·ªØ l·∫°i c√°c JSON h·ª£p l·ªá\n",
        "\n",
        "    Args:\n",
        "        json_strings: Danh s√°ch c√°c chu·ªói JSON\n",
        "\n",
        "    Returns:\n",
        "        List[Dict]: Danh s√°ch c√°c ƒë·ªëi t∆∞·ª£ng JSON h·ª£p l·ªá\n",
        "    \"\"\"\n",
        "    result = []\n",
        "    for js in json_strings:\n",
        "        try:\n",
        "            data = ast.literal_eval(js)\n",
        "            jsonschema.validate(instance=data, schema=COOKIE_SCHEMA)\n",
        "            result.append(data)\n",
        "        except (json.JSONDecodeError, jsonschema.exceptions.ValidationError):\n",
        "            pass\n",
        "    return result\n",
        "\n",
        "def exact_match_metrics(ground_truth: List[Dict], predictions: List[Dict], field: str) -> Tuple[float, float, float]:\n",
        "    \"\"\"\n",
        "    T√≠nh precision, recall, F1 cho vi·ªác so kh·ªõp ch√≠nh x√°c m·ªôt tr∆∞·ªùng trong cookies\n",
        "\n",
        "    Args:\n",
        "        ground_truth: Danh s√°ch ƒë·ªëi t∆∞·ª£ng JSON chu·∫©n\n",
        "        predictions: Danh s√°ch ƒë·ªëi t∆∞·ª£ng JSON d·ª± ƒëo√°n\n",
        "        field: T√™n tr∆∞·ªùng c·∫ßn ƒë√°nh gi√°\n",
        "\n",
        "    Returns:\n",
        "        Tuple[float, float, float]: (precision, recall, F1-score)\n",
        "    \"\"\"\n",
        "    # T·∫°o √°nh x·∫° t·ª´ cookie_name sang gi√° tr·ªã tr∆∞·ªùng c·∫ßn ƒë√°nh gi√°\n",
        "    gt_cookies = []\n",
        "    for doc in ground_truth:\n",
        "        gt_cookies.extend(doc.get(\"cookies\", []))\n",
        "\n",
        "    pred_cookies = []\n",
        "    for doc in predictions:\n",
        "        pred_cookies.extend(doc.get(\"cookies\", []))\n",
        "\n",
        "    gt_map = {item[\"cookie_name\"]: item.get(field) for item in gt_cookies if \"cookie_name\" in item}\n",
        "    pred_map = {item[\"cookie_name\"]: item.get(field) for item in pred_cookies if \"cookie_name\" in item}\n",
        "\n",
        "    # X·ª≠ l√Ω tr∆∞·ªùng h·ª£p ƒë·∫∑c bi·ªát cho declared_third_parties l√† m·∫£ng\n",
        "    if field == \"declared_third_parties\":\n",
        "        # Chuy·ªÉn th√†nh set ƒë·ªÉ so s√°nh kh√¥ng ph·ª• thu·ªôc th·ª© t·ª±\n",
        "        gt_map = {k: set(v) if v is not None else set() for k, v in gt_map.items()}\n",
        "        pred_map = {k: set(v) if v is not None else set() for k, v in pred_map.items()}\n",
        "    else:\n",
        "        # Chu·∫©n h√≥a d·ªØ li·ªáu vƒÉn b·∫£n\n",
        "        gt_map = {k: normalize_text(v) for k, v in gt_map.items()}\n",
        "        pred_map = {k: normalize_text(v) for k, v in pred_map.items()}\n",
        "\n",
        "    # ƒê·∫øm s·ªë l∆∞·ª£ng predicted cookies v√† ground truth cookies\n",
        "    total_gt = len(gt_map)\n",
        "    total_pred = len(pred_map)\n",
        "\n",
        "    # ƒê·∫øm c√°c tr∆∞·ªùng h·ª£p True Positive\n",
        "    tp = 0\n",
        "    for cookie_name in set(gt_map.keys()) & set(pred_map.keys()):\n",
        "        if field == \"declared_third_parties\":\n",
        "            if gt_map[cookie_name] == pred_map[cookie_name]:\n",
        "                tp += 1\n",
        "        else:\n",
        "            if gt_map[cookie_name] == pred_map[cookie_name]:\n",
        "                tp += 1\n",
        "\n",
        "    # T√≠nh precision, recall, F1\n",
        "    precision = tp / total_pred if total_pred > 0 else 0\n",
        "    recall = tp / total_gt if total_gt > 0 else 0\n",
        "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "    return precision, recall, f1\n",
        "\n",
        "def evaluate_is_specific_classification(ground_truth_json: List[str], predicted_json: List[str]) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    ƒê√°nh gi√° accuracy cho vi·ªác ph√¢n lo·∫°i is_specific\n",
        "\n",
        "    Args:\n",
        "        ground_truth_json: Danh s√°ch chu·ªói JSON chu·∫©n\n",
        "        predicted_json: Danh s√°ch chu·ªói JSON d·ª± ƒëo√°n\n",
        "\n",
        "    Returns:\n",
        "        Dict: K·∫øt qu·∫£ accuracy cho is_specific\n",
        "    \"\"\"\n",
        "    valid_gt = extract_valid_cookies(ground_truth_json)\n",
        "    valid_pred = extract_valid_cookies(predicted_json)\n",
        "\n",
        "    if not valid_gt or not valid_pred:\n",
        "        return {\"accuracy\": 0.0}\n",
        "\n",
        "    correct = 0\n",
        "    total = len(valid_gt)\n",
        "\n",
        "    for i in range(total):\n",
        "        if valid_gt[i].get(\"is_specific\") == valid_pred[i].get(\"is_specific\"):\n",
        "            correct += 1\n",
        "\n",
        "    accuracy = correct / total if total > 0 else 0\n",
        "\n",
        "    return {\"accuracy\": accuracy}\n",
        "\n",
        "def evaluate_field_metrics(ground_truth_json: List[str], predicted_json: List[str]) -> Dict[str, Dict[str, float]]:\n",
        "    \"\"\"\n",
        "    ƒê√°nh gi√° metrics cho t·∫•t c·∫£ c√°c tr∆∞·ªùng trong cookies\n",
        "\n",
        "    Args:\n",
        "        ground_truth_json: Danh s√°ch chu·ªói JSON chu·∫©n\n",
        "        predicted_json: Danh s√°ch chu·ªói JSON d·ª± ƒëo√°n\n",
        "\n",
        "    Returns:\n",
        "        Dict: K·∫øt qu·∫£ metrics cho t·ª´ng tr∆∞·ªùng\n",
        "    \"\"\"\n",
        "    # L·∫•y c√°c JSON h·ª£p l·ªá\n",
        "    valid_gt = extract_valid_cookies(ground_truth_json)\n",
        "    valid_pred = extract_valid_cookies(predicted_json)\n",
        "\n",
        "    if not valid_gt or not valid_pred:\n",
        "        empty_metrics = {\"precision\": 0.0, \"recall\": 0.0, \"f1\": 0.0}\n",
        "        return {\n",
        "            \"cookie_name\": empty_metrics,\n",
        "            \"declared_purpose\": empty_metrics,\n",
        "            \"declared_retention\": empty_metrics,\n",
        "            \"declared_third_parties\": empty_metrics,\n",
        "            \"declared_description\": empty_metrics\n",
        "        }\n",
        "\n",
        "    fields = [\"cookie_name\", \"declared_purpose\", \"declared_retention\",\n",
        "              \"declared_third_parties\", \"declared_description\"]\n",
        "\n",
        "    results = {}\n",
        "    for field in fields:\n",
        "        precision, recall, f1 = exact_match_metrics(valid_gt, valid_pred, field)\n",
        "        results[field] = {\n",
        "            \"precision\": precision,\n",
        "            \"recall\": recall,\n",
        "            \"f1\": f1\n",
        "        }\n",
        "\n",
        "    return results\n",
        "\n",
        "# 3. Semantic Similarity\n",
        "def load_sentence_transformer():\n",
        "    \"\"\"T·∫£i m√¥ h√¨nh sentence transformer\"\"\"\n",
        "    try:\n",
        "        return SentenceTransformer('all-MiniLM-L6-v2')\n",
        "    except:\n",
        "        print(\"C·∫ßn c√†i ƒë·∫∑t sentence-transformers: pip install sentence-transformers\")\n",
        "        return None\n",
        "\n",
        "def compute_semantic_similarity(ground_truth: List[Dict], predictions: List[Dict],\n",
        "                               field: str, model) -> float:\n",
        "    \"\"\"\n",
        "    T√≠nh to√°n ƒë·ªô t∆∞∆°ng ƒë·ªìng ng·ªØ nghƒ©a cho m·ªôt tr∆∞·ªùng trong cookies\n",
        "\n",
        "    Args:\n",
        "        ground_truth: Danh s√°ch ƒë·ªëi t∆∞·ª£ng JSON chu·∫©n\n",
        "        predictions: Danh s√°ch ƒë·ªëi t∆∞·ª£ng JSON d·ª± ƒëo√°n\n",
        "        field: T√™n tr∆∞·ªùng c·∫ßn ƒë√°nh gi√°\n",
        "        model: M√¥ h√¨nh sentence transformer\n",
        "\n",
        "    Returns:\n",
        "        float: ƒêi·ªÉm t∆∞∆°ng ƒë·ªìng ng·ªØ nghƒ©a trung b√¨nh\n",
        "    \"\"\"\n",
        "    if model is None:\n",
        "        return 0.0\n",
        "\n",
        "    # L·∫•y danh s√°ch cookies t·ª´ m·ªói ƒë·ªëi t∆∞·ª£ng JSON\n",
        "    gt_cookies = []\n",
        "    for doc in ground_truth:\n",
        "        gt_cookies.extend(doc.get(\"cookies\", []))\n",
        "\n",
        "    pred_cookies = []\n",
        "    for doc in predictions:\n",
        "        pred_cookies.extend(doc.get(\"cookies\", []))\n",
        "\n",
        "    # T·∫°o √°nh x·∫° t·ª´ cookie_name sang gi√° tr·ªã tr∆∞·ªùng c·∫ßn ƒë√°nh gi√°\n",
        "    gt_map = {item[\"cookie_name\"]: item.get(field, \"\") for item in gt_cookies if \"cookie_name\" in item}\n",
        "    pred_map = {item[\"cookie_name\"]: item.get(field, \"\") for item in pred_cookies if \"cookie_name\" in item}\n",
        "\n",
        "    # Ch·ªâ so s√°nh c√°c cookie c√πng t√™n\n",
        "    common_names = set(gt_map.keys()) & set(pred_map.keys())\n",
        "\n",
        "    if not common_names or field == \"declared_third_parties\":  # Kh√¥ng √°p d·ª•ng semantic similarity cho m·∫£ng\n",
        "        return 0.0\n",
        "\n",
        "    similarities = []\n",
        "    for name in common_names:\n",
        "        gt_text = gt_map[name]\n",
        "        pred_text = pred_map[name]\n",
        "\n",
        "        # B·ªè qua c√°c tr∆∞·ªùng r·ªóng ho·∫∑c None\n",
        "        if not gt_text or not pred_text or gt_text is None or pred_text is None:\n",
        "            continue\n",
        "\n",
        "        # M√£ h√≥a vƒÉn b·∫£n th√†nh vector\n",
        "        gt_embedding = model.encode(str(gt_text))\n",
        "        pred_embedding = model.encode(str(pred_text))\n",
        "\n",
        "        # T√≠nh cosine similarity\n",
        "        similarity = pairwise.cosine_similarity([gt_embedding], [pred_embedding])[0][0]\n",
        "        similarities.append(similarity)\n",
        "\n",
        "    # T√≠nh ƒëi·ªÉm trung b√¨nh\n",
        "    return float(np.mean(similarities)) if similarities else 0.0\n",
        "\n",
        "def evaluate_semantic_similarity(ground_truth_json: List[str], predicted_json: List[str]) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    ƒê√°nh gi√° ƒë·ªô t∆∞∆°ng ƒë·ªìng ng·ªØ nghƒ©a cho c√°c tr∆∞·ªùng vƒÉn b·∫£n\n",
        "\n",
        "    Args:\n",
        "        ground_truth_json: Danh s√°ch chu·ªói JSON chu·∫©n\n",
        "        predicted_json: Danh s√°ch chu·ªói JSON d·ª± ƒëo√°n\n",
        "\n",
        "    Returns:\n",
        "        Dict: K·∫øt qu·∫£ semantic similarity cho t·ª´ng tr∆∞·ªùng\n",
        "    \"\"\"\n",
        "    # T·∫£i m√¥ h√¨nh sentence transformer\n",
        "    model = load_sentence_transformer()\n",
        "\n",
        "    # L·∫•y c√°c JSON h·ª£p l·ªá\n",
        "    valid_gt = extract_valid_cookies(ground_truth_json)\n",
        "    valid_pred = extract_valid_cookies(predicted_json)\n",
        "\n",
        "    if not valid_gt or not valid_pred or model is None:\n",
        "        return {\n",
        "            \"declared_purpose\": 0.0,\n",
        "            \"declared_description\": 0.0,\n",
        "            \"declared_retention\": 0.0,\n",
        "            \"average\": 0.0\n",
        "        }\n",
        "\n",
        "    # C√°c tr∆∞·ªùng vƒÉn b·∫£n c·∫ßn ƒë√°nh gi√° semantic similarity\n",
        "    text_fields = [\"declared_purpose\", \"declared_description\", \"declared_retention\"]\n",
        "\n",
        "    results = {}\n",
        "    for field in text_fields:\n",
        "        similarity = compute_semantic_similarity(valid_gt, valid_pred, field, model)\n",
        "        results[field] = similarity\n",
        "\n",
        "    # T√≠nh ƒëi·ªÉm trung b√¨nh\n",
        "    results[\"average\"] = float(np.mean(list(results.values()))) if results else 0.0\n",
        "\n",
        "    return results\n",
        "\n",
        "# 4. Cookie Count Accuracy\n",
        "def evaluate_cookie_count_accuracy(ground_truth_json: List[str], predicted_json: List[str]) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    ƒê√°nh gi√° ƒë·ªô ch√≠nh x√°c v·ªÅ s·ªë l∆∞·ª£ng cookie ƒë∆∞·ª£c tr√≠ch xu·∫•t\n",
        "\n",
        "    Args:\n",
        "        ground_truth_json: Danh s√°ch chu·ªói JSON chu·∫©n\n",
        "        predicted_json: Danh s√°ch chu·ªói JSON d·ª± ƒëo√°n\n",
        "\n",
        "    Returns:\n",
        "        Dict: K·∫øt qu·∫£ ƒë√°nh gi√° s·ªë l∆∞·ª£ng cookie\n",
        "    \"\"\"\n",
        "    valid_gt = extract_valid_cookies(ground_truth_json)\n",
        "    valid_pred = extract_valid_cookies(predicted_json)\n",
        "\n",
        "    if not valid_gt:\n",
        "        return {\"cookie_count_accuracy\": 0.0}\n",
        "\n",
        "    # ƒê·∫øm s·ªë l∆∞·ª£ng cookie trong m·ªói JSON\n",
        "    gt_counts = [len(doc.get(\"cookies\", [])) for doc in valid_gt]\n",
        "    pred_counts = [len(doc.get(\"cookies\", [])) for doc in valid_pred]\n",
        "\n",
        "    # T√≠nh m·ª©c ƒë·ªô ch√™nh l·ªách tuy·ªát ƒë·ªëi trung b√¨nh\n",
        "    total_docs = min(len(gt_counts), len(pred_counts))\n",
        "    if total_docs == 0:\n",
        "        return {\"cookie_count_accuracy\": 0.0}\n",
        "\n",
        "    abs_diff_sum = sum(abs(gt_counts[i] - pred_counts[i]) for i in range(total_docs))\n",
        "    mean_abs_diff = abs_diff_sum / total_docs\n",
        "\n",
        "    # T√≠nh ƒë·ªô ch√≠nh x√°c c·ªßa s·ªë l∆∞·ª£ng cookie (0-1, c√†ng cao c√†ng t·ªët)\n",
        "    max_gt_count = max(gt_counts) if gt_counts else 1\n",
        "    cookie_count_accuracy = max(0, 1 - (mean_abs_diff / max_gt_count))\n",
        "\n",
        "    return {\"cookie_count_accuracy\": cookie_count_accuracy}\n",
        "\n",
        "# H√†m t·ªïng h·ª£p t·∫•t c·∫£ c√°c metrics\n",
        "def evaluate_cookie_extraction(ground_truth_json: List[str], predicted_json: List[str]) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    ƒê√°nh gi√° to√†n di·ªán vi·ªác tr√≠ch xu·∫•t cookie v√† ph√¢n lo·∫°i is_specific\n",
        "\n",
        "    Args:\n",
        "        ground_truth_json: Danh s√°ch chu·ªói JSON chu·∫©n\n",
        "        predicted_json: Danh s√°ch chu·ªói JSON d·ª± ƒëo√°n\n",
        "\n",
        "    Returns:\n",
        "        Dict: K·∫øt qu·∫£ t·∫•t c·∫£ c√°c metrics\n",
        "    \"\"\"\n",
        "    # 1. JSON Validity\n",
        "    validity_rate = json_validity_rate(predicted_json)\n",
        "\n",
        "    # 2. Field metrics (precision, recall, F1)\n",
        "    field_metrics = evaluate_field_metrics(ground_truth_json, predicted_json)\n",
        "\n",
        "    # 3. is_specific classification accuracy\n",
        "    is_specific_metrics = evaluate_is_specific_classification(ground_truth_json, predicted_json)\n",
        "\n",
        "    # 4. Cookie count accuracy\n",
        "    cookie_count_metrics = evaluate_cookie_count_accuracy(ground_truth_json, predicted_json)\n",
        "\n",
        "    # 5. Semantic similarity\n",
        "    semantic_metrics = evaluate_semantic_similarity(ground_truth_json, predicted_json)\n",
        "\n",
        "    # T√≠nh overall accuracy d·ª±a tr√™n trung b√¨nh c·ªßa c√°c metrics ch√≠nh\n",
        "    # K·∫øt h·ª£p F1 c·ªßa c√°c tr∆∞·ªùng + accuracy c·ªßa is_specific\n",
        "    f1_scores = [metrics[\"f1\"] for field, metrics in field_metrics.items()]\n",
        "    overall_accuracy = (sum(f1_scores) + is_specific_metrics[\"accuracy\"] + cookie_count_metrics[\"cookie_count_accuracy\"]) / (len(f1_scores) + 2)\n",
        "\n",
        "    # T·ªïng h·ª£p k·∫øt qu·∫£\n",
        "    results = {\n",
        "        \"json_validity_rate\": validity_rate,\n",
        "        \"field_metrics\": field_metrics,\n",
        "        \"is_specific_classification\": is_specific_metrics,\n",
        "        \"cookie_count_metrics\": cookie_count_metrics,\n",
        "        \"semantic_similarity\": semantic_metrics,\n",
        "        \"overall_accuracy\": overall_accuracy\n",
        "    }\n",
        "\n",
        "    return results\n",
        "\n",
        "# H√†m h·ªó tr·ª£ ƒë√°nh gi√° v·ªõi ƒë·∫ßu v√†o t·ª´ file\n",
        "def evaluate_from_files(ground_truth_file: str, prediction_file: str) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    ƒê√°nh gi√° t·ª´ c√°c file ch·ª©a JSON\n",
        "\n",
        "    Args:\n",
        "        ground_truth_file: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file ch·ª©a JSON chu·∫©n\n",
        "        prediction_file: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file ch·ª©a JSON d·ª± ƒëo√°n\n",
        "\n",
        "    Returns:\n",
        "        Dict: K·∫øt qu·∫£ t·∫•t c·∫£ c√°c metrics\n",
        "    \"\"\"\n",
        "    with open(ground_truth_file, 'r', encoding='utf-8') as f:\n",
        "        ground_truth_json = [line.strip() for line in f if line.strip()]\n",
        "\n",
        "    with open(prediction_file, 'r', encoding='utf-8') as f:\n",
        "        predicted_json = [line.strip() for line in f if line.strip()]\n",
        "\n",
        "    return evaluate_cookie_extraction(ground_truth_json, predicted_json)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-7-qCEgnBmm"
      },
      "source": [
        "### ƒê√°nh gi√° m√¥ h√¨nh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "5SqbAmE5mlIA"
      },
      "outputs": [],
      "source": [
        "def generate_response(messages, max_new_tokens=4096, temperature=0):\n",
        "\n",
        "    inputs = tokenizer(messages, return_tensors=\"pt\", truncation=True,\n",
        "                       max_length=max_new_tokens\n",
        "                       ).to(device)\n",
        "\n",
        "    # T·∫°o ƒë·∫ßu ra\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            do_sample=temperature > 0,\n",
        "            temperature=temperature,\n",
        "            top_p=1,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    # # Decode the prediction\n",
        "    decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    result_text = decoded_output.split(\"### Response:\")[-1].strip()\n",
        "\n",
        "\n",
        "    # # Tr√≠ch xu·∫•t ph·∫ßn JSON\n",
        "    json_start = result_text.find(\"{\")\n",
        "    json_end = result_text.rfind(\"}\")\n",
        "    if json_start != -1 and json_end != -1 and json_end > json_start:\n",
        "        json_text = result_text[json_start:json_end+1]\n",
        "        return json_text\n",
        "\n",
        "    return result_text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_response(\"how are you today\")"
      ],
      "metadata": {
        "id": "Kev3j1dVzngZ",
        "outputId": "e32b896b-4b55-4f75-b554-2bcf629bb927",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'Qwen2Model' object has no attribute 'max_seq_length'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-5fd6634c97a8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerate_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"how are you today\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-087b2b98c8d8>\u001b[0m in \u001b[0;36mgenerate_response\u001b[0;34m(messages, max_new_tokens, temperature)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# T·∫°o ƒë·∫ßu ra\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         outputs = model.generate(\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1873\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_peft_forward_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1874\u001b[0m                     \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial_peft_forward_args\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1875\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1876\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1877\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, **kwargs)\u001b[0m\n\u001b[1;32m   2463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2464\u001b[0m             \u001b[0;31m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2465\u001b[0;31m             result = self._sample(\n\u001b[0m\u001b[1;32m   2466\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2467\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepared_logits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3430\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_prefill\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3431\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3432\u001b[0m                 \u001b[0mis_prefill\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3433\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36m_CausalLM_fast_forward\u001b[0;34m(self, input_ids, causal_mask, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, num_logits_to_keep, logits_to_keep, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             \u001b[0;31m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_no_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m             outputs = self.model(\n\u001b[0m\u001b[1;32m   1051\u001b[0m                 \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m                 \u001b[0mcausal_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcausal_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36mLlamaModel_fast_forward\u001b[0;34m(self, input_ids, causal_mask, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, *args, **kwargs)\u001b[0m\n\u001b[1;32m    707\u001b[0m             \u001b[0minputs_embeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_seq_length\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# Must resize!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m         \u001b[0minputs_embeds\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_requires_grad\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1926\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1927\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1928\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m   1929\u001b[0m             \u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1930\u001b[0m         )\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Qwen2Model' object has no attribute 'max_seq_length'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "\n",
        "def evaluate_model(eval_data: Dataset, batch_size: int = 4, checkpoint_interval: int = 10,\n",
        "                checkpoint_path: str = \"/content/drive/MyDrive/Project/Models-v3/Qwen2.5-3B-Instruct_SFT/eval_checkpoint.json\") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    ƒê√°nh gi√° m√¥ h√¨nh tr√™n t·∫≠p d·ªØ li·ªáu v·ªõi kh·∫£ nƒÉng l∆∞u checkpoint\n",
        "\n",
        "    Args:\n",
        "      eval_data: T·∫≠p d·ªØ li·ªáu ƒë√°nh gi√° (Dataset object)\n",
        "      batch_size: S·ªë l∆∞·ª£ng m·∫´u x·ª≠ l√Ω c√πng l√∫c\n",
        "      checkpoint_interval: S·ªë l∆∞·ª£ng m·∫´u x·ª≠ l√Ω tr∆∞·ªõc khi l∆∞u checkpoint\n",
        "      checkpoint_path: ƒê∆∞·ªùng d·∫´n ƒë·ªÉ l∆∞u t·ªáp checkpoint\n",
        "\n",
        "    Returns:\n",
        "      Dict: K·∫øt qu·∫£ ƒë√°nh gi√°\n",
        "    \"\"\"\n",
        "    if not model or not tokenizer:\n",
        "      raise ValueError(\"C·∫ßn t·∫£i m√¥ h√¨nh tr∆∞·ªõc khi ƒë√°nh gi√°\")\n",
        "\n",
        "    all_ground_truth = []\n",
        "    all_predictions = []\n",
        "\n",
        "    # Ki·ªÉm tra xem c√≥ checkpoint tr∆∞·ªõc ƒë√≥ hay kh√¥ng\n",
        "    start_idx = 0\n",
        "    if os.path.exists(checkpoint_path):\n",
        "        try:\n",
        "            with open(checkpoint_path, 'r', encoding='utf-8') as f:\n",
        "                checkpoint_data = json.load(f)\n",
        "                all_ground_truth = checkpoint_data.get('ground_truth', [])\n",
        "                all_predictions = checkpoint_data.get('predictions', [])\n",
        "                start_idx = checkpoint_data.get('next_idx', 0)\n",
        "                print(f\"ƒê√£ t·∫£i checkpoint, ti·∫øp t·ª•c t·ª´ m·∫´u {start_idx}/{len(eval_data)}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Kh√¥ng th·ªÉ t·∫£i checkpoint: {str(e)}, b·∫Øt ƒë·∫ßu t·ª´ ƒë·∫ßu\")\n",
        "    else:\n",
        "      print(\"Start from zero! \")\n",
        "    # T√≠nh s·ªë m·∫´u ƒë√£ x·ª≠ l√Ω\n",
        "#     processed_samples = len(all_ground_truth)\n",
        "\n",
        "#     for i in tqdm(range(start_idx, len(eval_data), batch_size), desc=\"ƒê√°nh gi√°\"):\n",
        "#       batch = [eval_data[j] for j in range(i, min(i + batch_size, len(eval_data)))]\n",
        "\n",
        "#       for sample in batch:\n",
        "#         try:\n",
        "#           # L·∫•y ground truth\n",
        "#           ground_truth = f\"\"\"\n",
        "# {{\n",
        "#   'is_specific': {sample['is_specific']},\n",
        "#   'extracted_cookies': {sample['extracted_cookies']}\n",
        "# }}\"\"\"\n",
        "#           all_ground_truth.append(ground_truth)\n",
        "#           print(\"------> Ground_truth: \", ground_truth)\n",
        "\n",
        "#           # Sinh d·ª± ƒëo√°n\n",
        "#           prediction = generate_response(sample['text'])\n",
        "#           print(\"-----> Predict: \", prediction)\n",
        "#           all_predictions.append(prediction)\n",
        "\n",
        "#           # TƒÉng s·ªë m·∫´u ƒë√£ x·ª≠ l√Ω\n",
        "#           processed_samples += 1\n",
        "\n",
        "#           # L∆∞u checkpoint sau m·ªói checkpoint_interval m·∫´u\n",
        "#           if processed_samples % checkpoint_interval == 0:\n",
        "#               save_checkpoint(all_ground_truth, all_predictions, i + 1, checkpoint_path)\n",
        "#               print(f\"ƒê√£ l∆∞u checkpoint sau khi x·ª≠ l√Ω {processed_samples} m·∫´u\")\n",
        "\n",
        "#         except Exception as e:\n",
        "#           print(f\"L·ªói khi x·ª≠ l√Ω m·∫´u {i}: {str(e)}\")\n",
        "\n",
        "    print(\"----------Start to evaluate----------\")\n",
        "    # ƒê√°nh gi√° k·∫øt qu·∫£ sau khi ho√†n th√†nh\n",
        "    overall_result = evaluate_cookie_extraction(all_ground_truth, all_predictions)\n",
        "\n",
        "    return {\n",
        "      'overall': overall_result,\n",
        "    }\n",
        "\n",
        "def save_checkpoint(ground_truth: list, predictions: list, next_idx: int, checkpoint_path: str):\n",
        "    \"\"\"\n",
        "    L∆∞u tr·∫°ng th√°i hi·ªán t·∫°i c·ªßa qu√° tr√¨nh ƒë√°nh gi√°\n",
        "\n",
        "    Args:\n",
        "        ground_truth: Danh s√°ch ground truth ƒë√£ x·ª≠ l√Ω\n",
        "        predictions: Danh s√°ch d·ª± ƒëo√°n ƒë√£ x·ª≠ l√Ω\n",
        "        next_idx: Ch·ªâ s·ªë m·∫´u ti·∫øp theo s·∫Ω x·ª≠ l√Ω\n",
        "        checkpoint_path: ƒê∆∞·ªùng d·∫´n l∆∞u t·ªáp checkpoint\n",
        "    \"\"\"\n",
        "    checkpoint_data = {\n",
        "        'ground_truth': ground_truth,\n",
        "        'predictions': predictions,\n",
        "        'next_idx': next_idx,\n",
        "        'timestamp': datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    }\n",
        "\n",
        "    # T·∫°o th∆∞ m·ª•c ch·ª©a n·∫øu ch∆∞a t·ªìn t·∫°i\n",
        "    os.makedirs(os.path.dirname(checkpoint_path) if os.path.dirname(checkpoint_path) else '.', exist_ok=True)\n",
        "\n",
        "    with open(checkpoint_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(checkpoint_data, f, ensure_ascii=False)\n",
        "\n",
        "def save_evaluation_report(eval_results: Dict[str, Any], output_path: str = \"evaluation_report.json\"):\n",
        "    \"\"\"\n",
        "    L∆∞u b√°o c√°o ƒë√°nh gi√°\n",
        "\n",
        "    Args:\n",
        "        eval_results: K·∫øt qu·∫£ ƒë√°nh gi√°\n",
        "        output_path: ƒê∆∞·ªùng d·∫´n l∆∞u b√°o c√°o\n",
        "    \"\"\"\n",
        "    with open(output_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(eval_results, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    print(f\"ƒê√£ l∆∞u b√°o c√°o ƒë√°nh gi√° t·∫°i: {output_path}\")\n",
        "\n",
        "    summary = {\n",
        "        \"json_validity_rate\": eval_results['overall']['json_validity_rate'],\n",
        "        \"average_f1_scores\": {\n",
        "            field: metrics['f1']\n",
        "            for field, metrics in eval_results['overall']['field_metrics'].items()\n",
        "        },\n",
        "        \"average_semantic_similarity\": eval_results['overall']['semantic_similarity']['average']\n",
        "    }\n",
        "\n",
        "    print(\"\\n=== B√ÅO C√ÅO T√ìM T·∫ÆT ===\")\n",
        "    print(f\"T·ª∑ l·ªá JSON h·ª£p l·ªá: {summary['json_validity_rate']:.2%}\")\n",
        "    print(\"\\nF1-score trung b√¨nh theo tr∆∞·ªùng:\")\n",
        "    for field, score in summary['average_f1_scores'].items():\n",
        "        print(f\"  - {field}: {score:.4f}\")\n",
        "    print(f\"\\nƒê·ªô t∆∞∆°ng ƒë·ªìng ng·ªØ nghƒ©a trung b√¨nh: {summary['average_semantic_similarity']:.4f}\")"
      ],
      "metadata": {
        "id": "hknhOpDpeXcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nLONIRAnM0J"
      },
      "source": [
        "### B·∫Øt ƒë·∫ßu ƒë√°nh gi√°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ps_A4ueinK6s"
      },
      "outputs": [],
      "source": [
        "evaluate_result = evaluate_model(dataset, batch_size=4)\n",
        "\n",
        "results = evaluate_model(\n",
        "    dataset,\n",
        "    batch_size=16,\n",
        "    checkpoint_interval=32,  # L∆∞u sau m·ªói 30 m·∫´u\n",
        "    checkpoint_path=\"/content/drive/MyDrive/Project/Models-v3/Qwen2.5-3B-Instruct_SFT/eval_checkpoint.json\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_result"
      ],
      "metadata": {
        "id": "fx3si8TZ5_Ct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_evaluation_report(evaluate_result, \"/content/drive/MyDrive/Qwen2.5_(3B)-SFT/evaluation_report.json\")"
      ],
      "metadata": {
        "id": "0HqzIxok5_l-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_model_online = \"sonhask/Qwen2.5_3B_SFT_detect_cookies\"\n",
        "\n",
        "model.push_to_hub(new_model_online) # Online saving\n",
        "tokenizer.push_to_hub(new_model_online) # Online saving"
      ],
      "metadata": {
        "id": "-viRVvdel2rA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = \"meta-llama/meta-Llama-3.1-8B-Instruct\"\n",
        "peft_model = \"Llama_3_1_8B_GRPO_detect_cookies\"\n",
        "hub_id = \"sonhask/Llama_3_1_8B_GRPO_detect_cookies\"\n",
        "\n",
        "print(f\"[1/5] Loading base model: {base_model}\")\n",
        "base_model = FastLanguageModel.from_pretrained(\n",
        "    base_model,\n",
        "    return_dict=True,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
        "\n",
        "print(f\"[2/5] Loading adapter: {peft_model}\")\n",
        "model = PeftModel.from_pretrained(base_model, peft_model, device_map=\"auto\")\n",
        "\n",
        "print(\"[3/5] Merge base model and adapter\")\n",
        "model = model.merge_and_unload()\n",
        "\n",
        "print(f\"[4/5] Saving model and tokenizer in {hub_id}\")\n",
        "model.save_pretrained(f\"{hub_id}\")\n",
        "tokenizer.save_pretrained(f\"{hub_id}\")\n",
        "\n",
        "print(f\"[5/5] Uploading to Hugging Face Hub: {hub_id}\")\n",
        "model.push_to_hub(f\"{hub_id}\", use_temp_dir=False)\n",
        "tokenizer.push_to_hub(f\"{hub_id}\", use_temp_dir=False)\n",
        "\n",
        "print(\"Merged model uploaded to Hugging Face Hub!\")"
      ],
      "metadata": {
        "id": "6snCuRc5pwWA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "rD_-G4bHm8WZ"
      ],
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ff11f0bb506b47f7be210d111ba31bd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9becec72152640e08f06f5d84fc9b26e",
              "IPY_MODEL_c163660edb1a42dea70cbb0610a6206e",
              "IPY_MODEL_3f511e3d4fb64fe19738c4958d4a42f5"
            ],
            "layout": "IPY_MODEL_a87243b4a4064d958e72e95c37fc8d9f"
          }
        },
        "9becec72152640e08f06f5d84fc9b26e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa5fc6aa5fc74587b3750bad4c269ef3",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0b55b2ce2dd84b82a1866b20395ed2d1",
            "value": "Generating‚Äátrain‚Äásplit:‚Äá100%"
          }
        },
        "c163660edb1a42dea70cbb0610a6206e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_090127ddf76945fd93e9c0672a9afc71",
            "max": 8808,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_98b5dd0ecb974ebbb8b09ba3a04beab3",
            "value": 8808
          }
        },
        "3f511e3d4fb64fe19738c4958d4a42f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a74f64e3e45a4badbaff14311df70d30",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_5f2da80a8b8749dd8d9e9dea956fba9b",
            "value": "‚Äá8808/8808‚Äá[00:00&lt;00:00,‚Äá22997.22‚Äáexamples/s]"
          }
        },
        "a87243b4a4064d958e72e95c37fc8d9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa5fc6aa5fc74587b3750bad4c269ef3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b55b2ce2dd84b82a1866b20395ed2d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "090127ddf76945fd93e9c0672a9afc71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98b5dd0ecb974ebbb8b09ba3a04beab3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a74f64e3e45a4badbaff14311df70d30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f2da80a8b8749dd8d9e9dea956fba9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87f57da48df0446f85c4facd9a157ef9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_90a88e92429a4d44a099101e0da00bdb",
              "IPY_MODEL_623a355710fe4bc29162af72b806a7dd",
              "IPY_MODEL_6f926127b92a42238afabe502b3aa85d"
            ],
            "layout": "IPY_MODEL_9a700962c00a47c8b931a2203872d3d9"
          }
        },
        "90a88e92429a4d44a099101e0da00bdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5ed84bc864941f594dfc381142a67f3",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_dce934a812ec4c66b7437913ab28f318",
            "value": "Generating‚Äátest‚Äásplit:‚Äá100%"
          }
        },
        "623a355710fe4bc29162af72b806a7dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_981c02c4fb404427bb05590bb3024682",
            "max": 2937,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_615c944248b848d9a4e51d357c977c1f",
            "value": 2937
          }
        },
        "6f926127b92a42238afabe502b3aa85d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8d733d813d4494fbddf69b15a7d518c",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_9d13bc2759e8448d8576026df1488187",
            "value": "‚Äá2937/2937‚Äá[00:00&lt;00:00,‚Äá5715.17‚Äáexamples/s]"
          }
        },
        "9a700962c00a47c8b931a2203872d3d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5ed84bc864941f594dfc381142a67f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dce934a812ec4c66b7437913ab28f318": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "981c02c4fb404427bb05590bb3024682": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "615c944248b848d9a4e51d357c977c1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a8d733d813d4494fbddf69b15a7d518c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d13bc2759e8448d8576026df1488187": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5fc2f90b5c524f28856c8218642e4677": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fc3d1ad515b34a1f88dc6a33b23b44e2",
              "IPY_MODEL_59dd042efca44c17ac4e513dec73ecc2",
              "IPY_MODEL_8a66fce0fe124ffaacf5a8b92a40f124"
            ],
            "layout": "IPY_MODEL_d343c88f02094c289a308ad9025bb3f3"
          }
        },
        "fc3d1ad515b34a1f88dc6a33b23b44e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78670141e058497f96071742a7f98c70",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_bbe5963eba594e7cbeeefb4272c105d0",
            "value": "Map:‚Äá100%"
          }
        },
        "59dd042efca44c17ac4e513dec73ecc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb712b4471cb4e999c577e00a1de389e",
            "max": 2937,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dbb03abd80a74aa2a1b3320df5316d4e",
            "value": 2937
          }
        },
        "8a66fce0fe124ffaacf5a8b92a40f124": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac6848355fb443069f02e5c0e191a9b0",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_490f427b9b2a47c280b8b4e114fd253b",
            "value": "‚Äá2937/2937‚Äá[00:01&lt;00:00,‚Äá2201.17‚Äáexamples/s]"
          }
        },
        "d343c88f02094c289a308ad9025bb3f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78670141e058497f96071742a7f98c70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbe5963eba594e7cbeeefb4272c105d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb712b4471cb4e999c577e00a1de389e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbb03abd80a74aa2a1b3320df5316d4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ac6848355fb443069f02e5c0e191a9b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "490f427b9b2a47c280b8b4e114fd253b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c26ceb2c247043e9b56ed870749e8671": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_17d2d0e875354c5cadc9a98b477c13db",
              "IPY_MODEL_9d21702366ac43039b8a81f4ef542546",
              "IPY_MODEL_cece01037c274911bf33f6435bbaffef"
            ],
            "layout": "IPY_MODEL_3ba493e9888f49d783e1b718f48d35b6"
          }
        },
        "17d2d0e875354c5cadc9a98b477c13db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9adf06b614714af3859266ca0c7799ed",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e8b33e3dc5744d27bd06868f79f43b17",
            "value": "Filter:‚Äá100%"
          }
        },
        "9d21702366ac43039b8a81f4ef542546": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d0bb2f56dac4545b8cbd32d79ae6372",
            "max": 2937,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_58c0967e900745f0932334f3f956aaa1",
            "value": 2937
          }
        },
        "cece01037c274911bf33f6435bbaffef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be45d299f9a1416cbd1c30feaba40428",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ed4ee927579d48039e592b548337b0d0",
            "value": "‚Äá2937/2937‚Äá[00:00&lt;00:00,‚Äá5683.26‚Äáexamples/s]"
          }
        },
        "3ba493e9888f49d783e1b718f48d35b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9adf06b614714af3859266ca0c7799ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8b33e3dc5744d27bd06868f79f43b17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d0bb2f56dac4545b8cbd32d79ae6372": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58c0967e900745f0932334f3f956aaa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "be45d299f9a1416cbd1c30feaba40428": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed4ee927579d48039e592b548337b0d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a13f5a9401dc4f15a3ec2e3b916e06bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_28d664a5e7b94a9ba90d116ca69a206a",
              "IPY_MODEL_ad04ca82619e4a4a81ed2fa9a4982e18",
              "IPY_MODEL_a8a8bd718ffa427683bc9aa4d66aa8bc"
            ],
            "layout": "IPY_MODEL_64ddb8e9b9b34ef493f716c7eca5057e"
          }
        },
        "28d664a5e7b94a9ba90d116ca69a206a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bbaf97fd15c43bb993339fb4a0ef5e3",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_2e011084c31b41c2b74818b497ff4877",
            "value": "Filter:‚Äá100%"
          }
        },
        "ad04ca82619e4a4a81ed2fa9a4982e18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5be77eef223a4452a2ba928b727564eb",
            "max": 2937,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4bb8ef10815a47619cff50b29f74ca3e",
            "value": 2937
          }
        },
        "a8a8bd718ffa427683bc9aa4d66aa8bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5709222ad005478f8776d11c56a33f4b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_283296ca2c534534be29e4722ee7b2a4",
            "value": "‚Äá2937/2937‚Äá[00:00&lt;00:00,‚Äá8217.82‚Äáexamples/s]"
          }
        },
        "64ddb8e9b9b34ef493f716c7eca5057e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bbaf97fd15c43bb993339fb4a0ef5e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e011084c31b41c2b74818b497ff4877": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5be77eef223a4452a2ba928b727564eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bb8ef10815a47619cff50b29f74ca3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5709222ad005478f8776d11c56a33f4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "283296ca2c534534be29e4722ee7b2a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}